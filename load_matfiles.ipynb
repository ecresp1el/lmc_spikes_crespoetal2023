{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extract_ephys_from_struct import ExtractEphysData, calculate_mean_responses, ResponseDistributionPlotter\n",
    "from Analysis_for_ephys import * # import all functions from Analysis_for_ephys.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from plotting_functions import plot_spike_distribution_boxplots, plot_spike_distribution, plot_psth, plot_raster\n",
    "\n",
    "#now test the class\n",
    "#initialize the class\n",
    "EED = ExtractEphysData('/Users/cresp1el/Documents/MATLAB/lmc_20ms_data.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group name: Lmc_noopsin\n",
      "  Recording name: lmc_noch_1_3096_rec1 - Total units: 5\n",
      "  Recording name: lmc_noch_1_3096_rec2 - Total units: 4\n",
      "Group name: Lmc_opsin\n",
      "  Recording name: lmc_ch_1_3094_rec1 - Total units: 7\n",
      "  Recording name: lmc_ch_1_3094_rec2 - Total units: 3\n",
      "  Recording name: lmc_ch_2_3093_rec1 - Total units: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'4bc09822d0832f7c00be68d2fb7a01dc': {'FRs_baseline': [array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.]),\n",
       "   array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.]),\n",
       "   array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.]),\n",
       "   array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "          0., 0.])],\n",
       "  'FRs_baseline_vec': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  'FRs_stim': [array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.]),\n",
       "   array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        , 49.91680532,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ]),\n",
       "   array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0.]),\n",
       "   array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        , 49.91680532,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ])],\n",
       "  'FanoFactor_baseline': array(1.),\n",
       "  'FanoFactor_stim': array([0., 1., 0., 1.]),\n",
       "  'FirstSpikeLatency': array([218.5,  10.5, 289.5,  10.5]),\n",
       "  'FirstSpikeLatency_Reliability': array([0.00143885, 0.00163934, 0.0015873 , 0.00165289]),\n",
       "  'FirstSpikeLatency_pdf_x': [array(218.5),\n",
       "   array([ 10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,\n",
       "           19.5,  20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,\n",
       "           28.5,  29.5,  30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,\n",
       "           37.5,  38.5,  39.5,  40.5,  41.5,  42.5,  43.5,  44.5,  45.5,\n",
       "           46.5,  47.5,  48.5,  49.5,  50.5,  51.5,  52.5,  53.5,  54.5,\n",
       "           55.5,  56.5,  57.5,  58.5,  59.5,  60.5,  61.5,  62.5,  63.5,\n",
       "           64.5,  65.5,  66.5,  67.5,  68.5,  69.5,  70.5,  71.5,  72.5,\n",
       "           73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,  80.5,  81.5,\n",
       "           82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5,  90.5,\n",
       "           91.5,  92.5,  93.5,  94.5,  95.5,  96.5,  97.5,  98.5,  99.5,\n",
       "          100.5, 101.5, 102.5, 103.5, 104.5, 105.5, 106.5, 107.5, 108.5,\n",
       "          109.5, 110.5, 111.5, 112.5, 113.5, 114.5, 115.5, 116.5, 117.5,\n",
       "          118.5, 119.5, 120.5, 121.5, 122.5, 123.5, 124.5, 125.5, 126.5,\n",
       "          127.5, 128.5, 129.5, 130.5, 131.5, 132.5, 133.5, 134.5, 135.5,\n",
       "          136.5, 137.5, 138.5, 139.5, 140.5, 141.5, 142.5, 143.5, 144.5,\n",
       "          145.5, 146.5, 147.5, 148.5, 149.5, 150.5, 151.5, 152.5, 153.5,\n",
       "          154.5, 155.5, 156.5, 157.5, 158.5, 159.5, 160.5, 161.5, 162.5,\n",
       "          163.5, 164.5, 165.5, 166.5, 167.5, 168.5, 169.5, 170.5, 171.5,\n",
       "          172.5, 173.5, 174.5, 175.5, 176.5, 177.5, 178.5, 179.5, 180.5,\n",
       "          181.5, 182.5, 183.5, 184.5, 185.5, 186.5, 187.5, 188.5, 189.5,\n",
       "          190.5, 191.5, 192.5, 193.5, 194.5, 195.5, 196.5, 197.5, 198.5,\n",
       "          199.5, 200.5, 201.5, 202.5, 203.5, 204.5, 205.5, 206.5, 207.5,\n",
       "          208.5, 209.5, 210.5, 211.5, 212.5, 213.5, 214.5, 215.5, 216.5,\n",
       "          217.5, 218.5, 219.5, 220.5, 221.5, 222.5, 223.5, 224.5, 225.5,\n",
       "          226.5, 227.5, 228.5, 229.5, 230.5, 231.5, 232.5, 233.5, 234.5,\n",
       "          235.5, 236.5, 237.5, 238.5, 239.5, 240.5, 241.5, 242.5, 243.5,\n",
       "          244.5, 245.5, 246.5, 247.5, 248.5, 249.5, 250.5, 251.5, 252.5,\n",
       "          253.5]),\n",
       "   array([289.5, 290.5, 291.5, 292.5, 293.5, 294.5, 295.5, 296.5, 297.5,\n",
       "          298.5, 299.5, 300.5, 301.5, 302.5, 303.5, 304.5, 305.5, 306.5,\n",
       "          307.5, 308.5, 309.5, 310.5, 311.5, 312.5, 313.5, 314.5, 315.5,\n",
       "          316.5, 317.5, 318.5, 319.5, 320.5, 321.5, 322.5, 323.5, 324.5,\n",
       "          325.5, 326.5, 327.5, 328.5, 329.5, 330.5, 331.5]),\n",
       "   array([ 10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,\n",
       "           19.5,  20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,\n",
       "           28.5,  29.5,  30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,\n",
       "           37.5,  38.5,  39.5,  40.5,  41.5,  42.5,  43.5,  44.5,  45.5,\n",
       "           46.5,  47.5,  48.5,  49.5,  50.5,  51.5,  52.5,  53.5,  54.5,\n",
       "           55.5,  56.5,  57.5,  58.5,  59.5,  60.5,  61.5,  62.5,  63.5,\n",
       "           64.5,  65.5,  66.5,  67.5,  68.5,  69.5,  70.5,  71.5,  72.5,\n",
       "           73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,  80.5,  81.5,\n",
       "           82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5,  90.5,\n",
       "           91.5,  92.5,  93.5,  94.5,  95.5,  96.5,  97.5,  98.5,  99.5,\n",
       "          100.5, 101.5, 102.5, 103.5, 104.5, 105.5, 106.5, 107.5, 108.5,\n",
       "          109.5, 110.5, 111.5, 112.5, 113.5, 114.5, 115.5, 116.5, 117.5,\n",
       "          118.5, 119.5, 120.5, 121.5, 122.5, 123.5, 124.5, 125.5, 126.5,\n",
       "          127.5, 128.5, 129.5, 130.5, 131.5, 132.5, 133.5, 134.5, 135.5,\n",
       "          136.5, 137.5, 138.5, 139.5, 140.5, 141.5, 142.5, 143.5, 144.5,\n",
       "          145.5, 146.5, 147.5, 148.5, 149.5, 150.5, 151.5, 152.5, 153.5,\n",
       "          154.5, 155.5, 156.5, 157.5, 158.5, 159.5, 160.5, 161.5, 162.5,\n",
       "          163.5, 164.5, 165.5, 166.5, 167.5, 168.5, 169.5, 170.5, 171.5,\n",
       "          172.5, 173.5, 174.5, 175.5, 176.5, 177.5, 178.5, 179.5, 180.5,\n",
       "          181.5, 182.5, 183.5, 184.5, 185.5, 186.5, 187.5, 188.5, 189.5,\n",
       "          190.5, 191.5, 192.5, 193.5, 194.5, 195.5, 196.5, 197.5, 198.5,\n",
       "          199.5, 200.5, 201.5, 202.5, 203.5, 204.5, 205.5, 206.5, 207.5,\n",
       "          208.5, 209.5, 210.5, 211.5, 212.5, 213.5, 214.5, 215.5, 216.5,\n",
       "          217.5, 218.5, 219.5, 220.5, 221.5, 222.5, 223.5, 224.5, 225.5,\n",
       "          226.5, 227.5, 228.5, 229.5, 230.5, 231.5, 232.5, 233.5, 234.5,\n",
       "          235.5, 236.5, 237.5, 238.5, 239.5, 240.5, 241.5, 242.5, 243.5,\n",
       "          244.5, 245.5, 246.5, 247.5, 248.5, 249.5, 250.5, 251.5, 252.5,\n",
       "          253.5, 254.5, 255.5, 256.5, 257.5, 258.5, 259.5, 260.5, 261.5,\n",
       "          262.5, 263.5, 264.5, 265.5, 266.5, 267.5, 268.5, 269.5, 270.5,\n",
       "          271.5, 272.5, 273.5, 274.5, 275.5, 276.5, 277.5, 278.5, 279.5,\n",
       "          280.5, 281.5, 282.5, 283.5, 284.5, 285.5, 286.5, 287.5, 288.5,\n",
       "          289.5, 290.5, 291.5, 292.5, 293.5, 294.5, 295.5, 296.5, 297.5,\n",
       "          298.5, 299.5, 300.5, 301.5, 302.5, 303.5, 304.5, 305.5, 306.5,\n",
       "          307.5, 308.5, 309.5, 310.5, 311.5, 312.5, 313.5, 314.5, 315.5,\n",
       "          316.5, 317.5, 318.5, 319.5, 320.5, 321.5, 322.5, 323.5, 324.5,\n",
       "          325.5, 326.5, 327.5, 328.5, 329.5, 330.5, 331.5, 332.5, 333.5,\n",
       "          334.5, 335.5, 336.5, 337.5, 338.5, 339.5, 340.5, 341.5, 342.5,\n",
       "          343.5, 344.5, 345.5, 346.5, 347.5, 348.5, 349.5, 350.5, 351.5,\n",
       "          352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5, 360.5,\n",
       "          361.5, 362.5, 363.5, 364.5, 365.5, 366.5, 367.5, 368.5, 369.5,\n",
       "          370.5, 371.5, 372.5, 373.5, 374.5, 375.5, 376.5, 377.5, 378.5,\n",
       "          379.5, 380.5, 381.5, 382.5, 383.5, 384.5, 385.5, 386.5, 387.5,\n",
       "          388.5, 389.5, 390.5, 391.5, 392.5, 393.5, 394.5, 395.5, 396.5,\n",
       "          397.5, 398.5, 399.5, 400.5, 401.5, 402.5, 403.5, 404.5, 405.5,\n",
       "          406.5, 407.5, 408.5, 409.5, 410.5, 411.5, 412.5, 413.5, 414.5,\n",
       "          415.5, 416.5, 417.5, 418.5, 419.5, 420.5, 421.5, 422.5])],\n",
       "  'FirstSpikeLatency_pdf_y': [array(0.00143885),\n",
       "   array([0.00163934, 0.00163934, 0.00163934, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.00163934, 0.00163934, 0.00163934, 0.00163934,\n",
       "          0.00163934, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.00163934, 0.00163934, 0.00163934, 0.00163934, 0.00163934,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.00163934, 0.00163934, 0.00163934]),\n",
       "   array([0.0015873, 0.0015873, 0.0015873, 0.       , 0.       , 0.       ,\n",
       "          0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "          0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "          0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "          0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "          0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "          0.       , 0.       , 0.       , 0.       , 0.0015873, 0.0015873,\n",
       "          0.0015873]),\n",
       "   array([0.00165289, 0.00165289, 0.00165289, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.00165289, 0.00165289, 0.00165289, 0.00165289, 0.00165289,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.00165289, 0.00165289, 0.00165289,\n",
       "          0.00165289, 0.00165289, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.00165289, 0.00165289, 0.00165289])],\n",
       "  'FirstSpikeLatency_perTrial': [array([         nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan, 218.76666667,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan]),\n",
       "   array([         nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan, 197.36666667,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "           10.56666667,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,  38.36666667,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan, 254.        ,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan]),\n",
       "   array([         nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan, 331.93333333, 289.56666667,          nan,\n",
       "                   nan,          nan]),\n",
       "   array([         nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan, 409.86666667,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan, 422.73333333,          nan,\n",
       "                   nan,  10.33333333,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan, 317.23333333,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan,          nan,          nan,          nan,\n",
       "                   nan])],\n",
       "  'ISI_baseline_CV': array(nan),\n",
       "  'ISI_baseline_vec': None,\n",
       "  'ISI_pdf_peak_xy': array([0.5, nan]),\n",
       "  'ISI_pdf_x': array(0.5),\n",
       "  'ISI_pdf_y': array(nan),\n",
       "  'MeanFR_baseline': array(0.02755906),\n",
       "  'MeanFR_inst_baseline': array(0.0286939),\n",
       "  'MeanFR_inst_stim': array([0.        , 0.39032006, 0.        , 0.39354585]),\n",
       "  'MeanFR_stim': array([0.        , 0.40915414, 0.        , 0.41253558]),\n",
       "  'ModulationIndex': array(0.86408716),\n",
       "  'PSTHs_conv': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'PSTHs_raw': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'PeakEvokedFR': array([0.        , 1.09048366, 0.        , 1.09949592]),\n",
       "  'PeakEvokedFR_Latency': array([ 0., 10.,  0., 10.]),\n",
       "  'SpikeTimes_baseline': [None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(29425165.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(35678988.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(43328408.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(64245930.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(88745900.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(1.04584312e+08),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(1.19108076e+08),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  'SpikeTimes_stim': [None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(39548726.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(46268141.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(48884657.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array([63908891., 63914145.]),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(71019232.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(76867600.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(78691440.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(97125353.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(1.09889077e+08),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(1.18385578e+08),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array([1.20190727e+08, 1.20193966e+08]),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  'SpikeTimes_trials': [None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(20991607.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(25101617.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(29425165.),\n",
       "   None,\n",
       "   None,\n",
       "   array(30165348.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(34244775.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(35678988.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(39548726.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(43328408.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(46268141.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(48884657.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(52002361.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array([63908891., 63914145.]),\n",
       "   array(64245930.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(67834397.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(71019232.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(76867600.),\n",
       "   None,\n",
       "   array(77490948.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(78691440.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(88745900.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(95530144.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(97125353.),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(1.04584312e+08),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(1.09889077e+08),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array(1.18385578e+08),\n",
       "   None,\n",
       "   None,\n",
       "   array(1.19108076e+08),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   array([1.20190727e+08, 1.20193966e+08]),\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  'SpikeTrains_baseline': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'SpikeTrains_baseline_ms': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'SpikeTrains_for_PSTHs': [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "   array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "   array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "   array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]], dtype=int8)],\n",
       "  'SpikeTrains_stim': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'SpikeTrains_stim_ms': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'SpikeTrains_trials': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'SpikeTrains_trials_ms': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'StimProb': array([0.50413223, 0.5       , 0.52678571]),\n",
       "  'StimResponsivity': array(0.),\n",
       "  'Stim_Intensity': array([2., 2., 1., 1., 2., 2., 2., 4., 2., 1., 2., 1., 1., 4., 3., 4., 1.,\n",
       "         1., 1., 1., 1., 3., 1., 3., 1., 2., 4., 2., 1., 1., 2., 1., 4., 3.,\n",
       "         4., 4., 4., 1., 3., 3., 2., 2., 3., 4., 1., 3., 4., 4., 3., 1., 4.,\n",
       "         1., 1., 2., 2., 3., 4., 3., 3., 1., 3., 3., 1., 3., 4., 2., 4., 4.,\n",
       "         1., 4., 4., 2., 3., 1., 2., 4., 4., 4., 1., 2., 4., 3., 2., 2., 3.,\n",
       "         3., 4., 1., 4., 3., 3., 2., 3., 1., 4., 1., 3., 1., 1., 4., 3., 4.,\n",
       "         3., 1., 2., 4., 3., 4., 4., 2., 1., 3., 1., 2., 3., 1., 1., 3., 1.,\n",
       "         2., 4., 4., 4., 1., 1., 2., 2., 2., 4., 3., 2., 4., 2., 3., 3., 1.,\n",
       "         3., 3., 2., 3., 4., 3., 4., 1., 2., 3., 2., 2., 3., 1., 2., 1., 1.,\n",
       "         4., 3., 3., 1., 2., 4., 4., 4., 4., 4., 2., 3., 3., 2., 1., 3., 1.,\n",
       "         2., 3., 4., 1., 2., 4., 3., 3., 4., 1., 1., 1., 1., 3., 4., 2., 4.,\n",
       "         4., 1., 1., 2., 1., 2., 2., 2., 4., 2., 2., 2., 3., 3., 2., 3., 4.,\n",
       "         2., 2., 1., 2., 1., 4., 2., 1., 3., 2., 3., 4., 3., 2., 2., 2., 1.,\n",
       "         1., 4., 4., 2., 2., 4., 4., 4., 3., 2., 1., 3., 4., 1., 3., 4., 2.,\n",
       "         2., 1., 3., 1., 3., 3., 1., 1., 2., 4., 1., 1., 2., 4., 1., 1., 3.,\n",
       "         2., 4., 3., 2., 3., 2., 3., 1., 3., 2., 3., 1., 3., 1., 4., 4., 4.,\n",
       "         3., 2., 1., 3., 2., 3., 3., 4., 4., 2., 3., 2., 3., 2., 2., 1., 3.,\n",
       "         3., 4., 3., 4., 4., 1., 3., 2., 3., 3., 2., 4., 3., 2., 2., 3., 3.,\n",
       "         3., 2., 4., 2., 2., 1., 3., 1., 2., 1., 3., 1., 4., 3., 1., 4., 3.,\n",
       "         4., 4., 2., 1., 4., 3., 1., 4., 1., 2., 3., 2., 1., 1., 4., 4., 1.,\n",
       "         2., 2., 2., 2., 3., 3., 1., 3., 1., 2., 3., 4., 1., 4., 3., 1., 3.,\n",
       "         2., 4., 2., 3., 1., 3., 4., 1., 1., 1., 4., 2., 2., 3., 1., 3., 1.,\n",
       "         3., 1., 3., 3., 4., 4., 2., 1., 1., 1., 4., 1., 4., 1., 4., 2., 1.,\n",
       "         1., 4., 4., 3., 2., 4., 1., 1., 2., 2., 1., 1., 4., 4., 2., 4., 4.,\n",
       "         4., 1., 4., 1., 1., 2., 4., 2., 1., 1., 1., 4., 2., 4., 1., 4., 3.,\n",
       "         2., 4., 3., 2., 3., 4., 4., 1., 2., 4., 1., 4., 2., 2., 1., 1., 1.,\n",
       "         1., 3., 3., 3., 1., 2., 2., 3., 3., 3., 1., 4., 1., 4., 1., 1., 2.,\n",
       "         3., 3., 1., 4., 4., 2., 3., 1., 2., 3., 4., 4., 1., 1., 3., 3., 4.,\n",
       "         2., 3., 3., 1., 1., 1., 4., 1., 3., 1., 2., 2., 1., 3., 4., 3., 2.,\n",
       "         1., 4., 1., 2., 4., 3., 3., 1., 2., 4., 2., 2., 3., 2., 3.]),\n",
       "  'Stim_Offsets_samples': array([7.0677000e+05, 7.9629000e+05, 1.1655000e+06, 1.2883500e+06,\n",
       "         1.6263900e+06, 1.8751500e+06, 2.0514300e+06, 2.2626000e+06,\n",
       "         2.6206200e+06, 2.7175200e+06, 3.0246000e+06, 3.2453100e+06,\n",
       "         3.5929800e+06, 3.7298700e+06, 4.0360200e+06, 4.2780000e+06,\n",
       "         4.5243600e+06, 4.7196000e+06, 4.9779600e+06, 5.2357200e+06,\n",
       "         5.4290100e+06, 5.6413500e+06, 5.9830800e+06, 6.0722100e+06,\n",
       "         6.3153900e+06, 6.6606300e+06, 6.8567400e+06, 7.1573700e+06,\n",
       "         7.4156100e+06, 7.5750000e+06, 7.9052100e+06, 8.0897400e+06,\n",
       "         8.2548000e+06, 8.6227800e+06, 8.7709800e+06, 8.9711100e+06,\n",
       "         9.3409500e+06, 9.5725800e+06, 9.6618600e+06, 9.9140100e+06,\n",
       "         1.0186890e+07, 1.0468590e+07, 1.0691160e+07, 1.0927410e+07,\n",
       "         1.1260350e+07, 1.1495880e+07, 1.1676600e+07, 1.1890290e+07,\n",
       "         1.2174570e+07, 1.2469050e+07, 1.2568410e+07, 1.2932070e+07,\n",
       "         1.3022730e+07, 1.3316730e+07, 1.3638510e+07, 1.3851810e+07,\n",
       "         1.4094180e+07, 1.4387820e+07, 1.4508390e+07, 1.4767230e+07,\n",
       "         1.4943690e+07, 1.5273690e+07, 1.5474390e+07, 1.5812280e+07,\n",
       "         1.5978180e+07, 1.6161840e+07, 1.6452030e+07, 1.6693650e+07,\n",
       "         1.6899720e+07, 1.7214930e+07, 1.7348280e+07, 1.7663010e+07,\n",
       "         1.7903250e+07, 1.8227640e+07, 1.8374910e+07, 1.8681810e+07,\n",
       "         1.8933090e+07, 1.9047540e+07, 1.9341600e+07, 1.9548300e+07,\n",
       "         1.9793760e+07, 2.0118480e+07, 2.0346030e+07, 2.0473020e+07,\n",
       "         2.0791050e+07, 2.0985750e+07, 2.1182520e+07, 2.1536460e+07,\n",
       "         2.1826350e+07, 2.1955890e+07, 2.2283670e+07, 2.2493730e+07,\n",
       "         2.2649910e+07, 2.2911390e+07, 2.3173860e+07, 2.3385450e+07,\n",
       "         2.3706420e+07, 2.3959890e+07, 2.4074820e+07, 2.4413220e+07,\n",
       "         2.4713130e+07, 2.4928800e+07, 2.5098090e+07, 2.5405140e+07,\n",
       "         2.5657620e+07, 2.5796460e+07, 2.6038680e+07, 2.6337840e+07,\n",
       "         2.6591010e+07, 2.6870790e+07, 2.6952600e+07, 2.7224760e+07,\n",
       "         2.7520080e+07, 2.7801630e+07, 2.7954060e+07, 2.8283130e+07,\n",
       "         2.8427580e+07, 2.8682250e+07, 2.8995510e+07, 2.9129160e+07,\n",
       "         2.9446560e+07, 2.9675760e+07, 2.9940810e+07, 3.0150960e+07,\n",
       "         3.0379440e+07, 3.0593910e+07, 3.0936450e+07, 3.1117950e+07,\n",
       "         3.1370400e+07, 3.1557450e+07, 3.1766910e+07, 3.2111520e+07,\n",
       "         3.2275530e+07, 3.2473680e+07, 3.2782620e+07, 3.2949510e+07,\n",
       "         3.3255750e+07, 3.3497220e+07, 3.3688380e+07, 3.3986190e+07,\n",
       "         3.4236540e+07, 3.4383360e+07, 3.4667730e+07, 3.4977120e+07,\n",
       "         3.5221200e+07, 3.5510640e+07, 3.5705850e+07, 3.5990520e+07,\n",
       "         3.6087810e+07, 3.6339990e+07, 3.6654420e+07, 3.6906000e+07,\n",
       "         3.7190970e+07, 3.7331100e+07, 3.7632780e+07, 3.7879890e+07,\n",
       "         3.8116560e+07, 3.8349990e+07, 3.8462580e+07, 3.8839620e+07,\n",
       "         3.9053820e+07, 3.9335220e+07, 3.9551430e+07, 3.9824730e+07,\n",
       "         3.9943020e+07, 4.0185210e+07, 4.0488000e+07, 4.0643010e+07,\n",
       "         4.0900230e+07, 4.1242110e+07, 4.1420940e+07, 4.1582190e+07,\n",
       "         4.1898840e+07, 4.2198750e+07, 4.2479820e+07, 4.2650310e+07,\n",
       "         4.2839550e+07, 4.3030230e+07, 4.3348440e+07, 4.3597350e+07,\n",
       "         4.3762500e+07, 4.4007600e+07, 4.4229570e+07, 4.4623740e+07,\n",
       "         4.4866740e+07, 4.5011070e+07, 4.5346050e+07, 4.5434460e+07,\n",
       "         4.5797040e+07, 4.6044810e+07, 4.6277220e+07, 4.6400070e+07,\n",
       "         4.6760070e+07, 4.6922490e+07, 4.7279520e+07, 4.7509200e+07,\n",
       "         4.7661660e+07, 4.7848200e+07, 4.8186030e+07, 4.8412770e+07,\n",
       "         4.8624450e+07, 4.8899340e+07, 4.9138740e+07, 4.9367700e+07,\n",
       "         4.9579410e+07, 4.9847880e+07, 5.0135130e+07, 5.0347770e+07,\n",
       "         5.0597250e+07, 5.0854740e+07, 5.1038850e+07, 5.1231990e+07,\n",
       "         5.1512460e+07, 5.1817350e+07, 5.1998040e+07, 5.2260000e+07,\n",
       "         5.2524360e+07, 5.2730340e+07, 5.2980300e+07, 5.3152830e+07,\n",
       "         5.3454450e+07, 5.3753010e+07, 5.3988840e+07, 5.4174600e+07,\n",
       "         5.4332760e+07, 5.4682230e+07, 5.4826380e+07, 5.5090950e+07,\n",
       "         5.5409700e+07, 5.5667790e+07, 5.5769580e+07, 5.6037300e+07,\n",
       "         5.6315130e+07, 5.6476770e+07, 5.6802270e+07, 5.7079410e+07,\n",
       "         5.7297090e+07, 5.7508110e+07, 5.7803220e+07, 5.7944550e+07,\n",
       "         5.8187040e+07, 5.8488780e+07, 5.8788210e+07, 5.8974660e+07,\n",
       "         5.9225400e+07, 5.9355840e+07, 5.9598930e+07, 5.9872950e+07,\n",
       "         6.0179730e+07, 6.0398850e+07, 6.0676620e+07, 6.0821730e+07,\n",
       "         6.1033770e+07, 6.1390380e+07, 6.1582050e+07, 6.1816710e+07,\n",
       "         6.2018520e+07, 6.2363550e+07, 6.2605020e+07, 6.2738760e+07,\n",
       "         6.2994000e+07, 6.3293070e+07, 6.3453450e+07, 6.3742980e+07,\n",
       "         6.3922740e+07, 6.4268760e+07, 6.4554660e+07, 6.4643070e+07,\n",
       "         6.5024160e+07, 6.5148930e+07, 6.5408190e+07, 6.5675130e+07,\n",
       "         6.5979990e+07, 6.6176910e+07, 6.6302340e+07, 6.6682980e+07,\n",
       "         6.6833400e+07, 6.7043310e+07, 6.7338270e+07, 6.7648260e+07,\n",
       "         6.7832550e+07, 6.8018220e+07, 6.8224260e+07, 6.8623170e+07,\n",
       "         6.8763600e+07, 6.9031620e+07, 6.9256260e+07, 6.9497940e+07,\n",
       "         6.9713550e+07, 7.0063710e+07, 7.0205820e+07, 7.0481490e+07,\n",
       "         7.0633890e+07, 7.1021550e+07, 7.1159280e+07, 7.1442570e+07,\n",
       "         7.1741970e+07, 7.1852130e+07, 7.2070290e+07, 7.2436860e+07,\n",
       "         7.2658020e+07, 7.2860670e+07, 7.3173120e+07, 7.3348290e+07,\n",
       "         7.3579980e+07, 7.3811730e+07, 7.4132670e+07, 7.4360460e+07,\n",
       "         7.4633970e+07, 7.4843370e+07, 7.5053730e+07, 7.5189810e+07,\n",
       "         7.5480750e+07, 7.5748050e+07, 7.6080330e+07, 7.6141440e+07,\n",
       "         7.6388370e+07, 7.6729140e+07, 7.6882290e+07, 7.7154840e+07,\n",
       "         7.7485200e+07, 7.7597790e+07, 7.7947110e+07, 7.8206340e+07,\n",
       "         7.8339900e+07, 7.8698820e+07, 7.8938280e+07, 7.9051290e+07,\n",
       "         7.9352880e+07, 7.9648020e+07, 7.9788900e+07, 8.0145180e+07,\n",
       "         8.0353050e+07, 8.0584680e+07, 8.0816760e+07, 8.0943090e+07,\n",
       "         8.1309570e+07, 8.1445680e+07, 8.1667650e+07, 8.1977760e+07,\n",
       "         8.2251060e+07, 8.2423530e+07, 8.2762500e+07, 8.2892070e+07,\n",
       "         8.3220570e+07, 8.3420130e+07, 8.3640780e+07, 8.3927430e+07,\n",
       "         8.4072420e+07, 8.4436410e+07, 8.4628530e+07, 8.4909570e+07,\n",
       "         8.5125900e+07, 8.5428630e+07, 8.5532100e+07, 8.5812780e+07,\n",
       "         8.6015340e+07, 8.6377470e+07, 8.6488890e+07, 8.6786280e+07,\n",
       "         8.7012060e+07, 8.7267480e+07, 8.7564420e+07, 8.7813750e+07,\n",
       "         8.7903480e+07, 8.8221090e+07, 8.8542180e+07, 8.8769340e+07,\n",
       "         8.9023830e+07, 8.9261940e+07, 8.9385960e+07, 8.9635230e+07,\n",
       "         8.9862300e+07, 9.0207540e+07, 9.0400170e+07, 9.0551070e+07,\n",
       "         9.0919680e+07, 9.1090590e+07, 9.1314240e+07, 9.1547790e+07,\n",
       "         9.1857210e+07, 9.2120520e+07, 9.2372160e+07, 9.2627310e+07,\n",
       "         9.2824650e+07, 9.3086880e+07, 9.3322530e+07, 9.3485940e+07,\n",
       "         9.3743310e+07, 9.4026210e+07, 9.4219860e+07, 9.4416150e+07,\n",
       "         9.4657020e+07, 9.4968630e+07, 9.5157060e+07, 9.5520090e+07,\n",
       "         9.5631510e+07, 9.5984190e+07, 9.6125700e+07, 9.6306000e+07,\n",
       "         9.6631830e+07, 9.6947760e+07, 9.7133790e+07, 9.7378680e+07,\n",
       "         9.7556550e+07, 9.7824330e+07, 9.8152950e+07, 9.8340810e+07,\n",
       "         9.8590140e+07, 9.8876580e+07, 9.9009870e+07, 9.9357570e+07,\n",
       "         9.9448140e+07, 9.9700560e+07, 9.9999600e+07, 1.0023858e+08,\n",
       "         1.0042209e+08, 1.0069374e+08, 1.0094361e+08, 1.0128036e+08,\n",
       "         1.0135284e+08, 1.0160658e+08, 1.0184775e+08, 1.0219662e+08,\n",
       "         1.0231200e+08, 1.0265619e+08, 1.0288356e+08, 1.0312128e+08,\n",
       "         1.0331391e+08, 1.0357800e+08, 1.0378647e+08, 1.0405467e+08,\n",
       "         1.0425108e+08, 1.0460901e+08, 1.0479267e+08, 1.0507191e+08,\n",
       "         1.0530834e+08, 1.0557306e+08, 1.0576332e+08, 1.0601835e+08,\n",
       "         1.0616910e+08, 1.0650708e+08, 1.0666932e+08, 1.0701918e+08,\n",
       "         1.0719771e+08, 1.0745085e+08, 1.0774347e+08, 1.0791222e+08,\n",
       "         1.0819236e+08, 1.0846362e+08, 1.0865955e+08, 1.0885170e+08,\n",
       "         1.0910679e+08, 1.0934763e+08, 1.0967760e+08, 1.0989456e+08,\n",
       "         1.1001783e+08, 1.1025579e+08, 1.1063151e+08, 1.1070519e+08,\n",
       "         1.1094354e+08, 1.1126616e+08, 1.1152494e+08, 1.1175579e+08,\n",
       "         1.1207754e+08, 1.1221668e+08, 1.1249031e+08, 1.1271954e+08,\n",
       "         1.1291931e+08, 1.1317881e+08, 1.1341839e+08, 1.1374428e+08,\n",
       "         1.1394606e+08, 1.1423541e+08, 1.1443785e+08, 1.1466468e+08,\n",
       "         1.1488635e+08, 1.1502957e+08, 1.1538492e+08, 1.1554302e+08,\n",
       "         1.1580792e+08, 1.1604036e+08, 1.1636967e+08, 1.1659857e+08,\n",
       "         1.1674953e+08, 1.1708049e+08, 1.1723484e+08, 1.1748030e+08,\n",
       "         1.1769612e+08, 1.1799171e+08, 1.1819037e+08, 1.1839062e+08,\n",
       "         1.1863746e+08, 1.1898591e+08, 1.1913132e+08, 1.1935065e+08,\n",
       "         1.1970678e+08, 1.1992419e+08, 1.2019704e+08, 1.2039204e+08,\n",
       "         1.2069111e+08, 1.2078669e+08, 1.2106836e+08, 1.2129114e+08,\n",
       "         1.2153828e+08, 1.2182169e+08, 1.2202926e+08, 1.2233844e+08]),\n",
       "  'Stim_Onsets_samples': array([6.9177000e+05, 7.8129000e+05, 1.1505000e+06, 1.2733500e+06,\n",
       "         1.6113900e+06, 1.8601500e+06, 2.0364300e+06, 2.2476000e+06,\n",
       "         2.6056200e+06, 2.7025200e+06, 3.0096000e+06, 3.2303100e+06,\n",
       "         3.5779800e+06, 3.7148700e+06, 4.0210200e+06, 4.2630000e+06,\n",
       "         4.5093600e+06, 4.7046000e+06, 4.9629600e+06, 5.2207200e+06,\n",
       "         5.4140100e+06, 5.6263500e+06, 5.9680800e+06, 6.0572100e+06,\n",
       "         6.3003900e+06, 6.6456300e+06, 6.8417400e+06, 7.1423700e+06,\n",
       "         7.4006100e+06, 7.5600000e+06, 7.8902100e+06, 8.0747400e+06,\n",
       "         8.2398000e+06, 8.6077800e+06, 8.7559800e+06, 8.9561100e+06,\n",
       "         9.3259500e+06, 9.5575800e+06, 9.6468600e+06, 9.8990100e+06,\n",
       "         1.0171890e+07, 1.0453590e+07, 1.0676160e+07, 1.0912440e+07,\n",
       "         1.1245350e+07, 1.1480880e+07, 1.1661600e+07, 1.1875290e+07,\n",
       "         1.2159570e+07, 1.2454050e+07, 1.2553410e+07, 1.2917070e+07,\n",
       "         1.3007730e+07, 1.3301730e+07, 1.3623510e+07, 1.3836810e+07,\n",
       "         1.4079180e+07, 1.4372820e+07, 1.4493390e+07, 1.4752230e+07,\n",
       "         1.4928690e+07, 1.5258690e+07, 1.5459390e+07, 1.5797280e+07,\n",
       "         1.5963180e+07, 1.6146840e+07, 1.6437030e+07, 1.6678650e+07,\n",
       "         1.6884720e+07, 1.7199930e+07, 1.7333280e+07, 1.7648010e+07,\n",
       "         1.7888250e+07, 1.8212640e+07, 1.8359910e+07, 1.8666810e+07,\n",
       "         1.8918090e+07, 1.9032540e+07, 1.9326600e+07, 1.9533300e+07,\n",
       "         1.9778760e+07, 2.0103480e+07, 2.0331030e+07, 2.0458020e+07,\n",
       "         2.0776050e+07, 2.0970750e+07, 2.1167520e+07, 2.1521460e+07,\n",
       "         2.1811350e+07, 2.1940890e+07, 2.2268670e+07, 2.2478730e+07,\n",
       "         2.2634910e+07, 2.2896390e+07, 2.3158860e+07, 2.3370450e+07,\n",
       "         2.3691420e+07, 2.3944890e+07, 2.4059820e+07, 2.4398220e+07,\n",
       "         2.4698130e+07, 2.4913800e+07, 2.5083090e+07, 2.5389990e+07,\n",
       "         2.5642620e+07, 2.5781490e+07, 2.6023680e+07, 2.6322840e+07,\n",
       "         2.6576010e+07, 2.6855790e+07, 2.6937600e+07, 2.7209760e+07,\n",
       "         2.7505080e+07, 2.7786630e+07, 2.7939060e+07, 2.8268130e+07,\n",
       "         2.8412580e+07, 2.8667250e+07, 2.8980510e+07, 2.9114160e+07,\n",
       "         2.9431560e+07, 2.9660760e+07, 2.9925810e+07, 3.0135960e+07,\n",
       "         3.0364440e+07, 3.0578910e+07, 3.0921450e+07, 3.1102950e+07,\n",
       "         3.1355400e+07, 3.1542450e+07, 3.1751940e+07, 3.2096520e+07,\n",
       "         3.2260530e+07, 3.2458680e+07, 3.2767620e+07, 3.2934510e+07,\n",
       "         3.3240750e+07, 3.3482220e+07, 3.3673380e+07, 3.3971190e+07,\n",
       "         3.4221540e+07, 3.4368360e+07, 3.4652730e+07, 3.4962120e+07,\n",
       "         3.5206200e+07, 3.5495640e+07, 3.5690850e+07, 3.5975520e+07,\n",
       "         3.6072810e+07, 3.6324990e+07, 3.6639420e+07, 3.6891000e+07,\n",
       "         3.7175970e+07, 3.7316100e+07, 3.7617780e+07, 3.7864890e+07,\n",
       "         3.8101560e+07, 3.8334990e+07, 3.8447580e+07, 3.8824620e+07,\n",
       "         3.9038820e+07, 3.9320220e+07, 3.9536430e+07, 3.9809730e+07,\n",
       "         3.9928020e+07, 4.0170210e+07, 4.0473000e+07, 4.0628010e+07,\n",
       "         4.0885230e+07, 4.1227110e+07, 4.1405940e+07, 4.1567190e+07,\n",
       "         4.1883840e+07, 4.2183750e+07, 4.2464820e+07, 4.2635310e+07,\n",
       "         4.2824550e+07, 4.3015230e+07, 4.3333440e+07, 4.3582350e+07,\n",
       "         4.3747500e+07, 4.3992600e+07, 4.4214570e+07, 4.4608740e+07,\n",
       "         4.4851740e+07, 4.4996070e+07, 4.5331050e+07, 4.5419460e+07,\n",
       "         4.5782040e+07, 4.6029810e+07, 4.6262220e+07, 4.6385070e+07,\n",
       "         4.6745070e+07, 4.6907490e+07, 4.7264520e+07, 4.7494200e+07,\n",
       "         4.7646660e+07, 4.7833200e+07, 4.8171030e+07, 4.8397770e+07,\n",
       "         4.8609450e+07, 4.8884340e+07, 4.9123740e+07, 4.9352700e+07,\n",
       "         4.9564410e+07, 4.9832880e+07, 5.0119980e+07, 5.0332770e+07,\n",
       "         5.0582250e+07, 5.0839740e+07, 5.1023850e+07, 5.1216990e+07,\n",
       "         5.1497460e+07, 5.1802290e+07, 5.1983040e+07, 5.2245000e+07,\n",
       "         5.2509360e+07, 5.2715340e+07, 5.2965300e+07, 5.3137830e+07,\n",
       "         5.3439450e+07, 5.3738010e+07, 5.3973840e+07, 5.4159600e+07,\n",
       "         5.4317760e+07, 5.4667230e+07, 5.4811380e+07, 5.5075950e+07,\n",
       "         5.5394700e+07, 5.5652790e+07, 5.5754580e+07, 5.6022300e+07,\n",
       "         5.6300130e+07, 5.6461770e+07, 5.6787270e+07, 5.7064410e+07,\n",
       "         5.7281940e+07, 5.7493110e+07, 5.7788220e+07, 5.7929550e+07,\n",
       "         5.8172040e+07, 5.8473810e+07, 5.8773210e+07, 5.8959660e+07,\n",
       "         5.9210400e+07, 5.9340840e+07, 5.9583930e+07, 5.9857950e+07,\n",
       "         6.0164730e+07, 6.0383850e+07, 6.0661620e+07, 6.0806730e+07,\n",
       "         6.1018770e+07, 6.1375410e+07, 6.1567050e+07, 6.1801710e+07,\n",
       "         6.2003520e+07, 6.2348550e+07, 6.2590020e+07, 6.2723760e+07,\n",
       "         6.2979000e+07, 6.3278070e+07, 6.3438450e+07, 6.3727980e+07,\n",
       "         6.3907740e+07, 6.4253610e+07, 6.4539660e+07, 6.4628070e+07,\n",
       "         6.5009160e+07, 6.5133930e+07, 6.5393190e+07, 6.5660130e+07,\n",
       "         6.5964990e+07, 6.6161910e+07, 6.6287340e+07, 6.6667980e+07,\n",
       "         6.6818400e+07, 6.7028310e+07, 6.7323270e+07, 6.7633260e+07,\n",
       "         6.7817550e+07, 6.8003220e+07, 6.8209260e+07, 6.8608170e+07,\n",
       "         6.8748600e+07, 6.9016620e+07, 6.9241260e+07, 6.9482940e+07,\n",
       "         6.9698550e+07, 7.0048710e+07, 7.0190820e+07, 7.0466490e+07,\n",
       "         7.0618890e+07, 7.1006550e+07, 7.1144280e+07, 7.1427570e+07,\n",
       "         7.1726970e+07, 7.1837130e+07, 7.2055290e+07, 7.2421860e+07,\n",
       "         7.2643020e+07, 7.2845670e+07, 7.3158120e+07, 7.3333290e+07,\n",
       "         7.3564980e+07, 7.3796730e+07, 7.4117670e+07, 7.4345460e+07,\n",
       "         7.4618970e+07, 7.4828370e+07, 7.5038730e+07, 7.5174810e+07,\n",
       "         7.5465750e+07, 7.5733050e+07, 7.6065330e+07, 7.6126440e+07,\n",
       "         7.6373370e+07, 7.6714140e+07, 7.6867290e+07, 7.7139840e+07,\n",
       "         7.7470200e+07, 7.7582790e+07, 7.7932110e+07, 7.8191340e+07,\n",
       "         7.8324900e+07, 7.8683820e+07, 7.8923280e+07, 7.9036290e+07,\n",
       "         7.9337880e+07, 7.9633020e+07, 7.9773900e+07, 8.0130180e+07,\n",
       "         8.0338050e+07, 8.0569680e+07, 8.0801760e+07, 8.0928090e+07,\n",
       "         8.1294570e+07, 8.1430680e+07, 8.1652650e+07, 8.1962760e+07,\n",
       "         8.2236060e+07, 8.2408530e+07, 8.2747500e+07, 8.2877070e+07,\n",
       "         8.3205570e+07, 8.3405130e+07, 8.3625780e+07, 8.3912430e+07,\n",
       "         8.4057420e+07, 8.4421410e+07, 8.4613530e+07, 8.4894570e+07,\n",
       "         8.5110900e+07, 8.5413630e+07, 8.5517100e+07, 8.5797780e+07,\n",
       "         8.6000340e+07, 8.6362470e+07, 8.6473890e+07, 8.6771280e+07,\n",
       "         8.6997060e+07, 8.7252480e+07, 8.7549390e+07, 8.7798750e+07,\n",
       "         8.7888480e+07, 8.8206120e+07, 8.8527180e+07, 8.8754340e+07,\n",
       "         8.9008830e+07, 8.9246790e+07, 8.9370960e+07, 8.9620230e+07,\n",
       "         8.9847300e+07, 9.0192540e+07, 9.0385170e+07, 9.0536070e+07,\n",
       "         9.0904680e+07, 9.1075590e+07, 9.1299240e+07, 9.1532790e+07,\n",
       "         9.1842210e+07, 9.2105520e+07, 9.2357160e+07, 9.2612310e+07,\n",
       "         9.2809530e+07, 9.3071880e+07, 9.3307530e+07, 9.3470940e+07,\n",
       "         9.3728310e+07, 9.4011210e+07, 9.4204860e+07, 9.4401150e+07,\n",
       "         9.4641870e+07, 9.4953630e+07, 9.5142060e+07, 9.5505090e+07,\n",
       "         9.5616510e+07, 9.5969190e+07, 9.6110700e+07, 9.6291000e+07,\n",
       "         9.6616830e+07, 9.6932760e+07, 9.7118790e+07, 9.7363680e+07,\n",
       "         9.7541550e+07, 9.7809330e+07, 9.8137950e+07, 9.8325810e+07,\n",
       "         9.8575140e+07, 9.8861580e+07, 9.8994870e+07, 9.9342570e+07,\n",
       "         9.9433140e+07, 9.9685560e+07, 9.9984480e+07, 1.0022358e+08,\n",
       "         1.0040709e+08, 1.0067874e+08, 1.0092861e+08, 1.0126536e+08,\n",
       "         1.0133784e+08, 1.0159158e+08, 1.0183275e+08, 1.0218162e+08,\n",
       "         1.0229700e+08, 1.0264119e+08, 1.0286856e+08, 1.0310628e+08,\n",
       "         1.0329891e+08, 1.0356300e+08, 1.0377147e+08, 1.0403967e+08,\n",
       "         1.0423608e+08, 1.0459401e+08, 1.0477767e+08, 1.0505691e+08,\n",
       "         1.0529334e+08, 1.0555806e+08, 1.0574832e+08, 1.0600335e+08,\n",
       "         1.0615410e+08, 1.0649208e+08, 1.0665432e+08, 1.0700418e+08,\n",
       "         1.0718271e+08, 1.0743585e+08, 1.0772847e+08, 1.0789722e+08,\n",
       "         1.0817736e+08, 1.0844862e+08, 1.0864455e+08, 1.0883670e+08,\n",
       "         1.0909179e+08, 1.0933263e+08, 1.0966260e+08, 1.0987956e+08,\n",
       "         1.1000283e+08, 1.1024079e+08, 1.1061651e+08, 1.1069019e+08,\n",
       "         1.1092854e+08, 1.1125116e+08, 1.1150994e+08, 1.1174079e+08,\n",
       "         1.1206254e+08, 1.1220168e+08, 1.1247531e+08, 1.1270454e+08,\n",
       "         1.1290431e+08, 1.1316381e+08, 1.1340339e+08, 1.1372928e+08,\n",
       "         1.1393106e+08, 1.1422041e+08, 1.1442270e+08, 1.1464968e+08,\n",
       "         1.1487135e+08, 1.1501457e+08, 1.1536992e+08, 1.1552802e+08,\n",
       "         1.1579292e+08, 1.1602536e+08, 1.1635467e+08, 1.1658357e+08,\n",
       "         1.1673453e+08, 1.1706549e+08, 1.1721984e+08, 1.1746530e+08,\n",
       "         1.1768112e+08, 1.1797674e+08, 1.1817537e+08, 1.1837562e+08,\n",
       "         1.1862246e+08, 1.1897091e+08, 1.1911632e+08, 1.1933565e+08,\n",
       "         1.1969178e+08, 1.1990919e+08, 1.2018204e+08, 1.2037704e+08,\n",
       "         1.2067611e+08, 1.2077169e+08, 1.2105336e+08, 1.2127614e+08,\n",
       "         1.2152328e+08, 1.2180669e+08, 1.2201426e+08, 1.2232344e+08])}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the methods of the class\n",
    "EED.load_matfiles_printdata()\n",
    "EED.get_original_cellid('4bc09822d0832f7c00be68d2fb7a01dc') #get the original cell id for a given unit id\n",
    "EED.get_pre_data('4bc09822d0832f7c00be68d2fb7a01dc') #get the pre data for a given unit id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in EED.get_group_names():\n",
    "    for recoring in EED.get_recording_names(group):\n",
    "        print(recoring)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Stim_Onset_samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/cresp1el/Documents/lmc_project_analysis_dir/lmc_spikes_crespoetal2023/load_matfiles.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cresp1el/Documents/lmc_project_analysis_dir/lmc_spikes_crespoetal2023/load_matfiles.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m EED\u001b[39m.\u001b[39;49mconstruct_stimulus_table(\u001b[39m'\u001b[39;49m\u001b[39mlmc_ch_1_3094_rec1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/lmc_project_analysis_dir/lmc_spikes_crespoetal2023/Extract_ephys_from_struct.py:528\u001b[0m, in \u001b[0;36mExtractEphysData.construct_stimulus_table\u001b[0;34m(self, recording_name)\u001b[0m\n\u001b[1;32m    525\u001b[0m pre_stim_data \u001b[39m=\u001b[39m pre_data[unit_id]\n\u001b[1;32m    526\u001b[0m post_stim_data \u001b[39m=\u001b[39m post_data[unit_id]\n\u001b[0;32m--> 528\u001b[0m \u001b[39mfor\u001b[39;00m i, (onset, offset, intensity) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(pre_stim_data[\u001b[39m'\u001b[39;49m\u001b[39mStim_Onset_samples\u001b[39;49m\u001b[39m'\u001b[39;49m], pre_stim_data[\u001b[39m'\u001b[39m\u001b[39mStim_Offset_samples\u001b[39m\u001b[39m'\u001b[39m], pre_stim_data[\u001b[39m'\u001b[39m\u001b[39mStim_Intensity\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[1;32m    529\u001b[0m     trial_ids\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrial\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    530\u001b[0m     onsets\u001b[39m.\u001b[39mappend(onset)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Stim_Onset_samples'"
     ]
    }
   ],
   "source": [
    "EED.construct_stimulus_table('lmc_ch_1_3094_rec1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_data = EED.get_unit_level_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_names = EED.get_unit_data_keys('4bc09822d0832f7c00be68d2fb7a01dc')\n",
    "print(key_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_data_df = EED.get_unit_table()\n",
    "unit_data_df.head()# Print the first few rows of the DataFrame to check the output\n",
    "#check the shape of the dataframe\n",
    "unit_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the UnitDataAnalysis class with the unit data DataFrame\n",
    "analysis = UnitDataAnalysis(unit_data_df)\n",
    "analysis.convert_samples2seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access thhe data in the analysis class \n",
    "analysis.unit_data['Group'].unique() #get the unique values in the group column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.calculate_and_plot_firing_rate_matrix(bin_size=10)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = calculate_mean_responses(EED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.keys()) #these are the group names\n",
    "print(test['Lmc_opsin'].keys()) #these are the pre and post epoch names for each group\n",
    "print(test['Lmc_opsin']['Pre']) #these are the cell names for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `mean_responses_data` is the dictionary obtained from the calculate_mean_responses function\n",
    "plotter = ResponseDistributionPlotter(test)\n",
    "plotter.plot_distribution('Lmc_opsin', 'Pre', 'Pooled', bins=100, overlay=True, phase='early') \n",
    "plotter.plot_distribution('Lmc_opsin', 'Post', 'Pooled', bins=100, overlay=True, phase='early')\n",
    "\n",
    "# Assuming `mean_responses_data` is the dictionary obtained from the calculate_mean_responses function\n",
    "plotter = ResponseDistributionPlotter(test)\n",
    "plotter.plot_distribution('Lmc_opsin', 'Pre', 'Pooled', bins=100, overlay=True, phase='late') \n",
    "plotter.plot_distribution('Lmc_opsin', 'Post', 'Pooled', bins=100, overlay=True, phase='late')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter.plot_distribution('Lmc_opsin', epoch=None, stim_level='Zero', overlay=True)\n",
    "#plot the distribution for pre and post stim levels separately\n",
    "plotter.plot_distribution('Lmc_opsin', epoch='Pre', stim_level='Zero', overlay=True)\n",
    "plotter.plot_distribution('Lmc_opsin', epoch='Post', stim_level='Zero', overlay=True)\n",
    "\n",
    "# Plotting 'Pre' and 'Post' distributions on top of each other by setting overlay=True \n",
    "#loop over the 'Zero', 'Low', 'Mid', 'Max', or 'Pooled' stim levels to plot the distributions for each stim level\n",
    "for stim_level in ['Zero', 'Low', 'Mid', 'Max', 'Pooled']: \n",
    "    plotter.plot_distribution('Lmc_opsin', epoch=None, stim_level=stim_level, overlay=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the pre and post for the low separated \n",
    "plotter.plot_distribution('Lmc_opsin', epoch='Pre', stim_level='Low', bins=100)\n",
    "plotter.plot_distribution('Lmc_opsin', epoch='Post', stim_level='Low', bins=100)\n",
    "\n",
    "#plot the pre and post for the high separated\n",
    "plotter.plot_distribution('Lmc_opsin', epoch='Pre', stim_level='Max', bins=100)\n",
    "plotter.plot_distribution('Lmc_opsin', epoch='Post', stim_level='Max', bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_box_and_whisker(data, group_name, stim_levels=['Zero', 'Low', 'Mid', 'Max', 'Pooled'], epoch='both', overlay=False):\n",
    "    \"\"\"\n",
    "    Plots a box and whisker plot of the mean responses for the specified group and stimulation levels.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): The data dictionary containing the mean responses.\n",
    "    - group_name (str): The name of the group to plot data for.\n",
    "    - stim_levels (list or str): The stimulation levels to plot data for (e.g., ['Zero', 'Low', 'Mid', 'Max', 'Pooled'] or 'Zero'). Default is all levels.\n",
    "    - epoch (str): The epoch to plot data for ('Pre', 'Post', or 'both'). Default is 'both'.\n",
    "    - overlay (bool): Whether to overlay the 'Pre' and 'Post' data on a single plot. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(stim_levels, str):\n",
    "        stim_levels = [stim_levels]\n",
    "\n",
    "    # Get the mean responses for the specified group\n",
    "    group_data = data[group_name]\n",
    "\n",
    "    # Get the data to plot\n",
    "    data_to_plot = defaultdict(list)\n",
    "    epochs_to_plot = ['Pre', 'Post'] if epoch == 'both' else [epoch]\n",
    "    for epoch in epochs_to_plot:\n",
    "        for stim_level in stim_levels:\n",
    "            stim_data = [unit_data[f'{epoch}_{stim_level}'] for unit_data in group_data[epoch]]\n",
    "            data_to_plot[epoch].append(stim_data)\n",
    "\n",
    "    # Create a new figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Create a box plot for each epoch\n",
    "    colors = {'Pre': 'grey', 'Post': 'blue'}\n",
    "    for i, (epoch, stim_data) in enumerate(data_to_plot.items()):\n",
    "        position = range(i * (len(stim_levels) + 1) + 1, (i + 1) * (len(stim_levels) + 1))\n",
    "        bp = plt.boxplot(stim_data, positions=position, labels=stim_levels if i == 0 else [''] * len(stim_levels), patch_artist=True)\n",
    "        \n",
    "        # Set colors\n",
    "        for box in bp['boxes']:\n",
    "            box.set_facecolor(colors[epoch])\n",
    "        \n",
    "    # Set the plot title and labels\n",
    "    plt.title(f'{group_name} Mean Responses')\n",
    "    plt.ylabel('Mean Response')\n",
    "    plt.xlabel('Stimulation Level')\n",
    "    \n",
    "    # Adding epoch labels\n",
    "    if epoch == 'both':\n",
    "        mid_point = len(stim_levels) / 2\n",
    "        plt.text(mid_point, plt.gca().get_ylim()[1], 'Pre', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "        plt.text(len(stim_levels) + 1 + mid_point, plt.gca().get_ylim()[1], 'Post', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Show the plot\n",
    "    if not overlay:\n",
    "        plt.show()\n",
    "\n",
    "# Usage example:\n",
    "# Assuming `data_dict` is your data dictionary obtained from `calculate_mean_responses` function\n",
    "plot_box_and_whisker(test, 'Lmc_opsin', 'Zero', 'both')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_box_and_whisker(data, group_name, stim_levels=['Zero', 'Low', 'Mid', 'Max', 'Pooled'], epoch='both', overlay=False):\n",
    "    \"\"\"\n",
    "    Plots a box and whisker plot of the mean responses for the specified group and stimulation levels.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): The data dictionary containing the mean responses.\n",
    "    - group_name (str): The name of the group to plot data for.\n",
    "    - stim_levels (list or str): The stimulation levels to plot data for (e.g., ['Zero', 'Low', 'Mid', 'Max', 'Pooled'] or 'Zero'). Default is all levels.\n",
    "    - epoch (str): The epoch to plot data for ('Pre', 'Post', or 'both'). Default is 'both'.\n",
    "    - overlay (bool): Whether to overlay the 'Pre' and 'Post' data on a single plot. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(stim_levels, str):\n",
    "        stim_levels = [stim_levels]\n",
    "\n",
    "    # Get the mean responses for the specified group\n",
    "    group_data = data[group_name]\n",
    "\n",
    "    # Get the data to plot\n",
    "    data_to_plot = defaultdict(list)\n",
    "    epochs_to_plot = ['Pre', 'Post'] if epoch == 'both' else [epoch]\n",
    "    for epoch in epochs_to_plot:\n",
    "        for stim_level in stim_levels:\n",
    "            stim_data = [unit_data[f'{epoch}_{stim_level}'] for unit_data in group_data[epoch]]\n",
    "            data_to_plot[epoch].append(stim_data)\n",
    "\n",
    "    # Create a new figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Create a box plot for each epoch\n",
    "    colors = {'Pre': 'grey', 'Post': 'blue'}\n",
    "    for i, (epoch, stim_data) in enumerate(data_to_plot.items()):\n",
    "        position = range(i * (len(stim_levels) + 1) + 1, (i + 1) * (len(stim_levels) + 1))\n",
    "        labels = [f'{epoch}{level}' for level in stim_levels]\n",
    "        bp = plt.boxplot(stim_data, positions=position, labels=labels, patch_artist=True)\n",
    "        \n",
    "        # Set colors\n",
    "        for box in bp['boxes']:\n",
    "            box.set_facecolor(colors[epoch])\n",
    "        \n",
    "    # Set the plot title and labels\n",
    "    plt.title(f'{group_name} Mean Responses')\n",
    "    plt.ylabel('Mean Response')\n",
    "    plt.xlabel('Stimulation Level Epoch')\n",
    "    \n",
    "    # Show the plot\n",
    "    if not overlay:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "# Assuming `data_dict` is your data dictionary obtained from `calculate_mean_responses` function\n",
    "plot_box_and_whisker(test, 'Lmc_opsin', 'Max', 'both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_box_and_whisker(data, group_name, stim_levels=['Zero', 'Low', 'Mid', 'Max', 'Pooled'], epoch='both', overlay=False, plot_hist=False):\n",
    "    \"\"\"\n",
    "    Plots a box and whisker plot of the mean responses for the specified group and stimulation levels.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): The data dictionary containing the mean responses.\n",
    "    - group_name (str): The name of the group to plot data for.\n",
    "    - stim_levels (list or str): The stimulation levels to plot data for (e.g., ['Zero', 'Low', 'Mid', 'Max', 'Pooled'] or 'Zero'). Default is all levels.\n",
    "    - epoch (str): The epoch to plot data for ('Pre', 'Post', or 'both'). Default is 'both'.\n",
    "    - overlay (bool): Whether to overlay the 'Pre' and 'Post' data on a single plot. Default is False.\n",
    "    - plot_hist (bool): Whether to plot the histogram distribution. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(stim_levels, str):\n",
    "        stim_levels = [stim_levels]\n",
    "\n",
    "    # Get the mean responses for the specified group\n",
    "    group_data = data[group_name]\n",
    "\n",
    "    # Get the data to plot\n",
    "    data_to_plot = defaultdict(list)\n",
    "    epochs_to_plot = ['Pre', 'Post'] if epoch == 'both' else [epoch]\n",
    "    for epoch in epochs_to_plot:\n",
    "        for stim_level in stim_levels:\n",
    "            stim_data = [unit_data[f'{epoch}_{stim_level}'] for unit_data in group_data[epoch]]\n",
    "            data_to_plot[epoch].append(stim_data)\n",
    "\n",
    "    # Create a new figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Create a box plot for each epoch\n",
    "    colors = {'Pre': 'grey', 'Post': 'blue'}\n",
    "    for i, (epoch, stim_data) in enumerate(data_to_plot.items()):\n",
    "        position = range(i * (len(stim_levels) + 1) + 1, (i + 1) * (len(stim_levels) + 1))\n",
    "        labels = [f'{epoch}_{level}' for level in stim_levels]\n",
    "        bp = plt.boxplot(stim_data, positions=position, labels=labels, patch_artist=True)\n",
    "        \n",
    "        # Set colors\n",
    "        for box in bp['boxes']:\n",
    "            box.set_facecolor(colors[epoch])\n",
    "        \n",
    "    # Set the plot title and labels\n",
    "    plt.title(f'{group_name} Mean Responses')\n",
    "    plt.ylabel('Mean Response')\n",
    "    plt.xlabel('Stimulation Level Epoch')\n",
    "    \n",
    "    # Rotate x-axis labels for better visibility\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot the histogram distribution if specified\n",
    "    if plot_hist:\n",
    "        plt.figure()\n",
    "        for epoch in epochs_to_plot:\n",
    "            for stim_level in stim_levels:\n",
    "                stim_data = [unit_data[f'{epoch}_{stim_level}'] for unit_data in group_data[epoch]]\n",
    "                plt.hist(stim_data, alpha=0.5, label=f'{epoch}_{stim_level}', color=colors[epoch], histtype='step')\n",
    "        plt.xlabel('Mean Response')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'{group_name} Response Distributions')\n",
    "        plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    if not overlay:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# Assuming `data_dict` is your data dictionary obtained from `calculate_mean_responses` function\n",
    "plot_box_and_whisker(test, 'Lmc_opsin', 'Zero', 'both', plot_hist=True)\n",
    "\n",
    "# Assuming `data_dict` is your data dictionary obtained from your data processing\n",
    "plot_box_and_whisker(test, group_name='Lmc_opsin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic Usage with Default Parameters\n",
    "plot_box_and_whisker(test, group_name='Lmc_opsin')\n",
    "\n",
    "#Example 2: Plotting for a Single Epoch with Histograms\n",
    "plot_box_and_whisker(test, group_name='Lmc_opsin', epoch='Pre', plot_hist=True)\n",
    "\n",
    "#Example 3: Plotting for Specific Stimulation Levels \n",
    "plot_box_and_whisker(test, group_name='Lmc_opsin', stim_levels=['Zero', 'Max'], plot_hist=True)\n",
    "\n",
    "#Example 4: Overlaying 'Pre' and 'Post' Data on a Single Plot\n",
    "plot_box_and_whisker(test, group_name='Lmc_opsin', overlay=True)\n",
    "\n",
    "# Example 5: Plotting for a Single Stimulation Level\n",
    "plot_box_and_whisker(test, group_name='Lmc_opsin', stim_levels='Zero', plot_hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_regression(data, stimulation='Pooled', overlay=True, log_scale=False):\n",
    "    \n",
    "    pre_early = []\n",
    "    pre_late = []\n",
    "    post_early = []\n",
    "    post_late = []\n",
    "\n",
    "    for group in data.values():\n",
    "        for epoch_data in group.values():\n",
    "            for record in epoch_data:\n",
    "                pre_early.append(record[f'Pre_{stimulation}_early'])\n",
    "                pre_late.append(record[f'Pre_{stimulation}_late'])\n",
    "                post_early.append(record[f'Post_{stimulation}_early'])\n",
    "                post_late.append(record[f'Post_{stimulation}_late'])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2 if not overlay else 1, figsize=(10, 5))\n",
    "\n",
    "    if log_scale:\n",
    "        pre_early = [np.log(x+1) for x in pre_early]\n",
    "        pre_late = [np.log(x+1) for x in pre_late]\n",
    "        post_early = [np.log(x+1) for x in post_early]\n",
    "        post_late = [np.log(x+1) for x in post_late]\n",
    "\n",
    "    if overlay:\n",
    "        ax.scatter(pre_early, pre_late, color='grey', alpha=0.5, label='Pre')\n",
    "        ax.scatter(post_early, post_late, color='blue', alpha=0.5, label='Post')\n",
    "        \n",
    "        # Adding simple linear regression lines\n",
    "        slope, intercept, _, _, _ = stats.linregress(pre_early, pre_late)\n",
    "        ax.plot(pre_early, np.array(pre_early)*slope + intercept, color='grey')\n",
    "        \n",
    "        slope, intercept, _, _, _ = stats.linregress(post_early, post_late)\n",
    "        ax.plot(post_early, np.array(post_early)*slope + intercept, color='blue')\n",
    "        \n",
    "        ax.set_xlabel('Early Phase')\n",
    "        ax.set_ylabel('Late Phase')\n",
    "    else:\n",
    "        ax[0].scatter(pre_early, pre_late, color='grey', alpha=0.5, label='Pre')\n",
    "        ax[1].scatter(post_early, post_late, color='blue', alpha=0.5, label='Post')\n",
    "        \n",
    "        # Adding simple linear regression lines\n",
    "        slope, intercept, _, _, _ = stats.linregress(pre_early, pre_late)\n",
    "        ax[0].plot(pre_early, np.array(pre_early)*slope + intercept, color='grey')\n",
    "        \n",
    "        slope, intercept, _, _, _ = stats.linregress(post_early, post_late)\n",
    "        ax[1].plot(post_early, np.array(post_early)*slope + intercept, color='blue')\n",
    "        \n",
    "        ax[0].set_xlabel('Early Phase')\n",
    "        ax[0].set_ylabel('Late Phase')\n",
    "        ax[1].set_xlabel('Early Phase')\n",
    "        ax[1].set_ylabel('Late Phase')\n",
    "        \n",
    "        ax[0].legend()\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example commands to test the function\n",
    "# Replace 'test' with your actual data dictionary\n",
    "plot_regression(test, stimulation='Pooled', overlay=True, log_scale=True)\n",
    "plot_regression(test, stimulation='Pooled', overlay=False, log_scale=True)\n",
    "plot_regression(test, stimulation='Low', overlay=True, log_scale=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test['Lmc_opsin']['Pre'])) #prints the type of the data\n",
    "print(len(test['Lmc_opsin']['Pre'])) #print the number of units in the pre epoch of the Lmc_opsin group\n",
    "print(test['Lmc_opsin']['Pre'][0].keys()) #print the keys of the first element in the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test['Lmc_opsin']['Pre'])) #prints the type of the data\n",
    "print(len(test['Lmc_opsin']['Pre'])) #print the number of units in the pre epoch of the Lmc_opsin group\n",
    "print(test['Lmc_opsin']['Pre'][0].keys()) #print the keys of the first element in the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def calculate_pearson_correlations(EED, group_name=None):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson correlation coefficients using the individual trial responses from both the early and late windows during both the pre and post epochs for each unit.\n",
    "\n",
    "    Parameters:\n",
    "    EED (object): The object containing the electrophysiology data.\n",
    "    group_name (str, optional): The name of the group to analyze. Defaults to None, in which case all groups are analyzed.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the Pearson correlation coefficients for each unit.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get list of group names\n",
    "    group_names = [group_name] if group_name else EED.group_names\n",
    "    \n",
    "    # Dictionary to store the Pearson correlation coefficients for each group\n",
    "    pearson_correlations = {}\n",
    "    \n",
    "    # Loop through each group\n",
    "    for group in group_names:\n",
    "        recording_names = EED.get_recording_names(group)\n",
    "        \n",
    "        # Dictionary to store the Pearson correlation coefficients for all units in the current group\n",
    "        group_pearson_correlations = {'Pre': [], 'Post': []}\n",
    "        \n",
    "        # Loop through each recording\n",
    "        for recording in recording_names:\n",
    "            cellid_names = EED.get_cellid_names(group, recording)\n",
    "            \n",
    "            # Loop through each cell ID\n",
    "            for cell_id in cellid_names:\n",
    "                # Get the pre and post stim data\n",
    "                data = EED.get_pre_post_data(group, recording, cell_id)\n",
    "                \n",
    "                # Define stimulation levels and pooled stimulation levels\n",
    "                stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "                \n",
    "                # Dictionary to store the Pearson correlation coefficients for the current unit\n",
    "                unit_pearson_correlations = {'Recording': recording, 'CellID': cell_id}\n",
    "                \n",
    "                # Loop through each epoch (pre and post) and stimulation level to calculate Pearson correlation coefficients\n",
    "                for epoch in ['Pre', 'Post']: #loop through the pre and post epochs\n",
    "                    for stim_level in stim_levels: #loop through the stim levels\n",
    "                        if stim_level == 'Pooled': #if the stim level is pooled, then use all stim levels\n",
    "                            stim_indices = [1, 2, 3] #indices for the stim levels\n",
    "                        else: #otherwise, use the stim level specified\n",
    "                            stim_indices = [stim_levels.index(stim_level)] #create a list with the index of the stim level\n",
    "                        \n",
    "                        # Get spike trains for the current stimulation level\n",
    "                        spiketrains = np.concatenate([data[epoch]['SpikeTrains_for_PSTHs'][i] for i in stim_indices], axis=0) #list comprehension to get the spike trains for the stim level by looping through the stim indices\n",
    "                        \n",
    "                        # Extract spike data for the early phase (0-50 ms post-stimulus)\n",
    "                        early_phase = spiketrains[:, 500:550]  # Adjust indices as necessary\n",
    "                        \n",
    "                        # Extract spike data for the late phase (100-700 ms post-stimulus)\n",
    "                        late_phase = spiketrains[:, 600:1200]  # Adjust indices as necessary\n",
    "                        \n",
    "                        # Calculate the total number of spikes in each trial during the early and late phases\n",
    "                        early_response = early_phase.sum(axis=1) #sum across the rows which are the trials for the early phase\n",
    "                        late_response = late_phase.sum(axis=1) #sum across the rows which are the trials for the late phase\n",
    "                        \n",
    "                        # Calculate the Pearson correlation coefficient for the early and late responses\n",
    "                        corr, _ = stats.pearsonr(early_response, late_response)\n",
    "                        \n",
    "                        # Add the Pearson correlation coefficient to the dictionary\n",
    "                        unit_pearson_correlations[f'{epoch}_{stim_level}_Pearson_Correlation'] = corr\n",
    "                \n",
    "                # Calculate the difference between post and pre Pearson correlation coefficients for each stimulation level\n",
    "                for stim_level in stim_levels:\n",
    "                    pre_corr = unit_pearson_correlations[f'Pre_{stim_level}_Pearson_Correlation']\n",
    "                    post_corr = unit_pearson_correlations[f'Post_{stim_level}_Pearson_Correlation']\n",
    "                    unit_pearson_correlations[f'{stim_level}_Correlation_Difference'] = post_corr - pre_corr\n",
    "                \n",
    "                # Add the Pearson correlation coefficients for the current unit to the list\n",
    "                group_pearson_correlations['Pre'].append(unit_pearson_correlations)\n",
    "                group_pearson_correlations['Post'].append(unit_pearson_correlations)\n",
    "        \n",
    "        # Add the Pearson correlation coefficients for the current group to the dictionary\n",
    "        pearson_correlations[group] = group_pearson_correlations\n",
    "    \n",
    "    return pearson_correlations\n",
    "\n",
    "\n",
    "# use the function\n",
    "pearson_correlations = calculate_pearson_correlations(EED, group_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_correlations.keys() #prints the keys of the dictionary\n",
    "pearson_correlations['Lmc_opsin'].keys() \n",
    "pearson_correlations['Lmc_opsin']['Pre'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(pearson_correlations.values())[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "def plot_correlation_differences(correlation_data, stimulation_level):\n",
    "    \"\"\"\n",
    "    Plot the correlation differences for all units, ranked from least to most, for a specified stimulation level.\n",
    "\n",
    "    Parameters:\n",
    "    correlation_data (dict): The dictionary containing the Pearson correlation data for each unit.\n",
    "    stimulation_level (str): The stimulation level to plot (one of 'Zero', 'Low', 'Mid', 'Max', 'Pooled').\n",
    "\n",
    "    Returns:\n",
    "    None: The function will plot the data but not return any values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop through each group in the correlation data\n",
    "    for group_name, group_data in correlation_data.items():\n",
    "        \n",
    "        # List to store all units and their correlation differences\n",
    "        all_units_correlation_differences = []\n",
    "\n",
    "        # Loop through each unit in the 'Pre' epoch to get its correlation difference for the specified stimulation level\n",
    "        for unit in group_data['Pre']:\n",
    "            # Get the correlation difference for the current unit and the specified stimulation level\n",
    "            correlation_difference = unit.get(f'{stimulation_level}_Correlation_Difference') # Returns None if the key doesn't exist\n",
    "            \n",
    "            # Skip units with invalid correlation differences\n",
    "            if correlation_difference is None or np.isnan(correlation_difference):\n",
    "                continue\n",
    "            \n",
    "            # Get the cell ID for the current unit\n",
    "            cell_id = unit['CellID']\n",
    "            \n",
    "            # Add the unit's cell ID and correlation difference to the list\n",
    "            all_units_correlation_differences.append((cell_id, correlation_difference))\n",
    "        \n",
    "        # Print the list of units and their correlation differences\n",
    "        print(all_units_correlation_differences)  \n",
    "\n",
    "        # Sort the units by their correlation differences from least to most\n",
    "        sorted_units = sorted(all_units_correlation_differences, key=lambda x: x[1])\n",
    "        \n",
    "        # Get the cell IDs and correlation differences as separate lists\n",
    "        cell_ids, correlation_differences = zip(*sorted_units)\n",
    "        \n",
    "        # Create a bar plot of the correlation differences\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create a colormap for the bar colors\n",
    "        norm = mcolors.Normalize(vmin=-1, vmax=1)\n",
    "        cmap = plt.cm.get_cmap('coolwarm')\n",
    "        \n",
    "        # Create a bar plot with colors based on the correlation differences\n",
    "        plt.bar(range(len(correlation_differences)), correlation_differences, tick_label=cell_ids, color=cmap(norm(correlation_differences)))\n",
    "        \n",
    "        # Add a colorbar to the plot\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        plt.colorbar(sm, label='Correlation Difference')\n",
    "        \n",
    "        # Add labels and title to the plot\n",
    "        plt.xlabel('Cell ID')\n",
    "        plt.ylabel('Correlation Difference')\n",
    "        plt.title(f'Correlation Differences for {stimulation_level} Stimulation in {group_name} group')\n",
    "        \n",
    "        # Rotate the x-axis labels for better readability\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_correlation_differences(pearson_correlations, 'Mid')\n",
    "\n",
    "#loop over the stimulation levels\n",
    "for stimulation_level in ['Zero', 'Low', 'Mid', 'Max', 'Pooled']:\n",
    "    plot_correlation_differences(pearson_correlations, stimulation_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def calculate_global_pearson_correlations(EED, group_name=None):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson correlation coefficients using the mean responses from both the early and late windows during both the pre and post epochs for each unit.\n",
    "\n",
    "    Parameters:\n",
    "    EED (object): The object containing the electrophysiology data.\n",
    "    group_name (str, optional): The name of the group to analyze. Defaults to None, in which case all groups are analyzed.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the Pearson correlation coefficients for each unit.\n",
    "    \"\"\"\n",
    "    \n",
    "    group_names = [group_name] if group_name else EED.group_names\n",
    "    \n",
    "    detailed_data = {}\n",
    "    \n",
    "    for group in group_names:\n",
    "        recording_names = EED.get_recording_names(group)\n",
    "        \n",
    "        for recording in recording_names:\n",
    "            cellid_names = EED.get_cellid_names(group, recording)\n",
    "            \n",
    "            for cell_id in cellid_names:\n",
    "                data = EED.get_pre_post_data(group, recording, cell_id)\n",
    "                \n",
    "                stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "                \n",
    "                for epoch in ['Pre', 'Post']:\n",
    "                    for stim_level in stim_levels:\n",
    "                        if stim_level == 'Pooled':\n",
    "                            stim_indices = [1, 2, 3]\n",
    "                        else:\n",
    "                            stim_indices = [stim_levels.index(stim_level)]\n",
    "                        \n",
    "                        spiketrains = np.concatenate([data[epoch]['SpikeTrains_for_PSTHs'][i] for i in stim_indices], axis=0)\n",
    "                        \n",
    "                        early_phase = spiketrains[:, 500:550]\n",
    "                        late_phase = spiketrains[:, 600:1200]\n",
    "                        \n",
    "                        early_response = early_phase.sum(axis=1) / early_phase.shape[1]\n",
    "                        late_response = late_phase.sum(axis=1) / late_phase.shape[1]\n",
    "                        \n",
    "                        early_mean = early_response.mean()\n",
    "                        late_mean = late_response.mean()\n",
    "                        \n",
    "                        detailed_data.setdefault(group, {}).setdefault(recording, {}).setdefault(cell_id, {}).setdefault(epoch, {}).setdefault(stim_level, {\n",
    "                            'early_phase': early_phase,\n",
    "                            'late_phase': late_phase,\n",
    "                            'early_response': early_response,\n",
    "                            'late_response': late_response,\n",
    "                            'early_mean': early_mean,\n",
    "                            'late_mean': late_mean\n",
    "                        })\n",
    "    \n",
    "    return detailed_data\n",
    "\n",
    "# use the function\n",
    "# detailed_data = calculate_global_pearson_correlations(EED, group_name=None)\n",
    "\n",
    "\n",
    "# use the function\n",
    "pearson_correlations_global = calculate_global_pearson_correlations(EED, group_name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_correlations_global.keys() #prints the keys of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def calculate_pearson_correlations(EED, detailed_data):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson correlation coefficients using the mean responses from the detailed data.\n",
    "\n",
    "    Parameters:\n",
    "    EED (object): The object containing the electrophysiology data.\n",
    "    detailed_data (dict): The dictionary containing the detailed data including early and late mean responses.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the Pearson correlation coefficients for each stimulation level and epoch.\n",
    "    dict: A dictionary containing the cell IDs that were removed due to NaN values.\n",
    "    \"\"\"\n",
    "\n",
    "    pearson_correlations = {}\n",
    "    removed_cell_ids = {}\n",
    "\n",
    "    # Get list of group names\n",
    "    group_names = EED.group_names\n",
    "\n",
    "    # Define stimulation levels\n",
    "    stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "\n",
    "    # Loop through each group\n",
    "    for group in group_names:\n",
    "        group_correlations = {}\n",
    "\n",
    "        # Loop through each epoch (pre and post) and stimulation level to calculate Pearson correlation coefficients\n",
    "        for epoch in ['Pre', 'Post']: \n",
    "            for stim_level in stim_levels: \n",
    "\n",
    "                # Pool early and late means from all units for the current group, epoch, and stimulation level\n",
    "                early_means = []\n",
    "                late_means = []\n",
    "\n",
    "                recording_names = EED.get_recording_names(group)\n",
    "                for recording in recording_names:\n",
    "                    cellid_names = EED.get_cellid_names(group, recording)\n",
    "                    for cell_id in cellid_names:\n",
    "                        early_mean = detailed_data[group][recording][cell_id][epoch][stim_level]['early_mean']\n",
    "                        late_mean = detailed_data[group][recording][cell_id][epoch][stim_level]['late_mean']\n",
    "\n",
    "                        if not np.isnan(early_mean) and not np.isnan(late_mean):\n",
    "                            early_means.append(early_mean)\n",
    "                            late_means.append(late_mean)\n",
    "                        else:\n",
    "                            removed_cell_ids.setdefault(group, {}).setdefault(recording, {}).setdefault(epoch, {}).setdefault(stim_level, []).append(cell_id)\n",
    "\n",
    "                # Calculate the Pearson correlation coefficient\n",
    "                if early_means and late_means:  # Ensure the lists are not empty\n",
    "                    corr, _ = stats.pearsonr(early_means, late_means)\n",
    "                else:\n",
    "                    corr = None\n",
    "\n",
    "                # Store the Pearson correlation coefficient in the dictionary\n",
    "                group_correlations.setdefault(epoch, {}).setdefault(stim_level, corr)\n",
    "\n",
    "        # Add the Pearson correlation coefficients for the current group to the dictionary\n",
    "        pearson_correlations[group] = group_correlations\n",
    "\n",
    "    return pearson_correlations, removed_cell_ids\n",
    "\n",
    "# Use the function\n",
    "pearson_correlations, removed_cell_ids = calculate_pearson_correlations(EED, pearson_correlations_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_correlations['Lmc_opsin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def individual_unit_analysis(EED, group_name=None):\n",
    "    \"\"\"\n",
    "    Perform a comprehensive individual unit analysis including descriptive statistics, \n",
    "    time series analysis, correlation analysis, visualization, response profiling, \n",
    "    and outlier identification.\n",
    "\n",
    "    Parameters:\n",
    "    EED (object): The object containing the electrophysiology data.\n",
    "    group_name (str, optional): The name of the group to analyze. Defaults to None, in which case all groups are analyzed.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the results of all the analyses for each unit.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get list of group names\n",
    "    group_names = [group_name] if group_name else EED.group_names\n",
    "    \n",
    "    # Dictionary to store the analysis results for each group\n",
    "    analysis_results = {}\n",
    "    \n",
    "    # Loop through each group\n",
    "    for group in group_names:\n",
    "        recording_names = EED.get_recording_names(group)\n",
    "        \n",
    "        # Dictionary to store the analysis results for all units in the current group\n",
    "        group_analysis_results = {}\n",
    "        \n",
    "        # Loop through each recording\n",
    "        for recording in recording_names:\n",
    "            cellid_names = EED.get_cellid_names(group, recording)\n",
    "            \n",
    "            # Loop through each cell ID\n",
    "            for cell_id in cellid_names:\n",
    "                # Get the pre and post stim data\n",
    "                data = EED.get_pre_post_data(group, recording, cell_id)\n",
    "                \n",
    "                # Define stimulation levels and pooled stimulation levels\n",
    "                stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "                \n",
    "                # Dictionary to store the analysis results for the current unit\n",
    "                unit_analysis_results = {'Recording': recording, 'CellID': cell_id}\n",
    "                \n",
    "                # Loop through each epoch (pre and post) and stimulation level to calculate descriptive statistics\n",
    "                for epoch in ['Pre', 'Post']: #loop through the pre and post epochs\n",
    "                    for stim_level in stim_levels: #loop through the stim levels\n",
    "                        if stim_level == 'Pooled': #if the stim level is pooled, then use all stim levels\n",
    "                            stim_indices = [1, 2, 3] #indices for the stim levels\n",
    "                        else: #otherwise, use the stim level specified\n",
    "                            stim_indices = [stim_levels.index(stim_level)] #create a list with the index of the stim level\n",
    "                        \n",
    "                        # Get spike trains for the current stimulation level\n",
    "                        spiketrains = np.concatenate([data[epoch]['SpikeTrains_for_PSTHs'][i] for i in stim_indices], axis=0) #list comprehension to get the spike trains for the stim level by looping through the stim indices\n",
    "                        \n",
    "                        # Extract spike data for the early phase (0-50 ms post-stimulus)\n",
    "                        early_phase = spiketrains[:, 500:550]  # Adjust indices as necessary\n",
    "                        \n",
    "                        # Extract spike data for the late phase (100-700 ms post-stimulus)\n",
    "                        late_phase = spiketrains[:, 600:1200]  # Adjust indices as necessary\n",
    "                        \n",
    "                        # Calculate the total number of spikes in each trial during the early and late phases\n",
    "                        early_response = early_phase.sum(axis=1) / early_phase.shape[0] # Normalize by the number of trials which is the number of rows\n",
    "                        late_response = late_phase.sum(axis=1) / late_phase.shape[0] # Normalize by the number of trials which is the number of rows\n",
    "                        \n",
    "                        # Calculate descriptive statistics\n",
    "                        early_mean = np.mean(early_response)\n",
    "                        late_mean = np.mean(late_response)\n",
    "                        early_median = np.median(early_response)\n",
    "                        late_median = np.median(late_response)\n",
    "                        early_std = np.std(early_response)\n",
    "                        late_std = np.std(late_response) \n",
    "                        \n",
    "                        # Calculate the mean of the standard deviations across trials\n",
    "                        mean_std_early = np.mean(np.std(early_phase, axis=1))\n",
    "                        mean_std_late = np.mean(np.std(late_phase, axis=1))\n",
    "                        \n",
    "                        # Step 2: Time Series Analysis\n",
    "                        # Calculate the autocorrelation of the early and late responses\n",
    "                        early_autocorr = np.correlate(early_response, early_response, mode='full')\n",
    "                        late_autocorr = np.correlate(late_response, late_response, mode='full')\n",
    "                        \n",
    "                        # Step 3: Correlation Analysis\n",
    "                        # Calculate the Pearson correlation coefficient between the early and late responses\n",
    "                        corr, p_value = stats.pearsonr(early_response, late_response)\n",
    "\n",
    "                        # Step 5: Creating Response Profiles\n",
    "                        # Calculate the difference between the mean responses in the early and late phases\n",
    "                        mean_response_difference = late_mean - early_mean\n",
    "                        # Calculate the fold change relative to the early mean\n",
    "                        fold_change = late_mean / early_mean if early_mean != 0 else np.nan\n",
    "                        \n",
    " \n",
    "                        # Store the data and descriptive statistics in the dictionary\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_early_phase'] = early_phase\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_late_phase'] = late_phase\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_early_response'] = early_response\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_late_response'] = late_response\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_early_mean'] = early_mean\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_late_mean'] = late_mean\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_early_median'] = early_median\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_late_median'] = late_median\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_early_std'] = early_std\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_late_std'] = late_std\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_mean_std_early'] = mean_std_early\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_mean_std_late'] = mean_std_late\n",
    "                        \n",
    "                        # Store the autocorrelation data in the dictionary\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_early_autocorr'] = early_autocorr\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_late_autocorr'] = late_autocorr\n",
    "                        \n",
    "                        # Store the Pearson correlation coefficient and the p-value in the dictionary\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_Pearson_Correlation'] = corr\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_P_value'] = p_value\n",
    "                        \n",
    "                        # Store the response profile metrics in the dictionary\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_mean_response_difference'] = mean_response_difference\n",
    "                        unit_analysis_results[f'{epoch}_{stim_level}_fold_change'] = fold_change\n",
    "                        \n",
    "                # Add the analysis results for the current unit to the dictionary\n",
    "                group_analysis_results[cell_id] = unit_analysis_results\n",
    "        \n",
    "        # Add the analysis results for the current group to the dictionary\n",
    "        analysis_results[group] = group_analysis_results\n",
    "        \n",
    "    # Convert the nested dictionary to a pandas DataFrame for easy data manipulation and visualization\n",
    "    analysis_results_df = pd.DataFrame.from_dict({(group_name, cell_id): analysis_results[group_name][cell_id] \n",
    "                                                  for group_name in analysis_results.keys() \n",
    "                                                  for cell_id in analysis_results[group_name].keys()},\n",
    "                                                 orient='index')\n",
    "\n",
    "    return  analysis_results, analysis_results_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "individual_unit_analysis_output, individual_unit_analysis_df_output = individual_unit_analysis(EED, group_name=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_unit_analysis_df_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Low_early_autocorr']\n",
    "\n",
    "#now plot this data individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Low_early_autocorr']\n",
    "plt.plot(individual_unit_analysis_output['Lmc_opsin']['cid93']['Post_Low_early_autocorr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Low_Pearson_Correlation']\n",
    "#now look at mid \n",
    "individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Mid_Pearson_Correlation']\n",
    "#now look at max\n",
    "individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Max_Pearson_Correlation'] \n",
    "#now look at zero\n",
    "individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Zero_Pearson_Correlation']\n",
    "\n",
    "#repeat this process for cid102 and print the pearson correlation coefficients for each stimulation level\n",
    "print(individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Zero_Pearson_Correlation'])\n",
    "print(individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Low_Pearson_Correlation'])\n",
    "print(individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Mid_Pearson_Correlation'])\n",
    "print(individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Max_Pearson_Correlation'])\n",
    "\n",
    "#now print the mean for cid 102 for each stimulation level \n",
    "print(individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Zero_late_mean'])\n",
    "print(individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Low_late_mean'])\n",
    "print(individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Mid_late_mean'])\n",
    "print(individual_unit_analysis_output['Lmc_opsin']['cid102']['Post_Max_late_mean'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "class NeuralDataAnalysis:\n",
    "    def __init__(self, EED, group_name=None, early_phase_indices=(500, 550), late_phase_indices=(600, 1200)):\n",
    "        self.EED = EED\n",
    "        self.group_name = group_name\n",
    "        self.early_phase_indices = early_phase_indices\n",
    "        self.late_phase_indices = late_phase_indices\n",
    "        self.analysis_results = None\n",
    "        self.analysis_df = None\n",
    "        \n",
    "    def individual_unit_analysis(self, early_phase_indices=(500, 550), late_phase_indices=(600, 1200)):\n",
    "        \"\"\"\n",
    "        Perform a comprehensive individual unit analysis including descriptive statistics, \n",
    "        time series analysis, correlation analysis, visualization, response profiling, \n",
    "        and outlier identification.\n",
    "\n",
    "        Parameters:\n",
    "        EED (object): The object containing the electrophysiology data.\n",
    "        group_name (str, optional): The name of the group to analyze. Defaults to None, in which case all groups are analyzed.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary containing the results of all the analyses for each unit.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get list of group names\n",
    "        group_names = [self.group_name] if self.group_name else self.EED.group_names\n",
    "        \n",
    "        # Dictionary to store the analysis results for each group\n",
    "        analysis_results = {}\n",
    "        \n",
    "        # Loop through each group\n",
    "        for group in group_names:\n",
    "            recording_names = EED.get_recording_names(group)\n",
    "            \n",
    "            # Dictionary to store the analysis results for all units in the current group\n",
    "            group_analysis_results = {}\n",
    "            \n",
    "            # Loop through each recording\n",
    "            for recording in recording_names:\n",
    "                cellid_names = EED.get_cellid_names(group, recording)\n",
    "                \n",
    "                # Loop through each cell ID\n",
    "                for cell_id in cellid_names:\n",
    "                    # Get the pre and post stim data\n",
    "                    data = EED.get_pre_post_data(group, recording, cell_id)\n",
    "                    \n",
    "                    # Define stimulation levels and pooled stimulation levels\n",
    "                    stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "                    \n",
    "                    # Dictionary to store the analysis results for the current unit\n",
    "                    unit_analysis_results = {'Recording': recording, 'CellID': cell_id}\n",
    "                    \n",
    "                    # Loop through each epoch (pre and post) and stimulation level to calculate descriptive statistics\n",
    "                    for epoch in ['Pre', 'Post']: #loop through the pre and post epochs\n",
    "                        for stim_level in stim_levels: #loop through the stim levels\n",
    "                            if stim_level == 'Pooled': #if the stim level is pooled, then use all stim levels\n",
    "                                stim_indices = [1, 2, 3] #indices for the stim levels\n",
    "                            else: #otherwise, use the stim level specified\n",
    "                                stim_indices = [stim_levels.index(stim_level)] #create a list with the index of the stim level\n",
    "                            \n",
    "                            # Get spike trains for the current stimulation level\n",
    "                            spiketrains = np.concatenate([data[epoch]['SpikeTrains_for_PSTHs'][i] for i in stim_indices], axis=0) #list comprehension to get the spike trains for the stim level by looping through the stim indices\n",
    "                            \n",
    "                            # Store the spike trains in the dictionary\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_spiketrains'] = spiketrains\n",
    "                            \n",
    "                            # Extract spike data for the early and late phases using the provided indices\n",
    "                            early_phase = spiketrains[:, early_phase_indices[0]:early_phase_indices[1]]\n",
    "                            late_phase = spiketrains[:, late_phase_indices[0]:late_phase_indices[1]]\n",
    "                            \n",
    "                            # Calculate the total number of spikes in each trial during the early and late phases\n",
    "                            early_response = early_phase.sum(axis=1) / early_phase.shape[0] # Normalize by the number of trials which is the number of rows\n",
    "                            late_response = late_phase.sum(axis=1) / late_phase.shape[0] # Normalize by the number of trials which is the number of rows\n",
    "                            \n",
    "                            # Calculate descriptive statistics\n",
    "                            early_mean = np.mean(early_response)\n",
    "                            late_mean = np.mean(late_response)\n",
    "                            early_median = np.median(early_response)\n",
    "                            late_median = np.median(late_response)\n",
    "                            early_std = np.std(early_response)\n",
    "                            late_std = np.std(late_response) \n",
    "                            \n",
    "                            # Calculate the mean of the standard deviations across trials\n",
    "                            mean_std_early = np.mean(np.std(early_phase, axis=1))\n",
    "                            mean_std_late = np.mean(np.std(late_phase, axis=1))\n",
    "                            \n",
    "                            # Step 2: Time Series Analysis\n",
    "                            # Calculate the autocorrelation of the early and late responses\n",
    "                            early_autocorr = np.correlate(early_response, early_response, mode='full')\n",
    "                            late_autocorr = np.correlate(late_response, late_response, mode='full')\n",
    "                            \n",
    "                            # Step 3: Correlation Analysis\n",
    "                            # Calculate the Pearson correlation coefficient between the early and late responses\n",
    "                            corr, p_value = stats.pearsonr(early_response, late_response)\n",
    "\n",
    "                            # Step 5: Creating Response Profiles\n",
    "                            # Calculate the difference between the mean responses in the early and late phases\n",
    "                            mean_response_difference = late_mean - early_mean\n",
    "                            \n",
    "                            # Calculate the fold change relative to the early mean\n",
    "                            fold_change = late_mean / early_mean if early_mean != 0 else np.nan\n",
    "                            \n",
    "                            # Calculate the fold change and percent change using the early window of the pre-epoch to normalize the late window of the post-epoch\n",
    "                            if epoch == 'Post':\n",
    "                                pre_epoch_early_mean = unit_analysis_results[f'Pre_{stim_level}_early_mean']\n",
    "                                fold_change_normalized = late_mean / pre_epoch_early_mean if pre_epoch_early_mean != 0 else np.nan\n",
    "                                unit_analysis_results[f'{epoch}_{stim_level}_fold_change_normalized'] = fold_change_normalized\n",
    "                                percent_change_normalized = ((late_mean - pre_epoch_early_mean) / pre_epoch_early_mean) * 100 if pre_epoch_early_mean != 0 else np.nan\n",
    "                                unit_analysis_results[f'{epoch}_{stim_level}_percent_change_normalized'] = percent_change_normalized\n",
    "\n",
    "                            \n",
    "    \n",
    "                            # Store the data and descriptive statistics in the dictionary\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_early_phase'] = early_phase\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_late_phase'] = late_phase\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_early_response'] = early_response\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_late_response'] = late_response\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_early_mean'] = early_mean\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_late_mean'] = late_mean\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_early_median'] = early_median\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_late_median'] = late_median\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_early_std'] = early_std\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_late_std'] = late_std\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_mean_std_early'] = mean_std_early\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_mean_std_late'] = mean_std_late\n",
    "                            \n",
    "                            # Store the autocorrelation data in the dictionary\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_early_autocorr'] = early_autocorr\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_late_autocorr'] = late_autocorr\n",
    "                            \n",
    "                            # Store the Pearson correlation coefficient and the p-value in the dictionary\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_Pearson_Correlation'] = corr\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_P_value'] = p_value\n",
    "                            \n",
    "                            # Store the response profile metrics in the dictionary\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_mean_response_difference'] = mean_response_difference\n",
    "                            unit_analysis_results[f'{epoch}_{stim_level}_fold_change'] = fold_change\n",
    "                            \n",
    "                    # Add the analysis results for the current unit to the dictionary\n",
    "                    group_analysis_results[cell_id] = unit_analysis_results\n",
    "            \n",
    "            # Add the analysis results for the current group to the dictionary\n",
    "            analysis_results[group] = group_analysis_results\n",
    "            \n",
    "        # Convert the nested dictionary to a pandas DataFrame for easy data manipulation and visualization\n",
    "        analysis_results_df = pd.DataFrame.from_dict({(group_name, cell_id): analysis_results[group_name][cell_id] \n",
    "                                                    for group_name in analysis_results.keys() \n",
    "                                                    for cell_id in analysis_results[group_name].keys()},\n",
    "                                                    orient='index')\n",
    "\n",
    "\n",
    "        # Set the analysis_results attribute with the results dictionary\n",
    "        self.analysis_results = analysis_results\n",
    "        self.analysis_df = analysis_results_df\n",
    "        \n",
    "        # Return the DataFrame for inspection\n",
    "        return analysis_results_df, analysis_results\n",
    "\n",
    "    def rank_units_by_metric(self, group_name, column_name, ascending=True):\n",
    "        \"\"\"\n",
    "        Rank units within a specified group based on a specified metric (e.g., Pearson correlation, fold change).\n",
    "\n",
    "        Parameters:\n",
    "        group_name (str): The name of the group to rank the units for.\n",
    "        column_name (str): The name of the column (metric) to base the rankings on.\n",
    "        ascending (bool): Whether to rank in ascending order. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame containing the unit IDs and their respective rankings.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        group_data = self.analysis_df.loc[group_name].copy()\n",
    "        \n",
    "        # Rank the units based on the specified column\n",
    "        group_data['Rank'] = group_data[column_name].rank(ascending=ascending)\n",
    "        \n",
    "        # Get a DataFrame with only the Cell IDs and their rankings\n",
    "        ranking_df = group_data[['CellID', 'Rank']]\n",
    "        \n",
    "        return ranking_df \n",
    "\n",
    "\n",
    "\n",
    "    def plot_ranked_units(self, group_name, column_name, ascending=True):\n",
    "        \"\"\"\n",
    "        Plot the ranked units within a specified group based on a specified metric (e.g., Pearson correlation, fold change).\n",
    "\n",
    "        Parameters:\n",
    "        group_name (str): The name of the group to rank the units for.\n",
    "        column_name (str): The name of the column (metric) to base the rankings on.\n",
    "        ascending (bool): Whether to rank in ascending order. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "        None: The function will plot the data but not return any values.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the ranking data\n",
    "        ranking_df = self.rank_units_by_metric(group_name, column_name, ascending)\n",
    "        \n",
    "        # Get the data to plot\n",
    "        group_data = self.analysis_df.loc[group_name]\n",
    "        \n",
    "        # Merge the ranking data with the group data to get the values for the specified column\n",
    "        plot_data = group_data.merge(ranking_df, on='CellID')\n",
    "        \n",
    "        # Sort the data based on the rank\n",
    "        plot_data.sort_values(by='Rank', inplace=True)\n",
    "        \n",
    "        # Get a colormap\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "        \n",
    "        # Get the range of data values to set the color range\n",
    "        data_min = plot_data[column_name].min()\n",
    "        data_max = plot_data[column_name].max()\n",
    "        \n",
    "        # Create a normalized color range based on the data values\n",
    "        norm = mcolors.Normalize(vmin=data_min, vmax=data_max)\n",
    "        \n",
    "        # Get a list of colors based on the normalized data values\n",
    "        colors = cmap(norm(plot_data[column_name].values))\n",
    "        \n",
    "        # Plot the data with the colors\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(plot_data['CellID'], plot_data[column_name], color=colors)\n",
    "        \n",
    "        # Set labels, title, etc.\n",
    "        plt.xlabel('Cell ID')\n",
    "        plt.ylabel(column_name)\n",
    "        plt.title(f'Ranking of Units in {group_name} based on {column_name}')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.grid(axis='y')\n",
    "        \n",
    "        # Add a colorbar to show the color mapping\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        plt.colorbar(sm)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def plot_mean_firing(self, stim_level, group_name=None):\n",
    "        \"\"\"\n",
    "        This method plots the mean firing rates for individual units and the grand mean across units \n",
    "        during the early and late phases of the pre and post epochs. The early and late mean firing \n",
    "        rates are represented by lines connecting empty and filled circles, respectively. The grand \n",
    "        mean is represented by a red line.\n",
    "\n",
    "        Parameters:\n",
    "        stim_level (str): The stimulation level to consider ('Zero', 'Low', 'Mid', 'Max', or 'Pooled').\n",
    "        group_name (str, optional): The name of the group to plot data for. If None, data for all groups are plotted.\n",
    "\n",
    "        Returns:\n",
    "        None: The method displays the plot but does not return any values.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure the analysis results DataFrame is available\n",
    "        if self.analysis_df is None:\n",
    "            print(\"Please run the individual_unit_analysis method first.\")\n",
    "            return\n",
    "\n",
    "        # Get the list of group names\n",
    "        group_names = [group_name] if group_name else self.EED.group_names\n",
    "        \n",
    "        # Create a 1x2 subplot with shared y-axis\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n",
    "\n",
    "        # Loop through each group\n",
    "        for group in group_names:\n",
    "            \n",
    "            # Loop through each epoch (Pre and Post) to create the plots\n",
    "            for i, epoch in enumerate(['Pre', 'Post']):\n",
    "                early_means = self.analysis_df.loc[group, f'{epoch}_{stim_level}_early_mean']\n",
    "                late_means = self.analysis_df.loc[group, f'{epoch}_{stim_level}_late_mean']\n",
    "                \n",
    "                unit_ids = self.analysis_df.loc[group].index.get_level_values(0).unique()\n",
    "                \n",
    "                # Lists to store the early and late means for all units\n",
    "                early_means_list = []\n",
    "                late_means_list = []\n",
    "                \n",
    "                # Loop through each unit to gather the early and late means\n",
    "                for unit_id in unit_ids:\n",
    "                    early_mean = early_means.loc[unit_id]\n",
    "                    late_mean = late_means.loc[unit_id]\n",
    "                    \n",
    "                    early_means_list.append(early_mean)\n",
    "                    late_means_list.append(late_mean)\n",
    "                \n",
    "                # Now you have lists of early and late means for all units, and you can plot lines connecting these values\n",
    "                for j, unit_id in enumerate(unit_ids):\n",
    "                    color = 'grey' if epoch == 'Pre' else 'blue'\n",
    "                    axes[i].plot([1, 2], [early_means_list[j], late_means_list[j]], marker='o', markersize=5, markerfacecolor=color, markeredgecolor=color, linestyle='-', color=color)\n",
    "                    axes[i].plot(1, early_means_list[j], marker='o', markersize=5, markerfacecolor='white', markeredgecolor=color, linestyle='-', color=color)\n",
    "                \n",
    "                # Calculate the grand mean for all units\n",
    "                grand_mean_early = np.mean(early_means_list)\n",
    "                grand_mean_late = np.mean(late_means_list)\n",
    "                \n",
    "                # Plot the grand mean\n",
    "                axes[i].plot([1, 2], [grand_mean_early, grand_mean_late], marker='o', markersize=7, markerfacecolor='none', color='red', linewidth=2, label='Grand Mean')\n",
    "                \n",
    "                # Set the x-ticks labels and title\n",
    "                axes[i].set_xticks([1, 2])\n",
    "                axes[i].set_xticklabels(['Early-Phase', 'Late-Phase'])\n",
    "                axes[i].set_title(f'{epoch} Epoch with {stim_level} Stimulation')\n",
    "                axes[i].set_xlabel('Phase')\n",
    "                axes[i].set_ylabel('Mean Firing Rate')\n",
    "            \n",
    "            # Display a legend in the second plot\n",
    "            axes[1].legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "            \n",
    "            # Adjust the layout to prevent overlapping\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Display the plot\n",
    "            plt.show()\n",
    "            \n",
    "    def plot_standard_deviation(self, stim_level, group_name=None):\n",
    "        \"\"\"\n",
    "        This method plots the standard deviation of firing rates for individual units and the grand mean across units \n",
    "        during the early and late phases of the pre and post epochs. The early and late standard deviations \n",
    "        are represented by lines connecting empty and filled circles, respectively. The grand mean is represented \n",
    "        by a red line for the pre epoch and a green line for the post epoch.\n",
    "\n",
    "        Parameters:\n",
    "        stim_level (str): The stimulation level to consider ('Zero', 'Low', 'Mid', 'Max', or 'Pooled').\n",
    "        group_name (str, optional): The name of the group to plot data for. If None, data for all groups are plotted.\n",
    "\n",
    "        Returns:\n",
    "        None: The method displays the plot but does not return any values.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure the analysis results DataFrame is available\n",
    "        if self.analysis_df is None:\n",
    "            print(\"Please run the individual_unit_analysis method first.\")\n",
    "            return\n",
    "\n",
    "        # Get the list of group names\n",
    "        group_names = [group_name] if group_name else self.EED.group_names\n",
    "        \n",
    "        # Create a 1x2 subplot with shared y-axis\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n",
    "        \n",
    "        # Loop through each group\n",
    "        for group in group_names:\n",
    "            \n",
    "            # Loop through each epoch (Pre and Post) to create the plots\n",
    "            for i, epoch in enumerate(['Pre', 'Post']):\n",
    "                early_stds = self.analysis_df.loc[group, f'{epoch}_{stim_level}_early_std']\n",
    "                late_stds = self.analysis_df.loc[group, f'{epoch}_{stim_level}_late_std']\n",
    "                \n",
    "                unit_ids = self.analysis_df.loc[group].index.get_level_values(0).unique()\n",
    "                \n",
    "                # Lists to store the early and late standard deviations for all units\n",
    "                early_stds_list = []\n",
    "                late_stds_list = []\n",
    "                \n",
    "                # Loop through each unit to gather the early and late standard deviations\n",
    "                for unit_id in unit_ids:\n",
    "                    early_std = early_stds.loc[unit_id]\n",
    "                    late_std = late_stds.loc[unit_id]\n",
    "                    \n",
    "                    early_stds_list.append(early_std)\n",
    "                    late_stds_list.append(late_std)\n",
    "                \n",
    "                # Now you have lists of early and late standard deviations for all units, and you can plot lines connecting these values\n",
    "                for j, unit_id in enumerate(unit_ids):\n",
    "                    color = 'grey' if epoch == 'Pre' else 'blue'\n",
    "                    axes[i].plot([1, 2], [early_stds_list[j], late_stds_list[j]], marker='o', markersize=5, markerfacecolor=color, markeredgecolor=color, linestyle='-', color=color)\n",
    "                    axes[i].plot(1, early_stds_list[j], marker='o', markersize=5, markerfacecolor='white', markeredgecolor=color, linestyle='-', color=color)\n",
    "                    \n",
    "\n",
    "                \n",
    "                # Calculate the grand mean for all units\n",
    "                grand_mean_early = np.mean(early_stds_list)\n",
    "                grand_mean_late = np.mean(late_stds_list)\n",
    "                \n",
    "                # Plot the grand mean\n",
    "                axes[i].plot([1, 2], [grand_mean_early, grand_mean_late], marker='o', markersize=7, markerfacecolor='none', color='red', linewidth=2, label='Grand Mean')\n",
    "                \n",
    "                # Set the x-ticks labels and title\n",
    "                # And update the x-ticks and labels as follows:\n",
    "                axes[i].set_xticks([1, 2])\n",
    "                axes[i].set_xticklabels(['Early-Phase', 'Late-Phase'])\n",
    "                axes[i].set_title(f'{epoch} Epoch with {stim_level} Stimulation')\n",
    "                axes[i].set_xlabel('Phase')\n",
    "                axes[i].set_ylabel('Standard Deviation of Firing Rate')\n",
    "            \n",
    "            # Display a legend in the second plot\n",
    "            axes[1].legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "            \n",
    "            # Adjust the layout to prevent overlapping\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Display the plot\n",
    "            plt.show()\n",
    "    def plot_fold_change(self, stim_level, group_name=None):\n",
    "        \"\"\"\n",
    "        This method plots the fold change of firing rates for individual units and the grand mean across units \n",
    "        during the early and late phases of the pre and post epochs. The fold changes \n",
    "        are represented by lines connecting circles, with the baseline represented as 1. The grand mean is represented \n",
    "        by a red line.\n",
    "\n",
    "        Parameters:\n",
    "        stim_level (str): The stimulation level to consider ('Zero', 'Low', 'Mid', 'Max', or 'Pooled').\n",
    "        group_name (str, optional): The name of the group to plot data for. If None, data for all groups are plotted.\n",
    "\n",
    "        Returns:\n",
    "        None: The method displays the plot but does not return any values.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure the analysis results DataFrame is available\n",
    "        if self.analysis_df is None:\n",
    "            print(\"Please run the individual_unit_analysis method first.\")\n",
    "            return\n",
    "\n",
    "        # Get the list of group names\n",
    "        group_names = [group_name] if group_name else self.EED.group_names\n",
    "        \n",
    "        # Create a 1x2 subplot with shared y-axis\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n",
    "        \n",
    "        # Loop through each group\n",
    "        for group in group_names:\n",
    "            \n",
    "            # Loop through each epoch (Pre and Post) to create the plots\n",
    "            for i, epoch in enumerate(['Pre', 'Post']):\n",
    "                \n",
    "                fold_changes = self.analysis_df.loc[group, f'{epoch}_{stim_level}_fold_change']\n",
    "                unit_ids = self.analysis_df.loc[group].index.get_level_values(0).unique()\n",
    "                \n",
    "                # Lists to store the fold changes for all units\n",
    "                fold_changes_list = []\n",
    "                \n",
    "                # Loop through each unit to gather the fold changes\n",
    "                for unit_id in unit_ids:\n",
    "                    fold_change = fold_changes.loc[unit_id]\n",
    "                    fold_changes_list.append(fold_change)\n",
    "                \n",
    "                # Now you have a list of fold changes for all units, and you can plot lines connecting these values\n",
    "                for j, unit_id in enumerate(unit_ids):\n",
    "                    color = 'grey' if epoch == 'Pre' else 'blue'\n",
    "                    axes[i].plot([1, 2], [1, fold_changes_list[j]], marker='o', markersize=5, markerfacecolor=color, markeredgecolor=color, linestyle='-', color=color)\n",
    "                    \n",
    "                # Calculate the grand mean for all units\n",
    "                grand_mean_baseline = 1  # The baseline is 1 for fold change\n",
    "                grand_mean_fold_change = np.mean(fold_changes_list)\n",
    "                \n",
    "                # Plot the grand mean\n",
    "                axes[i].plot([1, 2], [grand_mean_baseline, grand_mean_fold_change], marker='o', markersize=7, markerfacecolor='none', color='red', linewidth=2, label='Grand Mean')\n",
    "                \n",
    "                # Set the x-ticks labels and title\n",
    "                axes[i].set_xticks([1, 2])\n",
    "                axes[i].set_xticklabels(['Baseline', 'Fold Change'])\n",
    "                axes[i].set_title(f'{epoch} Epoch with {stim_level} Stimulation')\n",
    "                axes[i].set_xlabel('Phase')\n",
    "                axes[i].set_ylabel('Fold Change of Firing Rate')\n",
    "            \n",
    "            # Display a legend in the second plot\n",
    "            axes[1].legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
    "            \n",
    "            # Adjust the layout to prevent overlapping\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Display the plot\n",
    "            plt.show()\n",
    "\n",
    "    def compare_percent_changes_between_groups(self, group1_name, group2_name):\n",
    "        # Ensure the analysis_df attribute is not None\n",
    "        if self.analysis_df is None:\n",
    "            raise ValueError(\"The analysis_df attribute is None. Please run the individual_unit_analysis method first.\")\n",
    "\n",
    "        # Define the stimulation levels\n",
    "        stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "\n",
    "        # Initialize an empty list to store the results of the t-tests\n",
    "        t_test_results = []\n",
    "\n",
    "        # Loop through each stimulation level to perform the t-tests\n",
    "        for stim_level in stim_levels:\n",
    "            # Get the percent changes for the current stimulation level for each group\n",
    "            group1_data = self.analysis_df.loc[(group1_name, slice(None)), :][f'Post_{stim_level}_percent_change_normalized'].values\n",
    "            group2_data = self.analysis_df.loc[(group2_name, slice(None)), :][f'Post_{stim_level}_percent_change_normalized'].values\n",
    "\n",
    "            # Perform an independent t-test\n",
    "            t_stat, p_val = stats.ttest_ind(group1_data, group2_data, nan_policy='omit')\n",
    "\n",
    "            # Store the results in the list\n",
    "            t_test_results.append({'Stimulation Level': stim_level, 't-statistic': t_stat, 'p-value': p_val})\n",
    "\n",
    "        # Create a DataFrame from the t-test results\n",
    "        #t_test_results_df = pd.DataFrame(t_test_results)\n",
    "\n",
    "        # Print the t-test results\n",
    "        #print(t_test_results_df)\n",
    "\n",
    "        # Create a bar plot to visualize the p-values\n",
    "        #sns.set(style=\"whitegrid\")\n",
    "        #plt.figure(figsize=(10, 6))\n",
    "        #sns.barplot(x='Stimulation Level', y='p-value', data=t_test_results_df)\n",
    "        #plt.axhline(y=0.05, color='r', linestyle='--')  # Add a line to indicate the 0.05 significance level\n",
    "        #plt.title('Significance of Percent Changes (Group1 vs. Group2)')\n",
    "        #plt.ylabel('p-value')\n",
    "        #plt.xlabel('Stimulation Level')\n",
    "        #plt.show()\n",
    "        \n",
    "        # Create a dictionary of p-values indexed by stimulation level\n",
    "        p_values = {result['Stimulation Level']: result['p-value'] for result in t_test_results}\n",
    "    \n",
    "        # Return the dictionary of p-values at the end of the method\n",
    "        return p_values\n",
    "        \n",
    "            \n",
    "            \n",
    "    def plot_fold_change_plotly(self, stim_level, group_name=None):\n",
    "        \"\"\"\n",
    "        This method plots the fold change of firing rates for individual units and the grand mean across units \n",
    "        during the baseline and fold change phases of the pre and post epochs using Plotly for interactive visualization. \n",
    "        The baseline and fold change values are represented by lines connecting markers at x=1 and x=2, respectively. \n",
    "        The grand mean is represented by a red line for the pre epoch and a green line for the post epoch.\n",
    "\n",
    "        Parameters:\n",
    "        stim_level (str): The stimulation level to consider ('Zero', 'Low', 'Mid', 'Max', or 'Pooled').\n",
    "        group_name (str, optional): The name of the group to plot data for. If None, data for all groups are plotted.\n",
    "\n",
    "        Returns:\n",
    "        None: The method displays the plot but does not return any values.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure the analysis results DataFrame is available\n",
    "        if self.analysis_df is None:\n",
    "            print(\"Please run the individual_unit_analysis method first.\")\n",
    "            return\n",
    "\n",
    "        # Get the list of group names\n",
    "        group_names = [group_name] if group_name else self.EED.group_names\n",
    "        \n",
    "        # Loop through each group\n",
    "        for group in group_names:\n",
    "            \n",
    "            # Create a Plotly figure\n",
    "            fig = go.Figure()\n",
    "            \n",
    "            # Loop through each epoch (Pre and Post) to create the plots\n",
    "            for i, epoch in enumerate(['Pre', 'Post']):\n",
    "                fold_changes = self.analysis_df.loc[group, f'{epoch}_{stim_level}_fold_change']\n",
    "                \n",
    "                unit_ids = self.analysis_df.loc[group].index.get_level_values(0).unique()\n",
    "                \n",
    "                # Lists to store the baseline and fold change values for all units\n",
    "                baseline_list = [1] * len(unit_ids)\n",
    "                fold_changes_list = []\n",
    "                \n",
    "                # Loop through each unit to gather the baseline and fold change values\n",
    "                for unit_id in unit_ids:\n",
    "                    fold_change = fold_changes.loc[unit_id]\n",
    "                    fold_changes_list.append(fold_change)\n",
    "                \n",
    "                # Now you have lists of baseline and fold change values for all units, and you can plot lines connecting these values\n",
    "                for j, unit_id in enumerate(unit_ids):\n",
    "                    color = 'grey' if epoch == 'Pre' else 'blue'\n",
    "                    fig.add_trace(go.Scatter(x=[1, 2], y=[1, fold_changes_list[j]], mode='lines+markers', marker=dict(color=color), line=dict(color=color), name=f'{unit_id} {epoch}', hovertemplate=f'Unit ID: {unit_id}<br>Phase: '+'%{x}<br>Fold Change: '+'%{y}'))\n",
    "\n",
    "                # Calculate the grand mean for all units\n",
    "                grand_mean_baseline = np.nanmean(baseline_list)\n",
    "                grand_mean_fold_change = np.nanmean(fold_changes_list)\n",
    "                \n",
    "                \n",
    "                # Plot the grand mean\n",
    "                color = 'red' if epoch == 'Pre' else 'green'\n",
    "                fig.add_trace(go.Scatter(x=[1, 2], y=[grand_mean_baseline, grand_mean_fold_change], mode='lines+markers', marker=dict(color=color), line=dict(color=color, width=2), name=f'Grand Mean {epoch}'))\n",
    "            \n",
    "            # Set the x-ticks labels and title            \n",
    "            fig.update_layout(\n",
    "                xaxis=dict(tickvals=[1, 2], ticktext=['Baseline', 'Fold Change']),\n",
    "                title=f'Fold Change with {stim_level} Stimulation for group {group}',\n",
    "                xaxis_title='Phase',\n",
    "                yaxis_title='Fold Change',\n",
    "                template='plotly_white',  # Change the template here\n",
    "                width=800,  # Set the width of the plot (in pixels)\n",
    "                height=600,  # Set the height of the plot (in pixels)\n",
    "            )\n",
    "            # Get the total number of traces (2 grand means + number of units for pre and post)\n",
    "            num_traces = len(fig.data)\n",
    "\n",
    "            # Define the dropdown buttons with dynamic visibility lists\n",
    "            buttons = [\n",
    "                dict(\n",
    "                    args=[{'visible': [True] * num_traces}],  # Show all traces (both pre and post)\n",
    "                    label='Both',\n",
    "                    method='update'\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[{'visible': [True if i < num_traces // 2 else False for i in range(num_traces)]}],  # Show only pre traces\n",
    "                    label='Pre',\n",
    "                    method='update'\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[{'visible': [False if i < num_traces // 2 else True for i in range(num_traces)]}],  # Show only post traces\n",
    "                    label='Post',\n",
    "                    method='update'\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Add the dropdown buttons to the figure\n",
    "            fig.update_layout(\n",
    "                updatemenus=[\n",
    "                    dict(\n",
    "                        x=1.15,\n",
    "                        y=1.2,\n",
    "                        xanchor='left',\n",
    "                        yanchor='top',\n",
    "                        buttons=buttons\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            # Display the plot\n",
    "            fig.show()\n",
    "\n",
    "    def plot_standard_deviation_plotly(self, stim_level, group_name=None, data_type='both'):\n",
    "            # Ensure the analysis results DataFrame is available\n",
    "            if self.analysis_df is None:\n",
    "                print(\"Please run the individual_unit_analysis method first.\")\n",
    "                return\n",
    "\n",
    "            # Get the list of group names\n",
    "            group_names = [group_name] if group_name else self.EED.group_names\n",
    "            \n",
    "            # Loop through each group\n",
    "            for group in group_names:\n",
    "                \n",
    "                # Create a Plotly figure\n",
    "                fig = go.Figure()\n",
    "                \n",
    "                # Loop through each epoch (Pre and Post) to create the plots\n",
    "                for i, epoch in enumerate(['Pre', 'Post']):\n",
    "                    \n",
    "                    # Get the standard deviations for the early and late phases\n",
    "                    early_std_devs = self.analysis_df.loc[group, f'{epoch}_{stim_level}_early_std']\n",
    "                    late_std_devs = self.analysis_df.loc[group, f'{epoch}_{stim_level}_late_std']\n",
    "                    \n",
    "                    unit_ids = self.analysis_df.loc[group].index.get_level_values(0).unique()\n",
    "                    \n",
    "                    # Loop through each unit to gather the standard deviation values for early and late phases\n",
    "                    for unit_id in unit_ids:\n",
    "                        early_std_dev = early_std_devs.loc[unit_id]\n",
    "                        late_std_dev = late_std_devs.loc[unit_id]\n",
    "                        \n",
    "                        color = 'grey' if epoch == 'Pre' else 'blue'\n",
    "                        fig.add_trace(go.Scatter(x=['Early', 'Late'], y=[early_std_dev, late_std_dev], mode='lines+markers', marker=dict(color=color), line=dict(color=color), name=f'{unit_id} {epoch}', hovertemplate=f'Unit ID: {unit_id}<br>Phase: '+'%{x}<br>Std Dev: '+'%{y}'))\n",
    "                    \n",
    "                    # Get the mean standard deviations across units for early and late phases\n",
    "                    mean_early_std_dev = np.nanmean(early_std_devs)\n",
    "                    mean_late_std_dev = np.nanmean(late_std_devs)\n",
    "\n",
    "                    color = 'red' if epoch == 'Pre' else 'green'\n",
    "                    fig.add_trace(go.Scatter(x=['Early', 'Late'], y=[mean_early_std_dev, mean_late_std_dev], mode='lines+markers', marker=dict(color=color), line=dict(color=color, width=2), name=f'Mean Std Dev {epoch}'))\n",
    "            \n",
    "            # Set the x-ticks labels and title            \n",
    "            fig.update_layout(\n",
    "                xaxis=dict(tickvals=[0, 1], ticktext=['Early', 'Late']),\n",
    "                title=f'Standard Deviation with {stim_level} Stimulation for group {group}',\n",
    "                xaxis_title='Phase',\n",
    "                yaxis_title='Standard Deviation',\n",
    "                template='plotly_white',\n",
    "                width=800,\n",
    "                height=600,\n",
    "            )\n",
    "            \n",
    "            # Get the total number of traces (2 grand means + number of units for pre and post)\n",
    "            num_traces = len(fig.data)\n",
    "\n",
    "            # Define the dropdown buttons with dynamic visibility lists\n",
    "            buttons = [\n",
    "                dict(\n",
    "                    args=[{'visible': [True] * num_traces}],  # Show all traces (both pre and post)\n",
    "                    label='Both',\n",
    "                    method='update'\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[{'visible': [True if i < num_traces // 2 else False for i in range(num_traces)]}],  # Show only pre traces\n",
    "                    label='Pre',\n",
    "                    method='update'\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[{'visible': [False if i < num_traces // 2 else True for i in range(num_traces)]}],  # Show only post traces\n",
    "                    label='Post',\n",
    "                    method='update'\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Add the dropdown buttons to the figure\n",
    "            fig.update_layout(\n",
    "                updatemenus=[           \n",
    "                    dict(\n",
    "                        x=1.15,\n",
    "                        y=1.2,\n",
    "                        xanchor='left',\n",
    "                        yanchor='top',\n",
    "                        buttons=buttons\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Display the plot\n",
    "            fig.show()\n",
    "            \n",
    "            \n",
    "    def plot_mean_firing_rate_plotly(self, stim_level, group_name=None):\n",
    "        # Ensure the analysis results DataFrame is available\n",
    "        if self.analysis_df is None:\n",
    "            print(\"Please run the individual_unit_analysis method first.\")\n",
    "            return\n",
    "\n",
    "        # Get the list of group names\n",
    "        group_names = [group_name] if group_name else self.EED.group_names\n",
    "        \n",
    "        # Loop through each group\n",
    "        for group in group_names:\n",
    "            \n",
    "            # Create a Plotly figure\n",
    "            fig = go.Figure()\n",
    "            \n",
    "            # Loop through each epoch (Pre and Post) to create the plots\n",
    "            for i, epoch in enumerate(['Pre', 'Post']):\n",
    "                \n",
    "                # Get the mean firing rates for the early and late phases\n",
    "                early_mean_rates = self.analysis_df.loc[group, f'{epoch}_{stim_level}_early_mean']\n",
    "                late_mean_rates = self.analysis_df.loc[group, f'{epoch}_{stim_level}_late_mean']\n",
    "                \n",
    "                unit_ids = self.analysis_df.loc[group].index.get_level_values(0).unique()\n",
    "                \n",
    "                # Loop through each unit to gather the mean firing rates for early and late phases\n",
    "                for unit_id in unit_ids:\n",
    "                    early_mean_rate = early_mean_rates.loc[unit_id]\n",
    "                    late_mean_rate = late_mean_rates.loc[unit_id]\n",
    "                    \n",
    "                    color = 'grey' if epoch == 'Pre' else 'blue'\n",
    "                    fig.add_trace(go.Scatter(x=['Early', 'Late'], y=[early_mean_rate, late_mean_rate], mode='lines+markers', marker=dict(color=color), line=dict(color=color), name=f'{unit_id} {epoch}', hovertemplate=f'Unit ID: {unit_id}<br>Phase: '+'%{x}<br>Mean Rate: '+'%{y}'))\n",
    "                \n",
    "                # Get the grand mean firing rates across units for early and late phases\n",
    "                grand_mean_early = np.nanmean(early_mean_rates)\n",
    "                grand_mean_late = np.nanmean(late_mean_rates)\n",
    "\n",
    "                color = 'red' if epoch == 'Pre' else 'green'\n",
    "                fig.add_trace(go.Scatter(x=['Early', 'Late'], y=[grand_mean_early, grand_mean_late], mode='lines+markers', marker=dict(color=color), line=dict(color=color, width=2), name=f'Grand Mean {epoch}'))\n",
    "            \n",
    "            # Set the x-ticks labels and title            \n",
    "            fig.update_layout(\n",
    "                xaxis=dict(tickvals=[0, 1], ticktext=['Early', 'Late']),\n",
    "                title=f'Mean Firing Rate with {stim_level} Stimulation for group {group}',\n",
    "                xaxis_title='Phase',\n",
    "                yaxis_title='Mean Firing Rate',\n",
    "                template='plotly_white',\n",
    "                width=800,\n",
    "                height=600,\n",
    "            )\n",
    "            \n",
    "            # Get the total number of traces (2 grand means + number of units for pre and post)\n",
    "            num_traces = len(fig.data)\n",
    "\n",
    "            # Define the dropdown buttons with dynamic visibility lists\n",
    "            buttons = [\n",
    "                dict(\n",
    "                    args=[{'visible': [True] * num_traces}],  # Show all traces (both pre and post)\n",
    "                    label='Both',\n",
    "                    method='update'\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[{'visible': [True if i < num_traces // 2 else False for i in range(num_traces)]}],  # Show only pre traces\n",
    "                    label='Pre',\n",
    "                    method='update'\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[{'visible': [False if i < num_traces // 2 else True for i in range(num_traces)]}],  # Show only post traces\n",
    "                    label='Post',\n",
    "                    method='update'\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Add the dropdown buttons to the figure\n",
    "            fig.update_layout(\n",
    "                updatemenus=[\n",
    "                    dict(\n",
    "                        x=1.15,\n",
    "                        y=1.2,\n",
    "                        xanchor='left',\n",
    "                        yanchor='top',\n",
    "                        buttons=buttons\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Display the plot\n",
    "            fig.show()\n",
    "            \n",
    "\n",
    "    def plot_group_responses(self, group_name):\n",
    "        # Ensure the analysis results DataFrame is available\n",
    "        if self.analysis_df is None:\n",
    "            print(\"Please run the individual_unit_analysis method first.\")\n",
    "            return\n",
    "\n",
    "        # Get the unique unit IDs for the specified group\n",
    "        unit_ids = self.analysis_df.loc[group_name].index.get_level_values(0).unique()\n",
    "\n",
    "        # Create a Plotly figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Loop through each unit ID to add a scatter plot trace for each combination of epoch, stim level, and phase\n",
    "        for unit_id in unit_ids:\n",
    "            for epoch in ['Pre', 'Post']:\n",
    "                for stim_level in ['Zero', 'Low', 'Mid', 'Max', 'Pooled']:\n",
    "                    for phase in ['early', 'late']:\n",
    "                        response = self.analysis_df.loc[(group_name, unit_id), f'{epoch}_{stim_level}_{phase}_response']\n",
    "                        fig.add_trace(go.Scatter(x=list(range(len(response))), y=response, mode='markers', name=f'{unit_id} {epoch} {stim_level} {phase}'))\n",
    "\n",
    "        # Create a dictionary to store the current visibility state of each option\n",
    "        current_visibility = {'epoch': ['Pre', 'Post'], 'stim_level': ['Zero', 'Low', 'Mid', 'Max', 'Pooled'], 'phase': ['early', 'late']}\n",
    "\n",
    "        # Define a function to update the visibility of the traces based on the selected options\n",
    "        def update_visibility(option_type, option_value):\n",
    "            if option_value in ['Both', 'All']:\n",
    "                current_visibility[option_type] = ['Pre', 'Post'] if option_type == 'epoch' else ['Zero', 'Low', 'Mid', 'Max', 'Pooled'] if option_type == 'stim_level' else ['early', 'late']\n",
    "            else:\n",
    "                current_visibility[option_type] = [option_value]\n",
    "            return [all(any(option in trace.name for option in current_visibility[option_type]) for option_type in current_visibility) for trace in fig.data]\n",
    "\n",
    "        # Define dropdown menus to control visibility of traces\n",
    "        epoch_buttons = [\n",
    "            dict(label=epoch, method=\"update\", args=[{\"visible\": update_visibility('epoch', epoch)}]) for epoch in ['Pre', 'Post', 'Both']\n",
    "        ]\n",
    "        stim_level_buttons = [\n",
    "            dict(label=stim_level, method=\"update\", args=[{\"visible\": update_visibility('stim_level', stim_level)}]) for stim_level in ['Zero', 'Low', 'Mid', 'Max', 'Pooled', 'All']\n",
    "        ]\n",
    "        phase_buttons = [\n",
    "            dict(label=phase, method=\"update\", args=[{\"visible\": update_visibility('phase', phase)}]) for phase in ['early', 'late', 'Both']\n",
    "        ]\n",
    "\n",
    "        # Add dropdown menus to the figure\n",
    "        fig.update_layout(\n",
    "            updatemenus=[\n",
    "                dict(\n",
    "                    x=1.15,\n",
    "                    y=1.2,\n",
    "                    xanchor='left',\n",
    "                    yanchor='top',\n",
    "                    buttons=epoch_buttons\n",
    "                ),\n",
    "                dict(\n",
    "                    x=1.15,\n",
    "                    y=1.1,\n",
    "                    xanchor='left',\n",
    "                    yanchor='top',\n",
    "                    buttons=stim_level_buttons\n",
    "                ),\n",
    "                dict(\n",
    "                    x=1.15,\n",
    "                    y=1.0,\n",
    "                    xanchor='left',\n",
    "                    yanchor='top',\n",
    "                    buttons=phase_buttons\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Display the plot\n",
    "        fig.show()\n",
    "        \n",
    "    def plot_group_responses_histogram(self, group_name, nbinsx=100):\n",
    "        \"\"\"\n",
    "        Plot a histogram of the responses for a specified group.\n",
    "\n",
    "        Parameters:\n",
    "        group_name (str): The name of the group to plot.\n",
    "        nbinsx (int, optional): The number of bins for the histogram. Defaults to 100.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure the analysis results DataFrame is available\n",
    "        if self.analysis_df is None:\n",
    "            print(\"Please run the individual_unit_analysis method first.\")\n",
    "            return\n",
    "\n",
    "        # Define the epochs, stimulation levels, and phases\n",
    "        epochs = ['Pre', 'Post']\n",
    "        stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "        phases = ['early', 'late']\n",
    "\n",
    "        # Define a list of colors to use for the different traces\n",
    "        colors = ['red', 'blue', 'green', 'purple', 'orange', 'pink', 'brown', 'yellow', 'grey', 'cyan']\n",
    "\n",
    "        # Create a Plotly figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Loop through each epoch, stimulation level, and phase to create the plots\n",
    "        from itertools import product\n",
    "        for i, (epoch, stim_level, phase) in enumerate(product(epochs, stim_levels, phases)):\n",
    "            response_data = self.analysis_df.loc[group_name, f'{epoch}_{stim_level}_{phase}_response'].values\n",
    "            \n",
    "            fig.add_trace(go.Histogram(\n",
    "                x=response_data,\n",
    "                nbinsx=nbinsx,  # Use the parameter to set the number of bins\n",
    "                name=f'{epoch} {stim_level} {phase}',\n",
    "                marker_color=colors[i % len(colors)],\n",
    "                hoverinfo='x+y',\n",
    "                hovertemplate='Count: %{y}<br>Response: %{x}<extra></extra>',\n",
    "            ))\n",
    "\n",
    "        # Define the dropdown buttons with dynamic visibility lists\n",
    "        buttons = [\n",
    "            dict(\n",
    "                args=[{'visible': [True] * len(fig.data)}], \n",
    "                label='All',\n",
    "                method='update'\n",
    "            )\n",
    "        ]\n",
    "        for i, (epoch, stim_level, phase) in enumerate(product(epochs, stim_levels, phases)):\n",
    "            visible = [False] * len(fig.data)\n",
    "            visible[i] = True\n",
    "            buttons.append(\n",
    "                dict(\n",
    "                    args=[{'visible': visible}], \n",
    "                    label=f'{epoch} {stim_level} {phase}',\n",
    "                    method='update'\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Add the dropdown buttons to the figure\n",
    "        fig.update_layout(\n",
    "            updatemenus=[\n",
    "                dict(\n",
    "                    x=1.15,\n",
    "                    y=1.2,\n",
    "                    xanchor='left',\n",
    "                    yanchor='top',\n",
    "                    buttons=buttons\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Set the x-ticks labels and title            \n",
    "        fig.update_layout(\n",
    "            title=f'Response Histogram for {group_name} group',\n",
    "            xaxis_title='Response',\n",
    "            xaxis=dict(\n",
    "                showticklabels=False,  # Hide x-axis labels\n",
    "                showgrid=False  # Remove x-axis grid lines\n",
    "            ),\n",
    "            yaxis_title='Count',\n",
    "            template='plotly_white',\n",
    "            width=800,\n",
    "            height=600,\n",
    "        )\n",
    "        \n",
    "        # Display the plot\n",
    "        fig.show()\n",
    "\n",
    "    def plot_group_responses_histogramsubplots(self, group_name, nbinsx=20):\n",
    "        # Define the stimulation levels and phases\n",
    "        stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "        phases = ['early', 'late']\n",
    "        epochs = ['Pre', 'Post']\n",
    "\n",
    "        # Get the unique unit IDs for the specified group\n",
    "        unit_ids = self.analysis_df.loc[(group_name, slice(None)), :].index.get_level_values(1).unique()\n",
    "        all_unit_ids = list(unit_ids)\n",
    "\n",
    "        # Create a subplot with 2 rows and 2 columns\n",
    "        fig = make_subplots(rows=2, cols=2, subplot_titles=('Pre Early', 'Pre Late', 'Post Early', 'Post Late'))\n",
    "\n",
    "        # Function to get pooled data for the current selection of units\n",
    "        def get_pooled_data(epoch, phase, stim_level, visible_unit_ids):\n",
    "            pooled_data = []\n",
    "            for unit_id in visible_unit_ids:\n",
    "                data = self.analysis_df.loc[(group_name, unit_id), f'{epoch}_{stim_level}_{phase}_response']\n",
    "                pooled_data.extend(data)\n",
    "            return pooled_data\n",
    "\n",
    "        # Initially, all units are visible\n",
    "        visible_unit_ids = all_unit_ids.copy()\n",
    "\n",
    "        # Loop through each condition to plot the histograms\n",
    "        for i, epoch in enumerate(epochs):\n",
    "            for j, phase in enumerate(phases):\n",
    "                data = get_pooled_data(epoch, phase, 'Pooled', visible_unit_ids)\n",
    "                fig.add_trace(go.Histogram(x=data, nbinsx=nbinsx, name='Pooled Data'), row=i+1, col=j+1)\n",
    "\n",
    "        # Create buttons to include or remove units\n",
    "        buttons = [\n",
    "            dict(\n",
    "                args=[\n",
    "                    {\n",
    "                        'x': [\n",
    "                            get_pooled_data(epoch, phase, 'Pooled', [unit_id for unit_id in visible_unit_ids if unit_id != uid]) \n",
    "                            for epoch in epochs \n",
    "                            for phase in phases\n",
    "                        ]\n",
    "                    }, \n",
    "                    list(range(4))\n",
    "                ],\n",
    "                label='Unit ' + str(uid),\n",
    "                method='restyle'\n",
    "            )\n",
    "            for uid in all_unit_ids\n",
    "        ]\n",
    "\n",
    "        stim_dropdown = [\n",
    "            dict(\n",
    "                args=[\n",
    "                    {\n",
    "                        'x': [\n",
    "                            get_pooled_data(epoch, phase, stim_level, visible_unit_ids) \n",
    "                            for epoch in epochs \n",
    "                            for phase in phases\n",
    "                        ]\n",
    "                    }, \n",
    "                    list(range(4))\n",
    "                ],\n",
    "                label=stim_level,\n",
    "                method='restyle'\n",
    "            )\n",
    "            for stim_level in stim_levels\n",
    "        ]\n",
    "\n",
    "        # Update layout to include the buttons and other details\n",
    "        fig.update_layout(\n",
    "            updatemenus=[\n",
    "                dict(\n",
    "                    buttons=stim_dropdown,\n",
    "                    direction=\"down\",\n",
    "                    pad={\"r\": 10, \"t\": 10},\n",
    "                    showactive=True,\n",
    "                    x=0.24,\n",
    "                    xanchor=\"left\",\n",
    "                    y=1.15,\n",
    "                    yanchor=\"top\"\n",
    "                ),\n",
    "                *[\n",
    "                    dict(\n",
    "                        buttons=[button],\n",
    "                        direction=\"down\",\n",
    "                        pad={\"r\": 10, \"t\": 10},\n",
    "                        showactive=True,\n",
    "                        x=0.17,\n",
    "                        xanchor=\"left\",\n",
    "                        y=1.15 - i * 0.05,  # Adjust the y position for each button to avoid overlap\n",
    "                        yanchor=\"top\"\n",
    "                    )\n",
    "                    for i, button in enumerate(buttons)\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Display the plot\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    def remove_cell_ids(self, group_name, cell_ids_to_remove):\n",
    "        \"\"\"\n",
    "        This method removes specific cell IDs from a specified group in the EED class.\n",
    "\n",
    "        Parameters:\n",
    "        group_name (str): The name of the group from which to remove cell IDs.\n",
    "        cell_ids_to_remove (list): A list of cell IDs to remove from the group.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if the analysis DataFrame is available\n",
    "        if self.analysis_df is None:\n",
    "            print(\"The analysis DataFrame is not available.\")\n",
    "            return\n",
    "        \n",
    "        # Check if the group name is valid\n",
    "        if group_name not in self.EED.group_names:\n",
    "            print(f\"The group name '{group_name}' does not exist.\")\n",
    "            return\n",
    "\n",
    "        # Remove the specified cell IDs from the specified group\n",
    "        self.analysis_df = self.analysis_df.drop(index=cell_ids_to_remove, level=1)\n",
    "\n",
    "        print(f\"Removed cell IDs {cell_ids_to_remove} from group '{group_name}'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "analysis_instance = NeuralDataAnalysis(EED, group_name=None, early_phase_indices= (500, 525) , late_phase_indices= (526, 800))\n",
    "\n",
    "result_df, results_dict = analysis_instance.individual_unit_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from scipy.stats import ConstantInputWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConstantInputWarning)\n",
    "\n",
    "\n",
    "def find_optimal_late_phase_range(analysis_instance, group1_name, group2_name, min_start=550, max_end=1200, min_step=1):\n",
    "    \n",
    "    # Define the stimulation levels\n",
    "    stim_levels = ['Zero', 'Low', 'Mid', 'Max']\n",
    "    \n",
    "    # Initialize variables to store the optimal range, step and minimum p-value before entering the step loop\n",
    "    optimal_range = (min_start, min_start + min_step)\n",
    "    optimal_step = min_step\n",
    "    min_p_value = 0.01  # Set the initial minimum p-value to a high value\n",
    "\n",
    "    max_step = max_end - min_start\n",
    "\n",
    "    # Loop through different step sizes from the maximum to the minimum\n",
    "    for step in range(max_step, min_step - 1, -min_step):\n",
    "       \n",
    "        # Calculate the number of iterations\n",
    "        num_start_iterations = ((max_end - step - min_start) // step) + 1\n",
    "        num_end_iterations = ((max_end - (min_start + step)) // step) + 1\n",
    "        total_iterations = num_start_iterations * num_end_iterations\n",
    "\n",
    "        # Print the total number of iterations\n",
    "        print(f\"Total number of iterations for step size {step}: {total_iterations}\")\n",
    "\n",
    "        # Start a timer to estimate the time to run\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Run a few iterations to estimate the average time per iteration\n",
    "        for i in range(5):\n",
    "            analysis_instance.individual_unit_analysis(early_phase_indices=(500, 550), late_phase_indices=(min_start, min_start + step))\n",
    "            analysis_instance.compare_percent_changes_between_groups(group1_name, group2_name)\n",
    "        avg_time_per_iteration = (time.time() - start_time) / 5\n",
    "\n",
    "        # Print the estimated time to run\n",
    "        estimated_time_to_run = avg_time_per_iteration * total_iterations\n",
    "        print(f\"Estimated time to run: {estimated_time_to_run / 60:.2f} minutes\")\n",
    "        \n",
    "        # Initialize a counter before entering your loop\n",
    "        iteration_counter = 0\n",
    "\n",
    "        # Loop through different start and end indices for the late phase\n",
    "        # Loop through different start and end indices for the late phase\n",
    "        for start in range(min_start, max_end - step, step):\n",
    "            for end in range(start + step, max_end, step):\n",
    "                # Inside your loop, increment the counter with each iteration\n",
    "                iteration_counter += 1\n",
    "                \n",
    "                # Update the late phase indices in the individual_unit_analysis method\n",
    "                analysis_instance.individual_unit_analysis(early_phase_indices=(500, 550), late_phase_indices=(start, end))\n",
    "                \n",
    "                # Get the p-values for the current range of late phase indices\n",
    "                p_values = analysis_instance.compare_percent_changes_between_groups(group1_name, group2_name)\n",
    "                \n",
    "                # Get the maximum p-value across the specified stimulation levels\n",
    "                max_p_value = max([p_values[stim] for stim in stim_levels[1:-1]]) # Exclude the 'Zero' and 'Pooled' stimulation levels\n",
    "\n",
    "                    \n",
    "                if max_p_value < min_p_value or (max_p_value < 0.05 and (end - start) > (optimal_range[1] - optimal_range[0])):\n",
    "                    min_p_value = max_p_value\n",
    "                    optimal_range = (start, end)\n",
    "                    optimal_step = step  # Store the current step size as the optimal step size\n",
    "   \n",
    "                \n",
    "                # Use an if statement with the modulo operator to print the p-values every 100 iterations\n",
    "                if iteration_counter % 100 == 0:\n",
    "                    print(f\"Iteration {iteration_counter}: {dict(zip(stim_levels, [p_values[stim] for stim in stim_levels]))}\")\n",
    "\n",
    "    # Return the optimal range, step and minimum p-value\n",
    "    return optimal_range, optimal_step, min_p_value\n",
    "\n",
    "# Usage\n",
    "optimal_range, optimal_step, min_p_value = find_optimal_late_phase_range(analysis_instance, 'Lmc_opsin', 'Lmc_noopsin')\n",
    "print(f\"Optimal range: {optimal_range}, Optimal step: {optimal_step}, Minimum p-value: {min_p_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_and_rank_units(analysis_instance, epoch, stim_level):\n",
    "    # Get the spike trains data\n",
    "    spiketrains = analysis_instance.analysis_df[f'{epoch}_{stim_level}_spiketrains']\n",
    "\n",
    "    # Calculate the total number of spikes for each unit ID across all trials\n",
    "    total_spikes_per_unit = spiketrains.apply(lambda x: x.sum())\n",
    "\n",
    "    # Rank the unit IDs based on the total number of spikes\n",
    "    ranked_units = total_spikes_per_unit.sort_values(ascending=False)\n",
    "\n",
    "    # Create a bar plot to visualize the ranked unit IDs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ranked_units.plot(kind='bar')\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Unit ID')\n",
    "    plt.ylabel('Total Number of Spikes')\n",
    "    plt.title(f'Ranking of Unit IDs based on Total Number of Spikes ({epoch}, {stim_level})')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Return the ranked unit IDs and their total number of spikes\n",
    "    return ranked_units\n",
    "\n",
    "# Usage\n",
    "# Replace 'your_epoch_here' and 'your_stim_level_here' with the actual epoch and stim level you want to use\n",
    "# ranked_units = plot_and_rank_units(analysis_instance, 'your_epoch_here', 'your_stim_level_here')\n",
    "\n",
    "\n",
    "# Usage\n",
    "# Replace 'your_epoch_here' and 'your_stim_level_here' with the actual epoch and stim level you want to use\n",
    "ranked_units = plot_and_rank_units(analysis_instance, 'Pre', 'Max')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the bottom 10 units\n",
    "bottom_10_units = ranked_units.tail(10)\n",
    "bottom_10_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now remove the bottom units from the lmc_opsin group\n",
    "analysis_instance.remove_cell_ids('Lmc_opsin', ['cid238', 'cid79','cid91', 'cid156' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.compare_percent_changes_between_groups('Lmc_opsin', 'Lmc_noopsin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df\n",
    "#now index in cid81 and get the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query the data frame to get columns names with 'fold_change' in them\n",
    "#result_df.filter(like='fold_change_normalized', axis=1)\n",
    "result_df.filter(like='percent_change_normalized', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ranked units based on a specific metric\n",
    "analysis_instance.plot_ranked_units('Lmc_opsin', 'Post_Mid_fold_change', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the mean firing rate for the mid stimulation level\n",
    "analysis_instance.plot_mean_firing('Low', group_name='Lmc_opsin') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the standard deviation for the mid stimulation level\n",
    "analysis_instance.plot_standard_deviation('Pooled', group_name='Lmc_opsin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now iterate for all the stims for the Lmc_opsin group and plot the mean firing rate\n",
    "for stim in ['Zero', 'Low', 'Mid', 'Max', 'Pooled']:\n",
    "    analysis_instance.plot_mean_firing(stim, group_name='Lmc_opsin')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat this for the standard deviation\n",
    "for stim in ['Zero', 'Low', 'Mid', 'Max', 'Pooled']:\n",
    "    analysis_instance.plot_standard_deviation(stim, group_name='Lmc_opsin')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot the fold change for the Lmc_opsin group\n",
    "for stim in ['Zero', 'Low', 'Mid', 'Max', 'Pooled']:\n",
    "    analysis_instance.plot_fold_change(stim, group_name='Lmc_opsin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a for loop to plot the fold change for all the stimulation levels\n",
    "for stim in ['Zero', 'Low', 'Mid', 'Max', 'Pooled']:\n",
    "    analysis_instance.plot_fold_change_plotly(stim, group_name='Lmc_opsin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.plot_fold_change_plotly('Max', group_name='Lmc_opsin')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.plot_standard_deviation_plotly('Low', group_name='Lmc_opsin', data_type='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.plot_mean_firing_rate_plotly('Max', group_name='Lmc_opsin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.remove_cell_ids('Lmc_opsin', ['cid238', 'cid79'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.plot_fold_change_plotly('Pooled', group_name='Lmc_opsin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.plot_group_responses('Lmc_opsin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.plot_group_responses_histogram('Lmc_opsin', nbinsx=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_instance.plot_group_responses_histogramsubplots('Lmc_opsin', nbinsx=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Get the unique unit IDs for the specified group\n",
    "all_unit_ids = list(unit_ids)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    dcc.Checklist(\n",
    "        id='unit-selection',\n",
    "        options=[{'label': str(unit), 'value': str(unit)} for unit in all_unit_ids],\n",
    "        value=all_unit_ids  # Initially, all checkboxes are selected\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='stimulation-selection',\n",
    "        options=[{'label': stim_level, 'value': stim_level} for stim_level in ['Zero', 'Low', 'Mid', 'Max', 'Pooled']],\n",
    "        value='Zero'  # Initially, 'Zero' is selected\n",
    "    ),\n",
    "    dcc.Graph(\n",
    "        id='histogram-plot'\n",
    "    )\n",
    "])\n",
    "\n",
    "# Define the callback to update the plot based on the selected units\n",
    "@app.callback(\n",
    "    Output('histogram-plot', 'figure'),\n",
    "    Input('unit-selection', 'value'),\n",
    "    Input('stimulation-selection', 'value'),\n",
    "    Input('histogram-plot', 'relayoutData'),\n",
    ")\n",
    "def update_plot(selected_units, current_stimulation, relayoutData):\n",
    "    # Define the stimulation levels and phases\n",
    "    stim_levels = ['Zero', 'Low', 'Mid', 'Max', 'Pooled']\n",
    "    phases = ['early', 'late']\n",
    "    epochs = ['Pre', 'Post']\n",
    "\n",
    "    # Function to get pooled data for the current selection of units\n",
    "    def get_pooled_data(epoch, phase, stim_level, visible_unit_ids):\n",
    "        pooled_data = []\n",
    "        for unit_id in visible_unit_ids:\n",
    "            data = analysis_df.loc[(group_name, unit_id), f'{epoch}_{stim_level}_{phase}_response']\n",
    "            pooled_data.extend(data)\n",
    "        return pooled_data\n",
    "\n",
    "    # Create a subplot with 2 rows and 2 columns\n",
    "    fig = make_subplots(rows=2, cols=2, subplot_titles=('Pre Early', 'Pre Late', 'Post Early', 'Post Late'))\n",
    "\n",
    "    # Loop through each condition to plot the histograms\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        for j, phase in enumerate(phases):\n",
    "            data = get_pooled_data(epoch, phase, current_stimulation, selected_units)\n",
    "            fig.add_trace(go.Histogram(x=data, nbinsx=20, name='Pooled Data'), row=i+1, col=j+1)\n",
    "\n",
    "    # If the user has zoomed in, maintain the same x-axis range\n",
    "    if relayoutData:\n",
    "        for i, key in enumerate(relayoutData.keys()):\n",
    "            if 'xaxis.range' in key:\n",
    "                fig.update_xaxes(range=relayoutData[key], row=i//2+1, col=i%2+1)\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matlab_python_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
