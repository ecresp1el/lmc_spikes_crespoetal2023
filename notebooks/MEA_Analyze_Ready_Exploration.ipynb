{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS MEA — Analyze Ready (Notebook)",
    "\n",
    "Interactive exploration of already-processed IFR NPZ data following the standardized workflow:",
    "- Build/inspect the readiness index (chem + NPZ by default)",
    "- Filter by round/group/plate and pick recordings",
    "- Load an NPZ and plot channels inline with the chemical timestamp",
    "- Use per-recording IFR NPZ summary (or compute it if missing)",
    "- Optionally run NPZ stats and/or inspect the global catalog\n",
    "This notebook does NOT re-open raw H5; it works from NPZ + annotations only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairings (CTZ vs VEH) utilities\n",
    "import sys\n",
    "from pathlib import Path\n",
    "def _ensure_repo_on_path():\n",
    "    here = Path.cwd()\n",
    "    for cand in [here, *here.parents]:\n",
    "        if (cand / 'mcs_mea_analysis').exists():\n",
    "            if str(cand) not in sys.path:\n",
    "                sys.path.insert(0, str(cand))\n",
    "            return cand\n",
    "    return None\n",
    "_ensure_repo_on_path()\n",
    "from mcs_mea_analysis.pairings import PairingIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure repo root is on sys.path so `mcs_mea_analysis` is importable from notebooks/\n",
    "if not (Path.cwd() / 'mcs_mea_analysis').exists() and (Path.cwd().parent / 'mcs_mea_analysis').exists():\n",
    "    sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from mcs_mea_analysis.ready import ReadinessConfig, build_ready_index\n",
    "from mcs_mea_analysis.ifr_processing import IFRProcessorConfig, process_ifr_npz\n",
    "from mcs_mea_analysis.analysis_config import NPZAnalysisConfig\n",
    "\n",
    "# Configure outputs root: prefer external Manny2TB; fallback to local if absent\n",
    "OUTPUT_ROOT = Path('/Volumes/Manny2TB/mcs_mea_outputs')\n",
    "if not OUTPUT_ROOT.exists():\n",
    "    print('External output root not found; using local fallback _mcs_mea_outputs_local')\n",
    "    OUTPUT_ROOT = Path('_mcs_mea_outputs_local')\n",
    "ANNOTATIONS_ROOT = OUTPUT_ROOT / 'annotations'\n",
    "OUTPUT_ROOT, ANNOTATIONS_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CTZ vs VEH pairings by plate (optionally also by round)\n",
    "import sys as _sys\n",
    "from pathlib import Path as _Path\n",
    "import pandas as pd\n",
    "# Ensure readiness DataFrame 'df' exists; if not, build it quickly here\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    # Make sure repo is importable then build readiness\n",
    "    if not (_Path.cwd() / 'mcs_mea_analysis').exists() and (_Path.cwd().parent / 'mcs_mea_analysis').exists():\n",
    "        _sys.path.insert(0, str(_Path.cwd().parent))\n",
    "    from mcs_mea_analysis.ready import ReadinessConfig as _ReadinessConfig, build_ready_index as _build_ready_index\n",
    "    OUTPUT_ROOT = OUTPUT_ROOT if 'OUTPUT_ROOT' in globals() else (_Path('/Volumes/Manny2TB/mcs_mea_outputs') if (_Path('/Volumes/Manny2TB/mcs_mea_outputs').exists()) else _Path('_mcs_mea_outputs_local'))\n",
    "    ready_csv, _, ready_rows = _build_ready_index(_ReadinessConfig(output_root=OUTPUT_ROOT, require_ifr_npz=True))\n",
    "    df = pd.DataFrame(ready_rows)\n",
    "\n",
    "# Ensure PairingIndex is importable (in case prior cell wasn't run)\n",
    "try:\n",
    "    PairingIndex\n",
    "except NameError:\n",
    "    if not (_Path.cwd() / 'mcs_mea_analysis').exists() and (_Path.cwd().parent / 'mcs_mea_analysis').exists():\n",
    "        _sys.path.insert(0, str(_Path.cwd().parent))\n",
    "    from mcs_mea_analysis.pairings import PairingIndex\n",
    "\n",
    "group_by_round = True  # set False to group only by plate\n",
    "pair_index = PairingIndex.from_ready_rows(df.to_dict('records'), group_by_round=group_by_round)\n",
    "pairs_summary = pd.DataFrame(pair_index.summary_rows()).sort_values(['plate','round']).reset_index(drop=True)\n",
    "print('Groups:', len(pairs_summary))\n",
    "pairs_summary.head(12)"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded pairs table (pairs + unpaired) and ready-only pairs\n",
    "pairs_df = pd.DataFrame(pair_index.pairs_dataframe())\n",
    "print('Pair rows:', len(pairs_df))\n",
    "display(pairs_df.head(12))\n",
    "ready_pairs_df = pairs_df.query('pair_status==\"ready_pair\"')\n",
    "print('Ready pairs:', len(ready_pairs_df))\n",
    "ready_pairs_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build readiness index (chem + NPZ present by default)\n",
    "ready_cfg = ReadinessConfig(\n",
    "    output_root=OUTPUT_ROOT,\n",
    "    require_opto=False,\n",
    "    require_not_ignored=True,\n",
    "    require_eligible=False,\n",
    "    require_ifr_npz=True,\n",
    "    require_fr_summary=False,\n",
    ")\n",
    "ready_csv, ready_jsonl, ready_rows = build_ready_index(ready_cfg)\n",
    "df = pd.DataFrame(ready_rows)\n",
    "df_ready = df[df['ready'] == True].copy()\n",
    "print(f'Ready rows: {len(df_ready)} (from {ready_csv})')\n",
    "df_ready.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inventory by group/round\n",
    "group_counts = df_ready['group_label'].value_counts().sort_index()\n",
    "round_counts = df_ready['round'].value_counts().sort_index()\n",
    "display(group_counts.to_frame('count'))\n",
    "display(round_counts.to_frame('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional filters — set any of these lists to narrow the ready set\n",
    "want_groups = []   # e.g., ['CTZ']\n",
    "want_rounds = []   # e.g., ['mea_blade_round5']\n",
    "want_plates = []   # e.g., [1, 6]\n",
    "\n",
    "filtered = df_ready.copy()\n",
    "if want_groups:\n",
    "    filtered = filtered[filtered['group_label'].isin(want_groups)]\n",
    "if want_rounds:\n",
    "    filtered = filtered[filtered['round'].isin(want_rounds)]\n",
    "if want_plates:\n",
    "    filtered = filtered[[any(f'plate_{p}' in str(x) for p in want_plates) for x in filtered['path']]]\n",
    "print(f'Filtered rows: {len(filtered)}')\n",
    "filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one recording by index in the filtered frame\n",
    "row_idx = 0\n",
    "r = filtered.iloc[row_idx]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IFR NPZ and basic info\n",
    "npz_path = Path(r['npz_path'])\n",
    "stem = r['recording_stem']\n",
    "print(npz_path)\n",
    "d = np.load(npz_path)\n",
    "time_s = np.asarray(d['time_s'], dtype=float)\n",
    "ifr = np.asarray(d['ifr_hz'], dtype=float)\n",
    "ifr_s = np.asarray(d.get('ifr_hz_smooth', ifr), dtype=float)\n",
    "n_ch, n_bins = ifr_s.shape\n",
    "dur = float(time_s[-1]) if time_s.size else np.nan\n",
    "chem_ts = r.get('chem_timestamp')\n",
    "if chem_ts is None or (pd.isna(chem_ts)):\n",
    "    # Fallback: read annotations to find the first chemical timestamp\n",
    "    def chem_time_for_stem(stem: str, annotations_root: Path):\n",
    "        for ext in ('.json', '.csv'):\n",
    "            p = annotations_root / f'{stem}{ext}'\n",
    "            if not p.exists():\n",
    "                continue\n",
    "            try:\n",
    "                if p.suffix.lower() == '.json':\n",
    "                    data = json.loads(p.read_text())\n",
    "                else:\n",
    "                    with p.open('r', newline='') as fh:\n",
    "                        data = list(csv.DictReader(fh))\n",
    "                for row in data:\n",
    "                    if str(row.get('category', 'manual')).lower() == 'chemical':\n",
    "                        return float(row.get('timestamp', 0.0))\n",
    "            except Exception:\n",
    "                continue\n",
    "        return None\n",
    "    chem_ts = chem_time_for_stem(stem, ANNOTATIONS_ROOT)\n",
    "print(f'Channels: {n_ch}  bins: {n_bins}  duration(s): {dur:.1f}  chem_ts: {chem_ts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a channels grid inline (decimated for speed), with chem marker if present\n",
    "def plot_ifr_grid_inline(time_s, ifr_s, chem_ts=None, max_points=6000, ncols=6):\n",
    "    n_ch, n_bins = ifr_s.shape\n",
    "    step = max(1, int(n_bins // max_points))\n",
    "    xs = time_s[::step]\n",
    "    Y = ifr_s[:, ::step]\n",
    "    nrows = int(np.ceil(n_ch / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*3.0, nrows*1.8), sharex=True, sharey=False)\n",
    "    axes = np.asarray(axes).reshape(-1)\n",
    "    for i in range(nrows * ncols):\n",
    "        ax = axes[i]\n",
    "        if i < n_ch:\n",
    "            ax.plot(xs, Y[i, :], lw=0.6)\n",
    "            if chem_ts is not None:\n",
    "                ax.axvline(float(chem_ts), color='r', linestyle='--', lw=0.8)\n",
    "            ax.set_title(f'Ch {i}', fontsize=8)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    fig.suptitle(f'IFR (smoothed) — {stem}')\n",
    "    for ax in axes[-ncols:]:\n",
    "        ax.set_xlabel('Time (s)')\n",
    "    for r_i in range(nrows):\n",
    "        axes[r_i*ncols].set_ylabel('IFR (Hz)')\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    return fig\n",
    "\n",
    "fig = plot_ifr_grid_inline(time_s, ifr_s, chem_ts)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-recording IFR NPZ summary (compute if missing, then inspect)\n",
    "fr_dir = npz_path.parent\n",
    "sum_csv = fr_dir / f'{stem}_ifr_npz_summary.csv'\n",
    "if not sum_csv.exists():\n",
    "    print('Summary CSV not found; computing with process_ifr_npz …')\n",
    "    _ = process_ifr_npz(npz_path)\n",
    "else:\n",
    "    print('Using existing:', sum_csv)\n",
    "sum_df = pd.read_csv(sum_csv)\n",
    "display(sum_df.head())\n",
    "ax = sum_df['modulation'].value_counts().plot(kind='bar', title=f'{stem} modulation counts')\n",
    "ax.set_xlabel('modulation')\n",
    "ax.set_ylabel('channels')\n",
    "plt.show()\n",
    "sum_df[['fr_pre','fr_post']].plot(kind='hist', bins=40, alpha=0.6, title='FR pre/post (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: per-recording NPZ stats (writes *_npz_stats.csv next to NPZ)\n",
    "run_npz_stats = False\n",
    "if run_npz_stats and (chem_ts is not None):\n",
    "    from mcs_mea_analysis.npz_stats import analyze_npz\n",
    "    stats_cfg = NPZAnalysisConfig()\n",
    "    out_stats = analyze_npz(npz_path, float(chem_ts), stats_cfg)\n",
    "    stats_df = pd.read_csv(out_stats)\n",
    "    display(stats_df.head())\n",
    "else:\n",
    "    print('Skipping stats (set run_npz_stats=True and ensure chem_ts is available).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global catalog (if previously built via scripts.process_ifr_npz)\n",
    "cat_dir = OUTPUT_ROOT / 'ifr_npz_catalog'\n",
    "cat_csv = cat_dir / 'ifr_npz_catalog.csv'\n",
    "status_csv = cat_dir / 'ifr_npz_status.csv'\n",
    "if cat_csv.exists():\n",
    "    cat_df = pd.read_csv(cat_csv)\n",
    "    display(cat_df.head())\n",
    "    if status_csv.exists():\n",
    "        status_df = pd.read_csv(status_csv)\n",
    "        display(status_df.head())\n",
    "    # Example: top recordings by positive-modulation ratio\n",
    "    pos_ratio = (\n",
    "        cat_df.assign(pos=(cat_df['modulation']=='positive').astype(int))\n",
    "              .groupby('recording_stem')\n",
    "              .agg(n=('channel','size'), n_pos=('pos','sum'))\n",
    "    )\n",
    "    pos_ratio['ratio'] = pos_ratio['n_pos'] / pos_ratio['n']\n",
    "    display(pos_ratio.sort_values('ratio', ascending=False).head(10))\n",
    "else:\n",
    "    print('Catalog not found at', cat_csv)\n",
    "    print('You can build it by running scripts/process_ifr_npz.py or the cell below.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: build/rebuild global catalog from all NPZs (may take time)\n",
    "run_build_catalog = False\n",
    "if run_build_catalog:\n",
    "    from mcs_mea_analysis.ifr_processing import process_all_ifr_npz, find_ifr_npz\n",
    "    files = find_ifr_npz(OUTPUT_ROOT)\n",
    "    print('Found NPZ:', len(files))\n",
    "    _, out_cat_csv, out_status_csv = process_all_ifr_npz(files, IFRProcessorConfig(output_root=OUTPUT_ROOT))\n",
    "    print('Catalog ->', out_cat_csv)\n",
    "    print('Status  ->', out_status_csv)\n",
    "else:\n",
    "    print('Skipping catalog rebuild (set run_build_catalog=True to run).')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
