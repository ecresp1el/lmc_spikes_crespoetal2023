{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS MEA — Analyze Ready (Notebook)",
    "\n",
    "Interactive exploration of already-processed IFR NPZ data following the standardized workflow:",
    "- Build/inspect the readiness index (chem + NPZ by default)",
    "- Filter by round/group/plate and pick recordings",
    "- Load an NPZ and plot channels inline with the chemical timestamp",
    "- Use per-recording IFR NPZ summary (or compute it if missing)",
    "- Optionally run NPZ stats and/or inspect the global catalog\n",
    "This notebook does NOT re-open raw H5; it works from NPZ + annotations only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipywidgets UI: pick plate → pair → channel, then launch the 2x2 GUI\n",
    "# Falls back gracefully if ipywidgets is not installed.\n",
    "import sys as _sys, subprocess, shlex\n",
    "from pathlib import Path as _Path\n",
    "import pandas as pd\n",
    "\n",
    "def _ensure_pairs_df():\n",
    "    global df, pair_index, pairs_df, ready_pairs_df\n",
    "    try:\n",
    "        pairs_df\n",
    "        ready_pairs_df\n",
    "    except NameError:\n",
    "        # Build if missing\n",
    "        try:\n",
    "            pair_index\n",
    "        except NameError:\n",
    "            # Ensure PairingIndex import and readiness df\n",
    "            if not (_Path.cwd() / 'mcs_mea_analysis').exists() and (_Path.cwd().parent / 'mcs_mea_analysis').exists():\n",
    "                _sys.path.insert(0, str(_Path.cwd().parent))\n",
    "            from mcs_mea_analysis.pairings import PairingIndex\n",
    "            try:\n",
    "                df\n",
    "            except NameError:\n",
    "                from mcs_mea_analysis.ready import ReadinessConfig as _ReadinessConfig, build_ready_index as _build_ready_index\n",
    "                OUTPUT_ROOT = OUTPUT_ROOT if 'OUTPUT_ROOT' in globals() else (_Path('/Volumes/Manny2TB/mcs_mea_outputs') if (_Path('/Volumes/Manny2TB/mcs_mea_outputs').exists()) else _Path('_mcs_mea_outputs_local'))\n",
    "                _, _, ready_rows = _build_ready_index(_ReadinessConfig(output_root=OUTPUT_ROOT, require_ifr_npz=True))\n",
    "                df = pd.DataFrame(ready_rows)\n",
    "            pair_index = PairingIndex.from_ready_rows(df.to_dict('records'), group_by_round=True)\n",
    "        pairs_df = pd.DataFrame(pair_index.pairs_dataframe())\n",
    "        ready_pairs_df = pairs_df.query('pair_status==\"ready_pair\"').copy()\n",
    "    return ready_pairs_df\n",
    "\n",
    "try:\n",
    "    import ipywidgets as W\n",
    "    _rp = _ensure_pairs_df()\n",
    "    plates = sorted([int(p) for p in _rp['plate'].dropna().unique().tolist()])\n",
    "    dd_plate = W.Dropdown(options=plates, description='Plate:')\n",
    "    dd_pair = W.Dropdown(options=[], description='Pair:')\n",
    "    sl_ch = W.IntSlider(value=0, min=0, max=59, step=1, description='Channel:')\n",
    "    btn = W.Button(description='Launch Viewer', button_style='primary')\n",
    "    out = W.Output()\n",
    "\n",
    "    def _update_pairs(*_):\n",
    "        rpp = _rp[_rp['plate']==dd_plate.value].reset_index(drop=True)\n",
    "        # Show index and stems\n",
    "        opts = [(f"{i}: {rpp.loc[i,'ctz_stem']} vs {rpp.loc[i,'veh_stem']}", i) for i in range(len(rpp))]\n",
    "        dd_pair.options = opts\n",
    "        sl_ch.max = 59\n",
    "        sl_ch.value = 0\n",
    "    dd_plate.observe(_update_pairs, names='value')\n",
    "    if plates:\n",
    "        dd_plate.value = plates[0]\n",
    "\n",
    "    def _on_click(_):\n",
    "        rpp = _rp[_rp['plate']==dd_plate.value].reset_index(drop=True)\n",
    "        if rpp.empty:\n",
    "            with out: print('No pairs for plate', dd_plate.value); return\n",
    "        i = int(dd_pair.value) if dd_pair.value is not None else 0\n",
    "        row = rpp.iloc[i]\n",
    "        # Find H5 + chem for stems\n",
    "        ctz_h5 = df.loc[df['recording_stem']==row['ctz_stem'], 'path']\n",
    "        veh_h5 = df.loc[df['recording_stem']==row['veh_stem'], 'path']\n",
    "        chem_c = df.loc[df['recording_stem']==row['ctz_stem'], 'chem_timestamp']\n",
    "        chem_v = df.loc[df['recording_stem']==row['veh_stem'], 'chem_timestamp']\n",
    "        # Build absolute script path so import path is not required\n",
    "        def _repo_root(start):\n",
    "            p = _Path(start).resolve()\n",
    "            while p != p.parent:\n",
    "                if (p / 'scripts' / 'pair_viewer.py').exists():\n",
    "                    return p\n",
    "                p = p.parent\n",
    "            return _Path.cwd()\n",
    "        _ROOT = _repo_root(_Path.cwd())\n",
    "        _SCRIPT = _ROOT / 'scripts' / 'pair_viewer.py'\n",
    "        cmd = [sys.executable, str(_SCRIPT),\n",
    "               '--ctz-npz', str(row['ctz_npz_path']), '--veh-npz', str(row['veh_npz_path']),\n",
    "               '--plate', str(row['plate']), '--round', str(row['round']), '--ch', str(int(sl_ch.value))]\n",
    "        if not ctz_h5.empty: cmd += ['--ctz-h5', str(ctz_h5.iloc[0])]\n",
    "        if not veh_h5.empty: cmd += ['--veh-h5', str(veh_h5.iloc[0])]\n",
    "        if not chem_c.empty and pd.notna(chem_c.iloc[0]): cmd += ['--chem-ctz', str(float(chem_c.iloc[0]))]\n",
    "        if not chem_v.empty and pd.notna(chem_v.iloc[0]): cmd += ['--chem-veh', str(float(chem_v.iloc[0]))]\n",
    "        with out:\n",
    "            print('Launching:', ' '.join(shlex.quote(str(c)) for c in cmd))\n",
    "        subprocess.Popen(cmd, cwd=str(_ROOT))\n",
    "\n",
    "    btn.on_click(_on_click)\n",
    "    ui = W.VBox([W.HBox([dd_plate, dd_pair, sl_ch, btn]), out])\n",
    "    display(ui)\n",
    "except Exception as e:\n",
    "    print('ipywidgets not available or failed to initialize:', e)\n",
    "    print('You can still launch the GUI using the previous cell or via scripts.pair_viewer CLI.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved selections and build a filtered catalog of kept channels\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def load_selections(output_root: Path) -> pd.DataFrame:\n",
    "    sel_dir = output_root / 'selections'\n",
    "    rows = []\n",
    "    if not sel_dir.exists():\n",
    "        return pd.DataFrame(columns=['plate','round','ctz_stem','veh_stem','accepted_channels','n_accepted','path'])\n",
    "    for p in sel_dir.glob('*.json'):\n",
    "        try:\n",
    "            data = json.loads(p.read_text())\n",
    "            acc = sorted([int(k) for k,v in (data.get('selections') or {}).items() if v=='accept'])\n",
    "            rows.append({\n",
    "                'plate': data.get('plate'), 'round': data.get('round'),\n",
    "                'ctz_stem': Path(data.get('ctz_npz', '')).stem.replace('_ifr_per_channel_1ms',''),\n",
    "                'veh_stem': Path(data.get('veh_npz', '')).stem.replace('_ifr_per_channel_1ms',''),\n",
    "                'accepted_channels': acc, 'n_accepted': len(acc), 'path': str(p)\n",
    "            })\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def build_kept_catalog(ready_pairs_df: pd.DataFrame, selections_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Flatten accepted channels into rows with CTZ/VEH metadata for later analysis\n",
    "    recs = []\n",
    "    for _, s in selections_df.iterrows():\n",
    "        plate = s.get('plate')\n",
    "        rnd = s.get('round')\n",
    "        rp = ready_pairs_df[(ready_pairs_df['plate']==plate) & (ready_pairs_df['ctz_stem']==s['ctz_stem']) & (ready_pairs_df['veh_stem']==s['veh_stem'])]\n",
    "        if rp.empty:\n",
    "            continue\n",
    "        r = rp.iloc[0]\n",
    "        for ch in s.get('accepted_channels') or []:\n",
    "            recs.append({\n",
    "                'plate': plate, 'round': rnd, 'channel': int(ch),\n",
    "                'ctz_stem': r['ctz_stem'], 'veh_stem': r['veh_stem'],\n",
    "                'ctz_npz_path': r['ctz_npz_path'], 'veh_npz_path': r['veh_npz_path'],\n",
    "            })\n",
    "    return pd.DataFrame(recs)\n",
    "\n",
    "OUTPUT_ROOT = OUTPUT_ROOT if 'OUTPUT_ROOT' in globals() else Path('/Volumes/Manny2TB/mcs_mea_outputs')\n",
    "if not OUTPUT_ROOT.exists(): OUTPUT_ROOT = Path('_mcs_mea_outputs_local')\n",
    "selections_df = load_selections(OUTPUT_ROOT)\n",
    "display(selections_df.sort_values(['plate','ctz_stem']).reset_index(drop=True).head(20))\n",
    "kept_df = build_kept_catalog(ready_pairs_df, selections_df) if len(selections_df)>0 else pd.DataFrame(columns=['plate','round','channel','ctz_stem','veh_stem','ctz_npz_path','veh_npz_path'])\n",
    "print('Kept channels rows:', len(kept_df))\n",
    "kept_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairings (CTZ vs VEH) utilities\n",
    "import sys\n",
    "from pathlib import Path\n",
    "def _ensure_repo_on_path():\n",
    "    here = Path.cwd()\n",
    "    for cand in [here, *here.parents]:\n",
    "        if (cand / 'mcs_mea_analysis').exists():\n",
    "            if str(cand) not in sys.path:\n",
    "                sys.path.insert(0, str(cand))\n",
    "            return cand\n",
    "    return None\n",
    "_ensure_repo_on_path()\n",
    "from mcs_mea_analysis.pairings import PairingIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure repo root is on sys.path so `mcs_mea_analysis` is importable from notebooks/\n",
    "if not (Path.cwd() / 'mcs_mea_analysis').exists() and (Path.cwd().parent / 'mcs_mea_analysis').exists():\n",
    "    sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from mcs_mea_analysis.ready import ReadinessConfig, build_ready_index\n",
    "from mcs_mea_analysis.ifr_processing import IFRProcessorConfig, process_ifr_npz\n",
    "from mcs_mea_analysis.analysis_config import NPZAnalysisConfig\n",
    "\n",
    "# Configure outputs root: prefer external Manny2TB; fallback to local if absent\n",
    "OUTPUT_ROOT = Path('/Volumes/Manny2TB/mcs_mea_outputs')\n",
    "if not OUTPUT_ROOT.exists():\n",
    "    print('External output root not found; using local fallback _mcs_mea_outputs_local')\n",
    "    OUTPUT_ROOT = Path('_mcs_mea_outputs_local')\n",
    "ANNOTATIONS_ROOT = OUTPUT_ROOT / 'annotations'\n",
    "OUTPUT_ROOT, ANNOTATIONS_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CTZ vs VEH pairings by plate (optionally also by round)\n",
    "import sys as _sys\n",
    "from pathlib import Path as _Path\n",
    "import pandas as pd\n",
    "# Ensure readiness DataFrame 'df' exists; if not, build it quickly here\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    # Make sure repo is importable then build readiness\n",
    "    if not (_Path.cwd() / 'mcs_mea_analysis').exists() and (_Path.cwd().parent / 'mcs_mea_analysis').exists():\n",
    "        _sys.path.insert(0, str(_Path.cwd().parent))\n",
    "    from mcs_mea_analysis.ready import ReadinessConfig as _ReadinessConfig, build_ready_index as _build_ready_index\n",
    "    OUTPUT_ROOT = OUTPUT_ROOT if 'OUTPUT_ROOT' in globals() else (_Path('/Volumes/Manny2TB/mcs_mea_outputs') if (_Path('/Volumes/Manny2TB/mcs_mea_outputs').exists()) else _Path('_mcs_mea_outputs_local'))\n",
    "    ready_csv, _, ready_rows = _build_ready_index(_ReadinessConfig(output_root=OUTPUT_ROOT, require_ifr_npz=True))\n",
    "    df = pd.DataFrame(ready_rows)\n",
    "\n",
    "# Ensure PairingIndex is importable (in case prior cell wasn't run)\n",
    "try:\n",
    "    PairingIndex\n",
    "except NameError:\n",
    "    if not (_Path.cwd() / 'mcs_mea_analysis').exists() and (_Path.cwd().parent / 'mcs_mea_analysis').exists():\n",
    "        _sys.path.insert(0, str(_Path.cwd().parent))\n",
    "    from mcs_mea_analysis.pairings import PairingIndex\n",
    "\n",
    "group_by_round = True  # set False to group only by plate\n",
    "pair_index = PairingIndex.from_ready_rows(df.to_dict('records'), group_by_round=group_by_round)\n",
    "pairs_summary = pd.DataFrame(pair_index.summary_rows()).sort_values(['plate','round']).reset_index(drop=True)\n",
    "print('Groups:', len(pairs_summary))\n",
    "pairs_summary.head(12)"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded pairs table (pairs + unpaired) and ready-only pairs\n",
    "pairs_df = pd.DataFrame(pair_index.pairs_dataframe())\n",
    "print('Pair rows:', len(pairs_df))\n",
    "display(pairs_df.head(12))\n",
    "ready_pairs_df = pairs_df.query('pair_status==\"ready_pair\"')\n",
    "print('Ready pairs:', len(ready_pairs_df))\n",
    "ready_pairs_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build readiness index (chem + NPZ present by default)\n",
    "ready_cfg = ReadinessConfig(\n",
    "    output_root=OUTPUT_ROOT,\n",
    "    require_opto=False,\n",
    "    require_not_ignored=True,\n",
    "    require_eligible=False,\n",
    "    require_ifr_npz=True,\n",
    "    require_fr_summary=False,\n",
    ")\n",
    "ready_csv, ready_jsonl, ready_rows = build_ready_index(ready_cfg)\n",
    "df = pd.DataFrame(ready_rows)\n",
    "df_ready = df[df['ready'] == True].copy()\n",
    "print(f'Ready rows: {len(df_ready)} (from {ready_csv})')\n",
    "df_ready.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inventory by group/round\n",
    "group_counts = df_ready['group_label'].value_counts().sort_index()\n",
    "round_counts = df_ready['round'].value_counts().sort_index()\n",
    "display(group_counts.to_frame('count'))\n",
    "display(round_counts.to_frame('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional filters — set any of these lists to narrow the ready set\n",
    "want_groups = []   # e.g., ['CTZ']\n",
    "want_rounds = []   # e.g., ['mea_blade_round5']\n",
    "want_plates = []   # e.g., [1, 6]\n",
    "\n",
    "filtered = df_ready.copy()\n",
    "if want_groups:\n",
    "    filtered = filtered[filtered['group_label'].isin(want_groups)]\n",
    "if want_rounds:\n",
    "    filtered = filtered[filtered['round'].isin(want_rounds)]\n",
    "if want_plates:\n",
    "    filtered = filtered[[any(f'plate_{p}' in str(x) for p in want_plates) for x in filtered['path']]]\n",
    "print(f'Filtered rows: {len(filtered)}')\n",
    "filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one recording by index in the filtered frame\n",
    "row_idx = 0\n",
    "r = filtered.iloc[row_idx]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IFR NPZ and basic info\n",
    "npz_path = Path(r['npz_path'])\n",
    "stem = r['recording_stem']\n",
    "print(npz_path)\n",
    "d = np.load(npz_path)\n",
    "time_s = np.asarray(d['time_s'], dtype=float)\n",
    "ifr = np.asarray(d['ifr_hz'], dtype=float)\n",
    "ifr_s = np.asarray(d.get('ifr_hz_smooth', ifr), dtype=float)\n",
    "n_ch, n_bins = ifr_s.shape\n",
    "dur = float(time_s[-1]) if time_s.size else np.nan\n",
    "chem_ts = r.get('chem_timestamp')\n",
    "if chem_ts is None or (pd.isna(chem_ts)):\n",
    "    # Fallback: read annotations to find the first chemical timestamp\n",
    "    def chem_time_for_stem(stem: str, annotations_root: Path):\n",
    "        for ext in ('.json', '.csv'):\n",
    "            p = annotations_root / f'{stem}{ext}'\n",
    "            if not p.exists():\n",
    "                continue\n",
    "            try:\n",
    "                if p.suffix.lower() == '.json':\n",
    "                    data = json.loads(p.read_text())\n",
    "                else:\n",
    "                    with p.open('r', newline='') as fh:\n",
    "                        data = list(csv.DictReader(fh))\n",
    "                for row in data:\n",
    "                    if str(row.get('category', 'manual')).lower() == 'chemical':\n",
    "                        return float(row.get('timestamp', 0.0))\n",
    "            except Exception:\n",
    "                continue\n",
    "        return None\n",
    "    chem_ts = chem_time_for_stem(stem, ANNOTATIONS_ROOT)\n",
    "print(f'Channels: {n_ch}  bins: {n_bins}  duration(s): {dur:.1f}  chem_ts: {chem_ts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a channels grid inline (decimated for speed), with chem marker if present\n",
    "def plot_ifr_grid_inline(time_s, ifr_s, chem_ts=None, max_points=6000, ncols=6):\n",
    "    n_ch, n_bins = ifr_s.shape\n",
    "    step = max(1, int(n_bins // max_points))\n",
    "    xs = time_s[::step]\n",
    "    Y = ifr_s[:, ::step]\n",
    "    nrows = int(np.ceil(n_ch / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*3.0, nrows*1.8), sharex=True, sharey=False)\n",
    "    axes = np.asarray(axes).reshape(-1)\n",
    "    for i in range(nrows * ncols):\n",
    "        ax = axes[i]\n",
    "        if i < n_ch:\n",
    "            ax.plot(xs, Y[i, :], lw=0.6)\n",
    "            if chem_ts is not None:\n",
    "                ax.axvline(float(chem_ts), color='r', linestyle='--', lw=0.8)\n",
    "            ax.set_title(f'Ch {i}', fontsize=8)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    fig.suptitle(f'IFR (smoothed) — {stem}')\n",
    "    for ax in axes[-ncols:]:\n",
    "        ax.set_xlabel('Time (s)')\n",
    "    for r_i in range(nrows):\n",
    "        axes[r_i*ncols].set_ylabel('IFR (Hz)')\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    return fig\n",
    "\n",
    "fig = plot_ifr_grid_inline(time_s, ifr_s, chem_ts)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-recording IFR NPZ summary (compute if missing, then inspect)\n",
    "fr_dir = npz_path.parent\n",
    "sum_csv = fr_dir / f'{stem}_ifr_npz_summary.csv'\n",
    "if not sum_csv.exists():\n",
    "    print('Summary CSV not found; computing with process_ifr_npz …')\n",
    "    _ = process_ifr_npz(npz_path)\n",
    "else:\n",
    "    print('Using existing:', sum_csv)\n",
    "sum_df = pd.read_csv(sum_csv)\n",
    "display(sum_df.head())\n",
    "ax = sum_df['modulation'].value_counts().plot(kind='bar', title=f'{stem} modulation counts')\n",
    "ax.set_xlabel('modulation')\n",
    "ax.set_ylabel('channels')\n",
    "plt.show()\n",
    "sum_df[['fr_pre','fr_post']].plot(kind='hist', bins=40, alpha=0.6, title='FR pre/post (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: per-recording NPZ stats (writes *_npz_stats.csv next to NPZ)\n",
    "run_npz_stats = False\n",
    "if run_npz_stats and (chem_ts is not None):\n",
    "    from mcs_mea_analysis.npz_stats import analyze_npz\n",
    "    stats_cfg = NPZAnalysisConfig()\n",
    "    out_stats = analyze_npz(npz_path, float(chem_ts), stats_cfg)\n",
    "    stats_df = pd.read_csv(out_stats)\n",
    "    display(stats_df.head())\n",
    "else:\n",
    "    print('Skipping stats (set run_npz_stats=True and ensure chem_ts is available).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global catalog (if previously built via scripts.process_ifr_npz)\n",
    "cat_dir = OUTPUT_ROOT / 'ifr_npz_catalog'\n",
    "cat_csv = cat_dir / 'ifr_npz_catalog.csv'\n",
    "status_csv = cat_dir / 'ifr_npz_status.csv'\n",
    "if cat_csv.exists():\n",
    "    cat_df = pd.read_csv(cat_csv)\n",
    "    display(cat_df.head())\n",
    "    if status_csv.exists():\n",
    "        status_df = pd.read_csv(status_csv)\n",
    "        display(status_df.head())\n",
    "    # Example: top recordings by positive-modulation ratio\n",
    "    pos_ratio = (\n",
    "        cat_df.assign(pos=(cat_df['modulation']=='positive').astype(int))\n",
    "              .groupby('recording_stem')\n",
    "              .agg(n=('channel','size'), n_pos=('pos','sum'))\n",
    "    )\n",
    "    pos_ratio['ratio'] = pos_ratio['n_pos'] / pos_ratio['n']\n",
    "    display(pos_ratio.sort_values('ratio', ascending=False).head(10))\n",
    "else:\n",
    "    print('Catalog not found at', cat_csv)\n",
    "    print('You can build it by running scripts/process_ifr_npz.py or the cell below.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: build/rebuild global catalog from all NPZs (may take time)\n",
    "run_build_catalog = False\n",
    "if run_build_catalog:\n",
    "    from mcs_mea_analysis.ifr_processing import process_all_ifr_npz, find_ifr_npz\n",
    "    files = find_ifr_npz(OUTPUT_ROOT)\n",
    "    print('Found NPZ:', len(files))\n",
    "    _, out_cat_csv, out_status_csv = process_all_ifr_npz(files, IFRProcessorConfig(output_root=OUTPUT_ROOT))\n",
    "    print('Catalog ->', out_cat_csv)\n",
    "    print('Status  ->', out_status_csv)\n",
    "else:\n",
    "    print('Skipping catalog rebuild (set run_build_catalog=True to run).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many CTZ–VEH ready pairs overall and by plate\n",
    "# Uses 'ready_pairs_df' from the previous cell; rebuilds if missing.\n",
    "import pandas as pd\n",
    "try:\n",
    "    ready_pairs_df\n",
    "except NameError:\n",
    "    # Build pairs_df and filter ready pairs\n",
    "    try:\n",
    "        pair_index\n",
    "    except NameError:\n",
    "        # Ensure PairingIndex import\n",
    "        import sys as _sys\n",
    "        from pathlib import Path as _Path\n",
    "        if not (_Path.cwd() / 'mcs_mea_analysis').exists() and (_Path.cwd().parent / 'mcs_mea_analysis').exists():\n",
    "            _sys.path.insert(0, str(_Path.cwd().parent))\n",
    "        from mcs_mea_analysis.pairings import PairingIndex\n",
    "        # Ensure readiness df exists\n",
    "        try:\n",
    "            df\n",
    "        except NameError:\n",
    "            from mcs_mea_analysis.ready import ReadinessConfig as _ReadinessConfig, build_ready_index as _build_ready_index\n",
    "            OUTPUT_ROOT = OUTPUT_ROOT if 'OUTPUT_ROOT' in globals() else (_Path('/Volumes/Manny2TB/mcs_mea_outputs') if (_Path('/Volumes/Manny2TB/mcs_mea_outputs').exists()) else _Path('_mcs_mea_outputs_local'))\n",
    "            _, _, ready_rows = _build_ready_index(_ReadinessConfig(output_root=OUTPUT_ROOT, require_ifr_npz=True))\n",
    "            df = pd.DataFrame(ready_rows)\n",
    "        pair_index = PairingIndex.from_ready_rows(df.to_dict('records'), group_by_round=True)\n",
    "    pairs_df = pd.DataFrame(pair_index.pairs_dataframe())\n",
    "    ready_pairs_df = pairs_df.query('pair_status==\"ready_pair\"').copy()\n",
    "\n",
    "total_pairs = len(ready_pairs_df)\n",
    "pairs_per_plate = ready_pairs_df.groupby('plate').size().sort_index()\n",
    "print(f'Total ready pairs: {total_pairs}')\n",
    "display(pairs_per_plate.to_frame('n_pairs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View matching electrodes (same channel index) side-by-side for a selected ready pair\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a plate and a pair within that plate\n",
    "plate_sel = None  # e.g., set to an integer plate id like 1; None = first available\n",
    "_pairs_in_plate = ready_pairs_df if plate_sel is None else ready_pairs_df[ready_pairs_df['plate']==plate_sel]\n",
    "row = _pairs_in_plate.iloc[0]\n",
    "print('Using plate:', row['plate'], 'pair:', row['ctz_stem'], 'vs', row['veh_stem'])\n",
    "\n",
    "ctz_npz = Path(row['ctz_npz_path']); veh_npz = Path(row['veh_npz_path'])\n",
    "ctz = np.load(ctz_npz); veh = np.load(veh_npz)\n",
    "t_ctz = np.asarray(ctz['time_s'], dtype=float); Y_ctz = np.asarray(ctz.get('ifr_hz_smooth', ctz['ifr_hz']), dtype=float)\n",
    "t_veh = np.asarray(veh['time_s'], dtype=float); Y_veh = np.asarray(veh.get('ifr_hz_smooth', veh['ifr_hz']), dtype=float)\n",
    "assert Y_ctz.shape[0] == Y_veh.shape[0], 'Channel count mismatch between CTZ and VEH'\n",
    "n_ch = Y_ctz.shape[0]\n",
    "\n",
    "# Choose a channel to visualize\n",
    "ch = 0  # change this to scan different electrodes\n",
    "# Decimate for speed\n",
    "def _decimate(ts, y, max_points=6000):\n",
    "    step = max(1, int(y.shape[-1]//max_points))\n",
    "    return ts[::step], y[..., ::step]\n",
    "xs_c, yc = _decimate(t_ctz, Y_ctz[ch, :])\n",
    "xs_v, yv = _decimate(t_veh, Y_veh[ch, :])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 3), sharey=True)\n",
    "axes[0].plot(xs_c, yc, lw=0.7); axes[0].set_title(f'CTZ — ch {ch}')\n",
    "axes[1].plot(xs_v, yv, lw=0.7, color='orange'); axes[1].set_title(f'VEH — ch {ch}')\n",
    "# Chem markers if available\n",
    "chem_c = df.loc[df['recording_stem']==row['ctz_stem'], 'chem_timestamp']\n",
    "chem_v = df.loc[df['recording_stem']==row['veh_stem'], 'chem_timestamp']\n",
    "if not chem_c.empty and pd.notna(chem_c.iloc[0]): axes[0].axvline(float(chem_c.iloc[0]), color='r', ls='--', lw=0.8)\n",
    "if not chem_v.empty and pd.notna(chem_v.iloc[0]): axes[1].axvline(float(chem_v.iloc[0]), color='r', ls='--', lw=0.8)\n",
    "for ax in axes: ax.set_xlabel('Time (s)'); axes[0].set_ylabel('IFR (Hz)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch interactive GUI viewer for this pair (2x2: raw + IFR)\n",
    "# Requires PyQt5 + pyqtgraph and access to raw H5 files.\n",
    "import shlex, sys\n",
    "from pathlib import Path as _Path\n",
    "def _repo_root(start):\n",
    "    p = _Path(start).resolve()\n",
    "    while p != p.parent:\n",
    "        if (p / 'scripts' / 'pair_viewer.py').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return _Path.cwd()\n",
    "_ROOT = _repo_root(_Path.cwd())\n",
    "_SCRIPT = _ROOT / 'scripts' / 'pair_viewer.py'\n",
    "cmd = [sys.executable, str(_SCRIPT),\n",
    "       '--ctz-npz', str(ctz_npz), '--veh-npz', str(veh_npz),\n",
    "       '--plate', str(row['plate'])]\n",
    "# Add H5 and chem if available\n",
    "ctz_h5 = df.loc[df['recording_stem']==row['ctz_stem'], 'path']\n",
    "veh_h5 = df.loc[df['recording_stem']==row['veh_stem'], 'path']\n",
    "if not ctz_h5.empty: cmd += ['--ctz-h5', str(ctz_h5.iloc[0])]\n",
    "if not veh_h5.empty: cmd += ['--veh-h5', str(veh_h5.iloc[0])]\n",
    "chem_c = df.loc[df['recording_stem']==row['ctz_stem'], 'chem_timestamp']\n",
    "chem_v = df.loc[df['recording_stem']==row['veh_stem'], 'chem_timestamp']\n",
    "if not chem_c.empty and pd.notna(chem_c.iloc[0]): cmd += ['--chem-ctz', str(float(chem_c.iloc[0]))]\n",
    "if not chem_v.empty and pd.notna(chem_v.iloc[0]): cmd += ['--chem-veh', str(float(chem_v.iloc[0]))]\n",
    "print('Launching:', ' '.join(shlex.quote(str(c)) for c in cmd))\n",
    "# In Jupyter, this spawns the GUI; you will need to close it to continue.\n",
    "import subprocess; subprocess.Popen(cmd, cwd=str(_ROOT))  # non-blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find candidate electrodes where CTZ changes but VEH does not (per IFR summary modulation)\n",
    "import pandas as pd\n",
    "from mcs_mea_analysis.ifr_processing import process_ifr_npz\n",
    "\n",
    "def _summary_df(stem: str, npz_path: Path) -> pd.DataFrame:\n",
    "    fr_dir = npz_path.parent\n",
    "    sum_csv = fr_dir / f'{stem}_ifr_npz_summary.csv'\n",
    "    if not sum_csv.exists():\n",
    "        _ = process_ifr_npz(npz_path)\n",
    "    return pd.read_csv(sum_csv)\n",
    "\n",
    "ctz_sum = _summary_df(row['ctz_stem'], ctz_npz)\n",
    "veh_sum = _summary_df(row['veh_stem'], veh_npz)\n",
    "merged = ctz_sum[['channel','modulation']].merge(veh_sum[['channel','modulation']], on='channel', suffixes=('_ctz','_veh'))\n",
    "candidates = merged[(merged['modulation_ctz']!='nochange') & (merged['modulation_veh']=='nochange')]['channel'].tolist()\n",
    "print('Candidate electrodes (CTZ changed, VEH not):', len(candidates))\n",
    "candidates[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
