{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEA Exports Analysis — Spikes + Waveforms\n",
    "\n",
    "Analyze and aggregate the per-pair exports produced by the Pair Viewer or the batch exporter.\n",
    "\n",
    "- Exports location: `<output_root>/exports/spikes_waveforms/...`\n",
    "- Format details: see `docs/exports_spikes_waveforms.md` in this repo (variable types, dataset names, and attributes).\n",
    "- This notebook auto-discovers pairs, loads HDF5/CSV per pair, and can aggregate per-plate.\n",
    "\n",
    "Tip: If your external drive is not mounted, set `OUTPUT_ROOT` to `_mcs_mea_outputs_local`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e119a1",
   "metadata": {},
   "source": [
    "## FR Box Plots\n",
    "Channel-level and per-pair mean firing rate distributions comparing CTZ vs VEH across all exported pairs.\n",
    "This cell discovers exports on disk and does not depend on prior variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-contained FR box plots (no dependency on df_pairs)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "\n",
    "# Resolve exports directory\n",
    "try:\n",
    "    EXPORTS_DIR\n",
    "except NameError:\n",
    "    try:\n",
    "        from mcs_mea_analysis.config import CONFIG\n",
    "        REPO_ROOT = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p/'mcs_mea_analysis').exists()), Path.cwd())\n",
    "        OUTPUT_ROOT = CONFIG.output_root if CONFIG.output_root.exists() else (REPO_ROOT / '_mcs_mea_outputs_local')\n",
    "        EXPORTS_DIR = OUTPUT_ROOT / 'exports' / 'spikes_waveforms'\n",
    "    except Exception:\n",
    "        EXPORTS_DIR = Path('/Volumes/Manny2TB/mcs_mea_outputs/exports/spikes_waveforms')\n",
    "print('Exports dir ->', EXPORTS_DIR)\n",
    "\n",
    "# Load all per-pair summary CSVs\n",
    "rows = []\n",
    "for csvp in EXPORTS_DIR.rglob('*_summary.csv'):\n",
    "    try:\n",
    "        # Extract plate/round from path\n",
    "        round_name = csvp.parents[1].name if len(csvp.parents) > 1 else None\n",
    "        plate = None\n",
    "        try:\n",
    "            ps = csvp.parent.name\n",
    "            plate = int(ps.replace('plate_', '')) if ps.startswith('plate_') else None\n",
    "        except Exception:\n",
    "            pass\n",
    "        base = csvp.stem.replace('_summary','')\n",
    "        pair_id = base\n",
    "        df = pd.read_csv(csvp)\n",
    "        # Types\n",
    "        df['fr_hz'] = pd.to_numeric(df['fr_hz'], errors='coerce')\n",
    "        df['channel'] = pd.to_numeric(df['channel'], errors='coerce').astype('Int64')\n",
    "        df['side'] = df['side'].astype(str)\n",
    "        df['pair_id'] = pair_id\n",
    "        df['plate'] = plate\n",
    "        df['round'] = round_name\n",
    "        rows.append(df)\n",
    "    except Exception as e:\n",
    "        print('Skip', csvp.name, ':', e)\n",
    "\n",
    "data = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=['channel','side','n_spikes','fr_hz','pair_id','plate','round'])\n",
    "print('Rows loaded:', len(data), 'from', len(rows), 'pairs')\n",
    "\n",
    "if data.empty:\n",
    "    print('No summary CSVs found under', EXPORTS_DIR)\n",
    "else:\n",
    "    # Channel-level box plot (CTZ vs VEH)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=data, x='side', y='fr_hz')\n",
    "        sns.stripplot(data=data, x='side', y='fr_hz', color='k', size=2, alpha=0.3)\n",
    "    else:\n",
    "        # Fallback to matplotlib only\n",
    "        groups = [data[data['side']=='CTZ']['fr_hz'].dropna(), data[data['side']=='VEH']['fr_hz'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.title('Firing Rate (Hz) by Treatment — Channel Level')\n",
    "    plt.ylabel('FR (Hz)'); plt.xlabel('')\n",
    "    plt.show()\n",
    "\n",
    "    # Per-pair mean FR box plot\n",
    "    mean_per_pair = (\n",
    "        data.groupby(['pair_id','side'], as_index=False)['fr_hz'].mean()\n",
    "        .rename(columns={'fr_hz':'mean_fr_hz'})\n",
    "    )\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=mean_per_pair, x='side', y='mean_fr_hz')\n",
    "        sns.stripplot(data=mean_per_pair, x='side', y='mean_fr_hz', color='k', size=3, alpha=0.5)\n",
    "    else:\n",
    "        groups = [mean_per_pair[mean_per_pair['side']=='CTZ']['mean_fr_hz'].dropna(),\n",
    "                  mean_per_pair[mean_per_pair['side']=='VEH']['mean_fr_hz'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.title('Mean Firing Rate (Hz) by Treatment — Per-Pair Means')\n",
    "    plt.ylabel('Mean FR (Hz)'); plt.xlabel('')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FR box plots across all exported pairs (no other vars needed)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "\n",
    "# Resolve exports directory\n",
    "try:\n",
    "    from mcs_mea_analysis.config import CONFIG\n",
    "    REPO_ROOT = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p/'mcs_mea_analysis').exists()), Path.cwd())\n",
    "    OUTPUT_ROOT = CONFIG.output_root if CONFIG.output_root.exists() else (REPO_ROOT / '_mcs_mea_outputs_local')\n",
    "    EXPORTS_DIR = OUTPUT_ROOT / 'exports' / 'spikes_waveforms'\n",
    "except Exception:\n",
    "    EXPORTS_DIR = Path('/Volumes/Manny2TB/mcs_mea_outputs/exports/spikes_waveforms')\n",
    "\n",
    "print('Exports dir ->', EXPORTS_DIR)\n",
    "\n",
    "# Load all per-pair summary CSVs\n",
    "rows = []\n",
    "for csvp in EXPORTS_DIR.rglob('*_summary.csv'):\n",
    "    try:\n",
    "        round_name = csvp.parents[1].name if len(csvp.parents) > 1 else None\n",
    "        plate = None\n",
    "        try:\n",
    "            ps = csvp.parent.name\n",
    "            plate = int(ps.replace('plate_', '')) if ps.startswith('plate_') else None\n",
    "        except Exception:\n",
    "            pass\n",
    "        pair_id = csvp.stem.replace('_summary', '')\n",
    "        df = pd.read_csv(csvp)\n",
    "        df['fr_hz'] = pd.to_numeric(df['fr_hz'], errors='coerce')\n",
    "        df['channel'] = pd.to_numeric(df['channel'], errors='coerce').astype('Int64')\n",
    "        df['side'] = df['side'].astype(str)\n",
    "        df['pair_id'] = pair_id\n",
    "        df['plate'] = plate\n",
    "        df['round'] = round_name\n",
    "        rows.append(df)\n",
    "    except Exception as e:\n",
    "        print('Skip', csvp.name, ':', e)\n",
    "\n",
    "data = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=['channel','side','n_spikes','fr_hz','pair_id','plate','round'])\n",
    "print('Rows loaded:', len(data), 'from', len(rows), 'pairs')\n",
    "\n",
    "if data.empty:\n",
    "    print('No summary CSVs found under', EXPORTS_DIR)\n",
    "else:\n",
    "    # Channel-level box plot (CTZ vs VEH)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=data, x='side', y='fr_hz')\n",
    "        sns.stripplot(data=data, x='side', y='fr_hz', color='k', size=2, alpha=0.3)\n",
    "    else:\n",
    "        groups = [data[data['side']=='CTZ']['fr_hz'].dropna(), data[data['side']=='VEH']['fr_hz'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.title('Firing Rate (Hz) by Treatment — Channel Level')\n",
    "    plt.ylabel('FR (Hz)'); plt.xlabel('')\n",
    "    plt.show()\n",
    "\n",
    "    # Per-pair mean FR box plot\n",
    "    mean_per_pair = (\n",
    "        data.groupby(['pair_id','side'], as_index=False)['fr_hz'].mean()\n",
    "            .rename(columns={'fr_hz':'mean_fr_hz'})\n",
    "    )\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=mean_per_pair, x='side', y='mean_fr_hz')\n",
    "        sns.stripplot(data=mean_per_pair, x='side', y='mean_fr_hz', color='k', size=3, alpha=0.5)\n",
    "    else:\n",
    "        groups = [mean_per_pair[mean_per_pair['side']=='CTZ']['mean_fr_hz'].dropna(),\n",
    "                  mean_per_pair[mean_per_pair['side']=='VEH']['mean_fr_hz'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.title('Mean Firing Rate (Hz) by Treatment — Per-Pair Means')\n",
    "    plt.ylabel('Mean FR (Hz)'); plt.xlabel('')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87adb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre/Post FR and spike durations (uses exported HDF5s)\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "\n",
    "try:\n",
    "    from scipy import signal\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"This cell needs scipy installed (for peak widths).\") from e\n",
    "\n",
    "# Resolve exports directory\n",
    "try:\n",
    "    from mcs_mea_analysis.config import CONFIG\n",
    "    REPO_ROOT = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p/'mcs_mea_analysis').exists()), Path.cwd())\n",
    "    OUTPUT_ROOT = CONFIG.output_root if CONFIG.output_root.exists() else (REPO_ROOT / '_mcs_mea_outputs_local')\n",
    "    EXPORTS_DIR = OUTPUT_ROOT / 'exports' / 'spikes_waveforms'\n",
    "except Exception:\n",
    "    EXPORTS_DIR = Path('/Volumes/Manny2TB/mcs_mea_outputs/exports/spikes_waveforms')\n",
    "\n",
    "def _noise_level(y: np.ndarray, method: str, pctl: float) -> float:\n",
    "    if y.size == 0:\n",
    "        return np.nan\n",
    "    if method == 'mad':\n",
    "        med = np.median(y)\n",
    "        return 1.4826 * np.median(np.abs(y - med))\n",
    "    if method == 'rms':\n",
    "        return float(np.sqrt(np.mean(np.square(y))))\n",
    "    if method == 'pctl':\n",
    "        med = np.median(y)\n",
    "        return float(np.percentile(np.abs(y - med), pctl))\n",
    "    return np.nan\n",
    "\n",
    "def _parse_bounds_attr(attr_val):\n",
    "    try:\n",
    "        if isinstance(attr_val, (bytes, bytearray)):\n",
    "            attr_val = attr_val.decode()\n",
    "        d = json.loads(attr_val) if isinstance(attr_val, str) else attr_val\n",
    "        return float(d.get('t0', 0.0)), float(d.get('t1', 0.0))\n",
    "    except Exception:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "def detect_pre_post(t: np.ndarray, y: np.ndarray, sr_hz: float,\n",
    "                    t0b: float, t1b: float, t0a: float, t1a: float, dcfg: dict):\n",
    "    # masks\n",
    "    mb = (t >= t0b) & (t <= t1b)\n",
    "    ma = (t >= t0a) & (t <= t1a)\n",
    "    yb = y[mb]\n",
    "    noise = _noise_level(yb, str(dcfg.get('noise','mad')), float(dcfg.get('noise_percentile',68.0)))\n",
    "    if not np.isfinite(noise) or noise <= 0:\n",
    "        return np.empty(0), np.empty(0), np.empty(0), np.empty(0)\n",
    "    thr = float(dcfg.get('K', 5.0)) * noise\n",
    "    dist = max(1, int(round(float(dcfg.get('refractory_ms',1.0)) * 1e-3 * sr_hz)))\n",
    "    minw = max(1, int(round(float(dcfg.get('min_width_ms',0.3)) * 1e-3 * sr_hz)))\n",
    "    pol = str(dcfg.get('polarity','neg'))\n",
    "\n",
    "    def detect_on_window(mask):\n",
    "        ta = t[mask]; ya = y[mask]\n",
    "        if ta.size == 0:\n",
    "            return np.empty(0), np.empty(0)\n",
    "        arr = -ya if pol in ('neg','both') else ya\n",
    "        peaks, _ = signal.find_peaks(arr, height=thr, distance=dist, width=minw)\n",
    "        widths, _, _, _ = signal.peak_widths(arr, peaks, rel_height=0.5) if peaks.size else (np.empty(0),)*4\n",
    "        st = ta[peaks] if peaks.size else np.empty(0)\n",
    "        w_ms = (widths / float(sr_hz)) * 1000.0 if widths.size else np.empty(0)\n",
    "        return st, w_ms\n",
    "\n",
    "    st_pre, w_pre_ms = detect_on_window(mb)\n",
    "    st_post, w_post_ms = detect_on_window(ma)\n",
    "    return st_pre, w_pre_ms, st_post, w_post_ms\n",
    "\n",
    "rows_fr = []\n",
    "rows_dur = []\n",
    "\n",
    "for h5 in EXPORTS_DIR.rglob('*.h5'):\n",
    "    if h5.name.endswith('_summary.h5'):\n",
    "        continue\n",
    "    try:\n",
    "        round_name = h5.parents[1].name if len(h5.parents) > 1 else None\n",
    "        plate = None\n",
    "        try:\n",
    "            ps = h5.parent.name\n",
    "            plate = int(ps.replace('plate_', '')) if ps.startswith('plate_') else None\n",
    "        except Exception:\n",
    "            pass\n",
    "        pair_id = h5.stem\n",
    "        with h5py.File(h5.as_posix(),'r') as f:\n",
    "            dcfg = {}\n",
    "            if 'detect_config_json' in f:\n",
    "                try:\n",
    "                    dcfg = json.loads(f['detect_config_json'][()].decode())\n",
    "                except Exception:\n",
    "                    dcfg = {}\n",
    "            for side in ('CTZ','VEH'):\n",
    "                if side not in f: \n",
    "                    continue\n",
    "                g = f[side]\n",
    "                sr = float(g.attrs.get('sr_hz', 0.0)) or 10000.0\n",
    "                t0b, t1b = _parse_bounds_attr(g.attrs.get('baseline_bounds', '{\"t0\":0,\"t1\":0}'))\n",
    "                t0a, t1a = _parse_bounds_attr(g.attrs.get('analysis_bounds', '{\"t0\":0,\"t1\":0}'))\n",
    "                chs = sorted(int(k[2:4]) for k in g.keys() if k.startswith('ch') and k.endswith('_time'))\n",
    "                for ch in chs:\n",
    "                    t = g[f'ch{ch:02d}_time'][:] if f'ch{ch:02d}_time' in g else np.empty(0)\n",
    "                    yf = g[f'ch{ch:02d}_filtered'][:] if f'ch{ch:02d}_filtered' in g else np.empty(0)\n",
    "                    if t.size == 0 or yf.size == 0:\n",
    "                        continue\n",
    "                    st_pre, w_pre, st_post, w_post = detect_pre_post(t, yf, sr, t0b, t1b, t0a, t1a, dcfg)\n",
    "                    dur_pre = max(1e-9, (t1b - t0b))\n",
    "                    dur_post = max(1e-9, (t1a - t0a))\n",
    "                    fr_pre = (st_pre.size / dur_pre) if dur_pre > 0 else np.nan\n",
    "                    fr_post = (st_post.size / dur_post) if dur_post > 0 else np.nan\n",
    "                    rows_fr.append({'pair_id': pair_id, 'plate': plate, 'round': round_name, 'side': side, 'channel': ch, 'period': 'pre', 'fr_hz': fr_pre})\n",
    "                    rows_fr.append({'pair_id': pair_id, 'plate': plate, 'round': round_name, 'side': side, 'channel': ch, 'period': 'post', 'fr_hz': fr_post})\n",
    "                    for dms in w_pre:\n",
    "                        rows_dur.append({'pair_id': pair_id, 'plate': plate, 'round': round_name, 'side': side, 'channel': ch, 'period': 'pre', 'width_ms': float(dms)})\n",
    "                    for dms in w_post:\n",
    "                        rows_dur.append({'pair_id': pair_id, 'plate': plate, 'round': round_name, 'side': side, 'channel': ch, 'period': 'post', 'width_ms': float(dms)})\n",
    "    except Exception as e:\n",
    "        print('Skip H5', h5.name, ':', e)\n",
    "\n",
    "fr_data = pd.DataFrame(rows_fr) if rows_fr else pd.DataFrame(columns=['pair_id','plate','round','side','channel','period','fr_hz'])\n",
    "dur_data = pd.DataFrame(rows_dur) if rows_dur else pd.DataFrame(columns=['pair_id','plate','round','side','channel','period','width_ms'])\n",
    "print('FR rows:', len(fr_data), '| Duration rows:', len(dur_data))\n",
    "\n",
    "# FR nested box plot (CTZ/VEH × pre/post)\n",
    "if not fr_data.empty:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=fr_data, x='side', y='fr_hz', hue='period')\n",
    "        sns.stripplot(data=fr_data, x='side', y='fr_hz', hue='period', dodge=True, color='k', size=2, alpha=0.3)\n",
    "        plt.legend_.remove() if hasattr(plt, 'legend_') else None\n",
    "    else:\n",
    "        for i, side in enumerate(['CTZ','VEH']):\n",
    "            grp = [fr_data[(fr_data.side==side)&(fr_data.period=='pre')]['fr_hz'].dropna(),\n",
    "                   fr_data[(fr_data.side==side)&(fr_data.period=='post')]['fr_hz'].dropna()]\n",
    "            plt.boxplot(grp, positions=[i*3+1, i*3+2], labels=[f'{side}-pre', f'{side}-post'])\n",
    "    plt.title('FR (Hz) — Pre vs Post by Treatment')\n",
    "    plt.ylabel('FR (Hz)')\n",
    "    plt.show()\n",
    "\n",
    "# Spike duration nested box plot (CTZ/VEH × pre/post)\n",
    "if not dur_data.empty:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=dur_data, x='side', y='width_ms', hue='period')\n",
    "        sns.stripplot(data=dur_data, x='side', y='width_ms', hue='period', dodge=True, color='k', size=2, alpha=0.3)\n",
    "        plt.legend_.remove() if hasattr(plt, 'legend_') else None\n",
    "    else:\n",
    "        for i, side in enumerate(['CTZ','VEH']):\n",
    "            grp = [dur_data[(dur_data.side==side)&(dur_data.period=='pre')]['width_ms'].dropna(),\n",
    "                   dur_data[(dur_data.side==side)&(dur_data.period=='post')]['width_ms'].dropna()]\n",
    "            plt.boxplot(grp, positions=[i*3+1, i*3+2], labels=[f'{side}-pre', f'{side}-post'])\n",
    "    plt.title('Spike Duration (ms, FWHM) — Pre vs Post by Treatment')\n",
    "    plt.ylabel('Width (ms)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d400832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-pair and combined plots: FR (CTZ vs VEH, pre vs post) + waveform traces\n",
    "import json, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "\n",
    "try:\n",
    "    from scipy import signal\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"This cell needs scipy installed (for spike widths).\") from e\n",
    "\n",
    "# Resolve exports directory\n",
    "def _exports_dir():\n",
    "    try:\n",
    "        from mcs_mea_analysis.config import CONFIG\n",
    "        REPO_ROOT = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p/'mcs_mea_analysis').exists()), Path.cwd())\n",
    "        OUTPUT_ROOT = CONFIG.output_root if CONFIG.output_root.exists() else (REPO_ROOT / '_mcs_mea_outputs_local')\n",
    "        return OUTPUT_ROOT / 'exports' / 'spikes_waveforms'\n",
    "    except Exception:\n",
    "        return Path('/Volumes/Manny2TB/mcs_mea_outputs/exports/spikes_waveforms')\n",
    "\n",
    "EXPORTS_DIR = _exports_dir()\n",
    "print('Exports dir ->', EXPORTS_DIR)\n",
    "\n",
    "# Discover H5 pairs and pick up to 3 (change MAX_PAIRS to include all)\n",
    "h5_pairs = sorted(EXPORTS_DIR.rglob('*.h5'))\n",
    "h5_pairs = [p for p in h5_pairs if not p.name.endswith('_summary.h5')]\n",
    "MAX_PAIRS = 3\n",
    "sel_pairs = h5_pairs[:MAX_PAIRS] if MAX_PAIRS else h5_pairs\n",
    "print('Pairs found:', len(h5_pairs), '| Using:', len(sel_pairs))\n",
    "for p in sel_pairs: print('  -', p.name)\n",
    "\n",
    "# Helper: noise estimator used for detection\n",
    "def _noise_level(y: np.ndarray, method: str, pctl: float) -> float:\n",
    "    if y.size == 0:\n",
    "        return np.nan\n",
    "    if method == 'mad':\n",
    "        med = np.median(y)\n",
    "        return 1.4826 * np.median(np.abs(y - med))\n",
    "    if method == 'rms':\n",
    "        return float(np.sqrt(np.mean(np.square(y))))\n",
    "    if method == 'pctl':\n",
    "        med = np.median(y)\n",
    "        return float(np.percentile(np.abs(y - med), pctl))\n",
    "    return np.nan\n",
    "\n",
    "# Detect spikes on pre/post windows using detect_config saved in H5\n",
    "def detect_pre_post(t: np.ndarray, y: np.ndarray, sr_hz: float,\n",
    "                    t0b: float, t1b: float, t0a: float, t1a: float, dcfg: dict):\n",
    "    # masks\n",
    "    mb = (t >= t0b) & (t <= t1b)\n",
    "    ma = (t >= t0a) & (t <= t1a)\n",
    "    yb = y[mb]\n",
    "    noise = _noise_level(yb, str(dcfg.get('noise','mad')), float(dcfg.get('noise_percentile',68.0)))\n",
    "    if not np.isfinite(noise) or noise <= 0:\n",
    "        return np.empty(0), np.empty(0), np.empty(0), np.empty(0)\n",
    "    thr = float(dcfg.get('K', 5.0)) * noise\n",
    "    dist = max(1, int(round(float(dcfg.get('refractory_ms',1.0)) * 1e-3 * sr_hz)))\n",
    "    minw = max(1, int(round(float(dcfg.get('min_width_ms',0.3)) * 1e-3 * sr_hz)))\n",
    "    pol = str(dcfg.get('polarity','neg'))\n",
    "\n",
    "    def detect_on_window(mask):\n",
    "        ta = t[mask]; ya = y[mask]\n",
    "        if ta.size == 0:\n",
    "            return np.empty(0), np.empty(0)\n",
    "        arr = -ya if pol in ('neg','both') else ya\n",
    "        peaks, _ = signal.find_peaks(arr, height=thr, distance=dist, width=minw)\n",
    "        widths, _, _, _ = signal.peak_widths(arr, peaks, rel_height=0.5) if peaks.size else (np.empty(0),)*4\n",
    "        st = ta[peaks] if peaks.size else np.empty(0)\n",
    "        w_ms = (widths / float(sr_hz)) * 1000.0 if widths.size else np.empty(0)\n",
    "        return st, w_ms\n",
    "\n",
    "    st_pre, w_pre_ms = detect_on_window(mb)\n",
    "    st_post, w_post_ms = detect_on_window(ma)\n",
    "    return st_pre, w_pre_ms, st_post, w_post_ms\n",
    "\n",
    "def _parse_bounds_attr(attr_val):\n",
    "    try:\n",
    "        if isinstance(attr_val, (bytes, bytearray)):\n",
    "            attr_val = attr_val.decode()\n",
    "        d = json.loads(attr_val) if isinstance(attr_val, str) else attr_val\n",
    "        return float(d.get('t0', 0.0)), float(d.get('t1', 0.0))\n",
    "    except Exception:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "# Per-pair plots (separate)\n",
    "combined_fr_rows = []\n",
    "combined_fr_prepost_rows = []\n",
    "\n",
    "for h5 in sel_pairs:\n",
    "    pair_id = h5.stem\n",
    "    # Load per-pair summary CSV (post-only FR per channel)\n",
    "    csv_sum = h5.with_name(h5.stem + '_summary.csv')\n",
    "    df_sum = pd.read_csv(csv_sum) if csv_sum.exists() else pd.DataFrame(columns=['channel','side','n_spikes','fr_hz'])\n",
    "    df_sum['side'] = df_sum['side'].astype(str)\n",
    "    df_sum['pair_id'] = pair_id\n",
    "    combined_fr_rows.append(df_sum.assign(period='post'))\n",
    "\n",
    "    # Plot: FR channel-level (CTZ vs VEH) for this pair\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=df_sum, x='side', y='fr_hz')\n",
    "        sns.stripplot(data=df_sum, x='side', y='fr_hz', color='k', size=2, alpha=0.3)\n",
    "    else:\n",
    "        groups = [df_sum[df_sum['side']=='CTZ']['fr_hz'].dropna(), df_sum[df_sum['side']=='VEH']['fr_hz'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.title(f'FR (Hz) by Treatment — Channels — {pair_id}')\n",
    "    plt.ylabel('FR (Hz)'); plt.xlabel('')\n",
    "    plt.show()\n",
    "\n",
    "    # Compute pre/post FR (re-detect spikes on exported filtered traces)\n",
    "    fr_prepost = []\n",
    "    with h5py.File(h5.as_posix(),'r') as f:\n",
    "        # detect config\n",
    "        dcfg = {}\n",
    "        if 'detect_config_json' in f:\n",
    "            try:\n",
    "                dcfg = json.loads(f['detect_config_json'][()].decode())\n",
    "            except Exception:\n",
    "                dcfg = {}\n",
    "        for side in ('CTZ','VEH'):\n",
    "            if side not in f:\n",
    "                continue\n",
    "            g = f[side]\n",
    "            sr = float(g.attrs.get('sr_hz', 0.0)) or 10000.0\n",
    "            t0b, t1b = _parse_bounds_attr(g.attrs.get('baseline_bounds', '{\"t0\":0,\"t1\":0}'))\n",
    "            t0a, t1a = _parse_bounds_attr(g.attrs.get('analysis_bounds', '{\"t0\":0,\"t1\":0}'))\n",
    "            chs = sorted(int(k[2:4]) for k in g.keys() if k.startswith('ch') and k.endswith('_time'))\n",
    "            for ch in chs:\n",
    "                t = g[f'ch{ch:02d}_time'][:] if f'ch{ch:02d}_time' in g else np.empty(0)\n",
    "                yf = g[f'ch{ch:02d}_filtered'][:] if f'ch{ch:02d}_filtered' in g else np.empty(0)\n",
    "                if t.size == 0 or yf.size == 0:\n",
    "                    continue\n",
    "                st_pre, _, st_post, _ = detect_pre_post(t, yf, sr, t0b, t1b, t0a, t1a, dcfg)\n",
    "                dur_pre = max(1e-9, (t1b - t0b))\n",
    "                dur_post = max(1e-9, (t1a - t0a))\n",
    "                fr_pre = (st_pre.size / dur_pre) if dur_pre > 0 else np.nan\n",
    "                fr_post = (st_post.size / dur_post) if dur_post > 0 else np.nan\n",
    "                fr_prepost.append({'pair_id': pair_id, 'side': side, 'channel': ch, 'period': 'pre', 'fr_hz': fr_pre})\n",
    "                fr_prepost.append({'pair_id': pair_id, 'side': side, 'channel': ch, 'period': 'post', 'fr_hz': fr_post})\n",
    "\n",
    "    df_pp = pd.DataFrame(fr_prepost)\n",
    "    combined_fr_prepost_rows.append(df_pp)\n",
    "\n",
    "    # Plot: Nested pre/post FR by side for this pair\n",
    "    plt.figure(figsize=(7,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=df_pp, x='side', y='fr_hz', hue='period')\n",
    "        sns.stripplot(data=df_pp, x='side', y='fr_hz', hue='period', dodge=True, color='k', size=2, alpha=0.3)\n",
    "        plt.legend_.remove() if hasattr(plt, 'legend_') else None\n",
    "    else:\n",
    "        for i, side in enumerate(['CTZ','VEH']):\n",
    "            grp = [df_pp[(df_pp.side==side)&(df_pp.period=='pre')]['fr_hz'].dropna(),\n",
    "                   df_pp[(df_pp.side==side)&(df_pp.period=='post')]['fr_hz'].dropna()]\n",
    "            plt.boxplot(grp, positions=[i*3+1, i*3+2], labels=[f'{side}-pre', f'{side}-post'])\n",
    "    plt.title(f'FR (Hz) — Pre vs Post by Treatment — {pair_id}')\n",
    "    plt.ylabel('FR (Hz)')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot: Waveform traces (overlay, sampled) for CTZ and VEH\n",
    "    # Sample up to N_WF waveforms total per side from across channels\n",
    "    N_WF = 200\n",
    "    with h5py.File(h5.as_posix(),'r') as f:\n",
    "        for side in ('CTZ','VEH'):\n",
    "            if side not in f:\n",
    "                continue\n",
    "            g = f[side]\n",
    "            sr = float(g.attrs.get('sr_hz',10000.0)) or 10000.0\n",
    "            # collect waveforms from all channels\n",
    "            waves = []\n",
    "            for k in sorted(g.keys()):\n",
    "                if k.startswith('ch') and k.endswith('_waveforms'):\n",
    "                    arr = g[k][:]\n",
    "                    if arr.size:\n",
    "                        waves.append(arr)\n",
    "            if not waves:\n",
    "                print(f'No waveforms in {pair_id} {side}')\n",
    "                continue\n",
    "            W = np.vstack([w for w in waves if w.size]) if len(waves) else np.empty((0,0))\n",
    "            if W.size == 0:\n",
    "                continue\n",
    "            # sample rows\n",
    "            idx = np.arange(W.shape[0])\n",
    "            if idx.size > N_WF:\n",
    "                rng = np.random.default_rng(0)\n",
    "                idx = rng.choice(idx, size=N_WF, replace=False)\n",
    "            W = W[idx]\n",
    "            n_samp = W.shape[1]\n",
    "            # approximate pre/post split ~ 1:2 (export used 0.8ms pre, 1.6ms post)\n",
    "            n_pre = int(round(n_samp / 3))\n",
    "            t_ms = (np.arange(n_samp) - n_pre) * (1000.0 / sr)\n",
    "            med = np.median(W, axis=0)\n",
    "            plt.figure(figsize=(6,3))\n",
    "            for r in range(W.shape[0]):\n",
    "                plt.plot(t_ms, W[r], color='C0' if side=='CTZ' else 'C1', alpha=0.1, linewidth=0.6)\n",
    "            plt.plot(t_ms, med, color='k', linewidth=2, label='median')\n",
    "            plt.axvline(0.0, color='k', linestyle='--', alpha=0.4)\n",
    "            plt.title(f'Waveform Traces — {side} — {pair_id} (n={W.shape[0]})')\n",
    "            plt.xlabel('Time (ms, approx)'); plt.ylabel('Filtered amplitude (a.u.)')\n",
    "            plt.show()\n",
    "\n",
    "# Combined plots across selected pairs\n",
    "if combined_fr_rows:\n",
    "    all_post = pd.concat(combined_fr_rows, ignore_index=True)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=all_post, x='side', y='fr_hz')\n",
    "        sns.stripplot(data=all_post, x='side', y='fr_hz', color='k', size=2, alpha=0.3)\n",
    "    else:\n",
    "        groups = [all_post[all_post['side']=='CTZ']['fr_hz'].dropna(),\n",
    "                  all_post[all_post['side']=='VEH']['fr_hz'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.title('FR (Hz) by Treatment — Channels — Combined')\n",
    "    plt.ylabel('FR (Hz)'); plt.xlabel('')\n",
    "    plt.show()\n",
    "\n",
    "if combined_fr_prepost_rows:\n",
    "    all_pp = pd.concat(combined_fr_prepost_rows, ignore_index=True)\n",
    "    plt.figure(figsize=(7,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=all_pp, x='side', y='fr_hz', hue='period')\n",
    "        sns.stripplot(data=all_pp, x='side', y='fr_hz', hue='period', dodge=True, color='k', size=2, alpha=0.3)\n",
    "        plt.legend_.remove() if hasattr(plt, 'legend_') else None\n",
    "    else:\n",
    "        for i, side in enumerate(['CTZ','VEH']):\n",
    "            grp = [all_pp[(all_pp.side==side)&(all_pp.period=='pre')]['fr_hz'].dropna(),\n",
    "                   all_pp[(all_pp.side==side)&(all_pp.period=='post')]['fr_hz'].dropna()]\n",
    "            plt.boxplot(grp, positions=[i*3+1, i*3+2], labels=[f'{side}-pre', f'{side}-post'])\n",
    "    plt.title('FR (Hz) — Pre vs Post — Combined')\n",
    "    plt.ylabel('FR (Hz)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98275e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PairBurstISIAnalyzer — discovers exports, re-detects spikes, computes ISI and burst durations\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "\n",
    "try:\n",
    "    from scipy import signal  # needed for detection\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"This analyzer requires scipy installed.\") from e\n",
    "\n",
    "def _resolve_exports_dir() -> Path:\n",
    "    try:\n",
    "        from mcs_mea_analysis.config import CONFIG\n",
    "        REPO_ROOT = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p/'mcs_mea_analysis').exists()), Path.cwd())\n",
    "        output_root = CONFIG.output_root if CONFIG.output_root.exists() else (REPO_ROOT / '_mcs_mea_outputs_local')\n",
    "        return output_root / 'exports' / 'spikes_waveforms'\n",
    "    except Exception:\n",
    "        return Path('/Volumes/Manny2TB/mcs_mea_outputs/exports/spikes_waveforms')\n",
    "\n",
    "def _parse_bounds_attr(attr_val) -> Tuple[float, float]:\n",
    "    try:\n",
    "        if isinstance(attr_val, (bytes, bytearray)):\n",
    "            attr_val = attr_val.decode()\n",
    "        d = json.loads(attr_val) if isinstance(attr_val, str) else attr_val\n",
    "        return float(d.get('t0', 0.0)), float(d.get('t1', 0.0))\n",
    "    except Exception:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "def _noise_level(y: np.ndarray, method: str, pctl: float) -> float:\n",
    "    if y.size == 0: return np.nan\n",
    "    if method == 'mad':\n",
    "        med = np.median(y); return 1.4826 * np.median(np.abs(y - med))\n",
    "    if method == 'rms':\n",
    "        return float(np.sqrt(np.mean(np.square(y))))\n",
    "    if method == 'pctl':\n",
    "        med = np.median(y); return float(np.percentile(np.abs(y - med), pctl))\n",
    "    return np.nan\n",
    "\n",
    "def _detect_prepost(t: np.ndarray, y: np.ndarray, sr_hz: float,\n",
    "                    t0b: float, t1b: float, t0a: float, t1a: float, dcfg: dict):\n",
    "    # masks\n",
    "    mb = (t >= t0b) & (t <= t1b)\n",
    "    ma = (t >= t0a) & (t <= t1a)\n",
    "    yb = y[mb]\n",
    "    noise = _noise_level(yb, str(dcfg.get('noise','mad')), float(dcfg.get('noise_percentile',68.0)))\n",
    "    if not np.isfinite(noise) or noise <= 0:\n",
    "        return np.empty(0), np.empty(0)\n",
    "    thr = float(dcfg.get('K', 5.0)) * noise\n",
    "    dist = max(1, int(round(float(dcfg.get('refractory_ms',1.0)) * 1e-3 * sr_hz)))\n",
    "    minw = max(1, int(round(float(dcfg.get('min_width_ms',0.3)) * 1e-3 * sr_hz)))\n",
    "    pol = str(dcfg.get('polarity','neg'))\n",
    "\n",
    "    def _detect(mask):\n",
    "        ta = t[mask]; ya = y[mask]\n",
    "        if ta.size == 0: return np.empty(0)\n",
    "        arr = -ya if pol in ('neg','both') else ya\n",
    "        peaks, _ = signal.find_peaks(arr, height=thr, distance=dist, width=minw)\n",
    "        return ta[peaks] if peaks.size else np.empty(0)\n",
    "\n",
    "    st_pre  = _detect(mb)\n",
    "    st_post = _detect(ma)\n",
    "    return st_pre, st_post\n",
    "\n",
    "def _bursts_from_spikes(st_s: np.ndarray, isi_thr_ms: float, min_spikes: int) -> List[Tuple[int,int,float,int]]:\n",
    "    \"\"\"\n",
    "    Return bursts as list of tuples: (start_idx, end_idx, dur_ms, n_spikes)\n",
    "    - start_idx/end_idx are spike indices in st_s (inclusive)\n",
    "    \"\"\"\n",
    "    if st_s.size < min_spikes: return []\n",
    "    isi_s = np.diff(st_s)\n",
    "    thr_s = isi_thr_ms / 1000.0\n",
    "    m = isi_s <= thr_s\n",
    "    bursts = []\n",
    "    i = 0\n",
    "    while i < m.size:\n",
    "        if not m[i]:\n",
    "            i += 1\n",
    "            continue\n",
    "        j = i\n",
    "        while j + 1 < m.size and m[j+1]:\n",
    "            j += 1\n",
    "        # run i..j of True spans spikes [i .. j+1]\n",
    "        n_spikes = (j - i + 1) + 1\n",
    "        if n_spikes >= min_spikes:\n",
    "            s_idx = i\n",
    "            e_idx = j + 1\n",
    "            dur_ms = (st_s[e_idx] - st_s[s_idx]) * 1000.0\n",
    "            bursts.append((s_idx, e_idx, float(dur_ms), int(n_spikes)))\n",
    "        i = j + 1\n",
    "    return bursts\n",
    "\n",
    "@dataclass\n",
    "class PairBurstISIAnalyzer:\n",
    "    exports_dir: Path = _resolve_exports_dir()\n",
    "\n",
    "    def discover_pairs(self) -> pd.DataFrame:\n",
    "        pairs = []\n",
    "        for h5 in sorted(self.exports_dir.rglob('*.h5')):\n",
    "            if h5.name.endswith('_summary.h5'):\n",
    "                continue\n",
    "            try:\n",
    "                round_name = h5.parents[1].name if len(h5.parents) > 1 else None\n",
    "                plate = None\n",
    "                try:\n",
    "                    ps = h5.parent.name\n",
    "                    plate = int(ps.replace('plate_', '')) if ps.startswith('plate_') else None\n",
    "                except Exception:\n",
    "                    pass\n",
    "                pairs.append({'pair_id': h5.stem, 'h5_path': str(h5), 'round': round_name, 'plate': plate})\n",
    "            except Exception:\n",
    "                continue\n",
    "        return pd.DataFrame(pairs).sort_values(['plate','round','pair_id']).reset_index(drop=True)\n",
    "\n",
    "    def spikes_prepost_for_pair(self, h5_path: Path) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        with h5py.File(h5_path.as_posix(),'r') as f:\n",
    "            dcfg = {}\n",
    "            if 'detect_config_json' in f:\n",
    "                try: dcfg = json.loads(f['detect_config_json'][()].decode())\n",
    "                except Exception: dcfg = {}\n",
    "            for side in ('CTZ','VEH'):\n",
    "                if side not in f: continue\n",
    "                g = f[side]\n",
    "                sr = float(g.attrs.get('sr_hz', 0.0)) or 10000.0\n",
    "                t0b, t1b = _parse_bounds_attr(g.attrs.get('baseline_bounds', '{\"t0\":0,\"t1\":0}'))\n",
    "                t0a, t1a = _parse_bounds_attr(g.attrs.get('analysis_bounds', '{\"t0\":0,\"t1\":0}'))\n",
    "                chs = sorted(int(k[2:4]) for k in g.keys() if k.startswith('ch') and k.endswith('_time'))\n",
    "                for ch in chs:\n",
    "                    t = g.get(f'ch{ch:02d}_time', None)\n",
    "                    y = g.get(f'ch{ch:02d}_filtered', None)\n",
    "                    if t is None or y is None: continue\n",
    "                    t = t[:]; y = y[:]\n",
    "                    if t.size == 0 or y.size == 0: continue\n",
    "                    st_pre, st_post = _detect_prepost(t, y, sr, t0b, t1b, t0a, t1a, dcfg)\n",
    "                    rows.append({'side': side, 'channel': ch, 'period': 'pre',  'spike_times_s': st_pre})\n",
    "                    rows.append({'side': side, 'channel': ch, 'period': 'post', 'spike_times_s': st_post})\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def compute_isi_and_bursts(self, pairs_df: pd.DataFrame, isi_thr_ms: float = 100.0, min_spikes: int = 3):\n",
    "        isi_rows, burst_rows = [], []\n",
    "        for _, r in pairs_df.iterrows():\n",
    "            h5p = Path(r['h5_path'])\n",
    "            spikes_df = self.spikes_prepost_for_pair(h5p)\n",
    "            if spikes_df.empty: continue\n",
    "            spikes_df['pair_id'] = r['pair_id']; spikes_df['plate'] = r['plate']; spikes_df['round'] = r['round']\n",
    "            for _, row in spikes_df.iterrows():\n",
    "                st = np.asarray(row['spike_times_s'], dtype=float)\n",
    "                if st.size >= 2:\n",
    "                    isi_ms = np.diff(st) * 1000.0\n",
    "                    for v in isi_ms:\n",
    "                        isi_rows.append({'pair_id': row['pair_id'], 'plate': row['plate'], 'round': row['round'],\n",
    "                                         'side': row['side'], 'channel': row['channel'], 'period': row['period'],\n",
    "                                         'isi_ms': float(v)})\n",
    "                # bursts\n",
    "                bursts = _bursts_from_spikes(st, isi_thr_ms=isi_thr_ms, min_spikes=min_spikes)\n",
    "                for s_idx, e_idx, dur_ms, nsp in bursts:\n",
    "                    burst_rows.append({'pair_id': row['pair_id'], 'plate': row['plate'], 'round': row['round'],\n",
    "                                       'side': row['side'], 'channel': row['channel'], 'period': row['period'],\n",
    "                                       'burst_dur_ms': float(dur_ms), 'n_spikes': int(nsp)})\n",
    "        isi_df   = pd.DataFrame(isi_rows)   if isi_rows   else pd.DataFrame(columns=['pair_id','plate','round','side','channel','period','isi_ms'])\n",
    "        burst_df = pd.DataFrame(burst_rows) if burst_rows else pd.DataFrame(columns=['pair_id','plate','round','side','channel','period','burst_dur_ms','n_spikes'])\n",
    "        return isi_df, burst_df\n",
    "\n",
    "    # Plot helpers\n",
    "    def plot_isi_pair(self, isi_df: pd.DataFrame, pair_id: str, logy: bool = True):\n",
    "        sub = isi_df[isi_df['pair_id']==pair_id].copy()\n",
    "        if sub.empty: print('No ISI data for', pair_id); return\n",
    "        plt.figure(figsize=(7,4))\n",
    "        if sns is not None:\n",
    "            sns.boxplot(data=sub, x='side', y='isi_ms', hue='period')\n",
    "            sns.stripplot(data=sub, x='side', y='isi_ms', hue='period', dodge=True, color='k', size=2, alpha=0.3)\n",
    "            plt.legend_.remove() if hasattr(plt, 'legend_') else None\n",
    "        else:\n",
    "            for i, side in enumerate(['CTZ','VEH']):\n",
    "                grp = [sub[(sub.side==side)&(sub.period=='pre')]['isi_ms'].dropna(),\n",
    "                       sub[(sub.side==side)&(sub.period=='post')]['isi_ms'].dropna()]\n",
    "                plt.boxplot(grp, positions=[i*3+1,i*3+2], labels=[f'{side}-pre', f'{side}-post'])\n",
    "        plt.title(f'ISI (ms) — {pair_id}'); plt.ylabel('ISI (ms)'); plt.xlabel('')\n",
    "        if logy: plt.yscale('log')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_isi_all(self, isi_df: pd.DataFrame, logy: bool = True):\n",
    "        sub = isi_df.copy()\n",
    "        if sub.empty: print('No ISI data.'); return\n",
    "        plt.figure(figsize=(7,4))\n",
    "        if sns is not None:\n",
    "            sns.boxplot(data=sub, x='side', y='isi_ms', hue='period')\n",
    "            sns.stripplot(data=sub, x='side', y='isi_ms', hue='period', dodge=True, color='k', size=2, alpha=0.3)\n",
    "            plt.legend_.remove() if hasattr(plt, 'legend_') else None\n",
    "        else:\n",
    "            for i, side in enumerate(['CTZ','VEH']):\n",
    "                grp = [sub[(sub.side==side)&(sub.period=='pre')]['isi_ms'].dropna(),\n",
    "                       sub[(sub.side==side)&(sub.period=='post')]['isi_ms'].dropna()]\n",
    "                plt.boxplot(grp, positions=[i*3+1,i*3+2], labels=[f'{side}-pre', f'{side}-post'])\n",
    "        plt.title('ISI (ms) — Combined Across Pairs'); plt.ylabel('ISI (ms)'); plt.xlabel('')\n",
    "        if logy: plt.yscale('log')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_burst_pair(self, burst_df: pd.DataFrame, pair_id: str, logy: bool = False):\n",
    "        sub = burst_df[burst_df['pair_id']==pair_id].copy()\n",
    "        if sub.empty: print('No burst data for', pair_id); return\n",
    "        plt.figure(figsize=(7,4))\n",
    "        if sns is not None:\n",
    "            sns.boxplot(data=sub, x='side', y='burst_dur_ms', hue='period')\n",
    "            sns.stripplot(data=sub, x='side', y='burst_dur_ms', hue='period', dodge=True, color='k', size=2, alpha=0.3)\n",
    "            plt.legend_.remove() if hasattr(plt, 'legend_') else None\n",
    "        else:\n",
    "            for i, side in enumerate(['CTZ','VEH']):\n",
    "                grp = [sub[(sub.side==side)&(sub.period=='pre')]['burst_dur_ms'].dropna(),\n",
    "                       sub[(sub.side==side)&(sub.period=='post')]['burst_dur_ms'].dropna()]\n",
    "                plt.boxplot(grp, positions=[i*3+1,i*3+2], labels=[f'{side}-pre', f'{side}-post'])\n",
    "        plt.title(f'Burst Duration (ms) — {pair_id}'); plt.ylabel('Burst duration (ms)'); plt.xlabel('')\n",
    "        if logy: plt.yscale('log')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_burst_all(self, burst_df: pd.DataFrame, logy: bool = False):\n",
    "        sub = burst_df.copy()\n",
    "        if sub.empty: print('No burst data.'); return\n",
    "        plt.figure(figsize=(7,4))\n",
    "        if sns is not None:\n",
    "            sns.boxplot(data=sub, x='side', y='burst_dur_ms', hue='period')\n",
    "            sns.stripplot(data=sub, x='side', y='burst_dur_ms', hue='period', dodge=True, color='k', size=2, alpha=0.3)\n",
    "            plt.legend_.remove() if hasattr(plt, 'legend_') else None\n",
    "        else:\n",
    "            for i, side in enumerate(['CTZ','VEH']):\n",
    "                grp = [sub[(sub.side==side)&(sub.period=='pre')]['burst_dur_ms'].dropna(),\n",
    "                       sub[(sub.side==side)&(sub.period=='post')]['burst_dur_ms'].dropna()]\n",
    "                plt.boxplot(grp, positions=[i*3+1,i*3+2], labels=[f'{side}-pre', f'{side}-post'])\n",
    "        plt.title('Burst Duration (ms) — Combined Across Pairs'); plt.ylabel('Burst duration (ms)'); plt.xlabel('')\n",
    "        if logy: plt.yscale('log')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ISI and burst metrics; plot per pair and combined\n",
    "an = PairBurstISIAnalyzer()\n",
    "pairs_df = an.discover_pairs()\n",
    "print('Discovered pairs:', len(pairs_df))\n",
    "display(pairs_df)\n",
    "\n",
    "# Choose first 3 pairs; set sel = pairs_df to use all\n",
    "sel = pairs_df.iloc[:3] if len(pairs_df) > 3 else pairs_df\n",
    "\n",
    "# Tunables: burst definition\n",
    "ISI_THR_MS = 100.0   # ISI threshold to link spikes into a burst\n",
    "MIN_SPIKES = 3       # min spikes per burst\n",
    "\n",
    "isi_df, burst_df = an.compute_isi_and_bursts(sel, isi_thr_ms=ISI_THR_MS, min_spikes=MIN_SPIKES)\n",
    "print('ISI rows:', len(isi_df), '| Burst rows:', len(burst_df))\n",
    "\n",
    "# Per‑pair plots (separate for each selected pair)\n",
    "for pid in sel['pair_id']:\n",
    "    an.plot_isi_pair(isi_df, pid, logy=True)\n",
    "    an.plot_burst_pair(burst_df, pid, logy=False)\n",
    "\n",
    "# Combined across selected pairs\n",
    "an.plot_isi_all(isi_df, logy=True)\n",
    "an.plot_burst_all(burst_df, logy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b69ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-only CTZ vs VEH: FR (channels), ISI, and Burst Duration\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, h5py, matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "\n",
    "# Resolve exports directory\n",
    "try:\n",
    "    from mcs_mea_analysis.config import CONFIG\n",
    "    REPO_ROOT = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p/'mcs_mea_analysis').exists()), Path.cwd())\n",
    "    OUTPUT_ROOT = CONFIG.output_root if CONFIG.output_root.exists() else (REPO_ROOT / '_mcs_mea_outputs_local')\n",
    "    EXPORTS_DIR = OUTPUT_ROOT / 'exports' / 'spikes_waveforms'\n",
    "except Exception:\n",
    "    EXPORTS_DIR = Path('/Volumes/Manny2TB/mcs_mea_outputs/exports/spikes_waveforms')\n",
    "\n",
    "print('Exports dir ->', EXPORTS_DIR)\n",
    "\n",
    "# 1) Post FR (channel-level) comes straight from the per-pair _summary.csv files\n",
    "rows = []\n",
    "for csvp in EXPORTS_DIR.rglob('*_summary.csv'):\n",
    "    try:\n",
    "        base = csvp.stem.replace('_summary','')\n",
    "        df = pd.read_csv(csvp)\n",
    "        df['side'] = df['side'].astype(str)\n",
    "        df['pair_id'] = base\n",
    "        rows.append(df[['pair_id','side','channel','fr_hz']])\n",
    "    except Exception as e:\n",
    "        print('Skip', csvp.name, ':', e)\n",
    "\n",
    "fr_post = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=['pair_id','side','channel','fr_hz'])\n",
    "print('FR (post) rows:', len(fr_post), 'from', len(rows), 'pairs')\n",
    "\n",
    "if not fr_post.empty:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=fr_post, x='side', y='fr_hz')\n",
    "        sns.stripplot(data=fr_post, x='side', y='fr_hz', color='k', size=2, alpha=0.3)\n",
    "    else:\n",
    "        groups = [fr_post[fr_post.side=='CTZ']['fr_hz'].dropna(), fr_post[fr_post.side=='VEH']['fr_hz'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.title('Post FR (Hz) — Channels — CTZ vs VEH')\n",
    "    plt.ylabel('FR (Hz)'); plt.xlabel('')\n",
    "    plt.show()\n",
    "\n",
    "# 2) ISI and 3) Burst duration (post) from exported post spike timestamps in the H5\n",
    "ISI_THR_MS = 100.0   # spikes closer than this ISI are part of the same burst\n",
    "MIN_SPIKES = 3       # minimum spikes per burst\n",
    "\n",
    "def bursts_from(spikes_s: np.ndarray, thr_ms: float, min_sp: int):\n",
    "    s = np.asarray(spikes_s, float)\n",
    "    if s.size < min_sp: return []\n",
    "    isi_s = np.diff(s); thr_s = thr_ms / 1000.0\n",
    "    m = isi_s <= thr_s\n",
    "    out = []; i = 0\n",
    "    while i < m.size:\n",
    "        if not m[i]: i += 1; continue\n",
    "        j = i\n",
    "        while j + 1 < m.size and m[j+1]: j += 1\n",
    "        n_sp = (j - i + 1) + 1\n",
    "        if n_sp >= min_sp:\n",
    "            s_idx, e_idx = i, j + 1\n",
    "            dur_ms = (s[e_idx] - s[s_idx]) * 1000.0\n",
    "            out.append((s_idx, e_idx, float(dur_ms), int(n_sp)))\n",
    "        i = j + 1\n",
    "    return out\n",
    "\n",
    "isi_rows, burst_rows = [], []\n",
    "h5_files = [p for p in EXPORTS_DIR.rglob('*.h5') if not p.name.endswith('_summary.h5')]\n",
    "for h5 in h5_files:\n",
    "    pair_id = h5.stem\n",
    "    with h5py.File(h5.as_posix(), 'r') as f:\n",
    "        for side in ('CTZ','VEH'):\n",
    "            if side not in f: continue\n",
    "            g = f[side]\n",
    "            # Post timestamps are already the analysis-window (post) spikes\n",
    "            ch_idxs = sorted(int(k[2:4]) for k in g.keys() if k.startswith('ch') and k.endswith('_timestamps'))\n",
    "            for ch in ch_idxs:\n",
    "                ds = f'{side}/ch{ch:02d}_timestamps'\n",
    "                if ds not in f: continue\n",
    "                st = np.asarray(f[ds][:], float)\n",
    "                # ISI (ms)\n",
    "                if st.size >= 2:\n",
    "                    isi_ms = np.diff(st) * 1000.0\n",
    "                    isi_rows.extend({'pair_id': pair_id, 'side': side, 'channel': ch, 'isi_ms': float(v)} for v in isi_ms)\n",
    "                # Burst durations (ms)\n",
    "                for _, _, dur_ms, nsp in bursts_from(st, ISI_THR_MS, MIN_SPIKES):\n",
    "                    burst_rows.append({'pair_id': pair_id, 'side': side, 'channel': ch, 'burst_dur_ms': float(dur_ms), 'n_spikes': int(nsp)})\n",
    "\n",
    "isi_df   = pd.DataFrame(isi_rows)   if isi_rows   else pd.DataFrame(columns=['pair_id','side','channel','isi_ms'])\n",
    "burst_df = pd.DataFrame(burst_rows) if burst_rows else pd.DataFrame(columns=['pair_id','side','channel','burst_dur_ms','n_spikes'])\n",
    "print('ISI rows:', len(isi_df), '| Burst rows:', len(burst_df))\n",
    "\n",
    "# ISI (post) — CTZ vs VEH\n",
    "if not isi_df.empty:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=isi_df, x='side', y='isi_ms')\n",
    "        sns.stripplot(data=isi_df, x='side', y='isi_ms', color='k', size=2, alpha=0.3)\n",
    "    else:\n",
    "        groups = [isi_df[isi_df.side=='CTZ']['isi_ms'].dropna(), isi_df[isi_df.side=='VEH']['isi_ms'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.yscale('log')\n",
    "    plt.title('Post ISI (ms) — CTZ vs VEH')\n",
    "    plt.ylabel('ISI (ms)'); plt.xlabel('')\n",
    "    plt.show()\n",
    "\n",
    "# Burst duration (post) — CTZ vs VEH\n",
    "if not burst_df.empty:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    if sns is not None:\n",
    "        sns.boxplot(data=burst_df, x='side', y='burst_dur_ms')\n",
    "        sns.stripplot(data=burst_df, x='side', y='burst_dur_ms', color='k', size=2, alpha=0.3)\n",
    "    else:\n",
    "        groups = [burst_df[burst_df.side=='CTZ']['burst_dur_ms'].dropna(), burst_df[burst_df.side=='VEH']['burst_dur_ms'].dropna()]\n",
    "        plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "    plt.title('Post Burst Duration (ms) — CTZ vs VEH')\n",
    "    plt.ylabel('Burst duration (ms)'); plt.xlabel('')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910da76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e713c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object-based analyzer for baseline (pre-chem) FR only\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "\n",
    "try:\n",
    "    from scipy import signal  # used for detection\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"This analyzer requires scipy installed.\") from e\n",
    "\n",
    "def _resolve_exports_dir() -> Path:\n",
    "    try:\n",
    "        from mcs_mea_analysis.config import CONFIG\n",
    "        REPO_ROOT = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p/'mcs_mea_analysis').exists()), Path.cwd())\n",
    "        output_root = CONFIG.output_root if CONFIG.output_root.exists() else (REPO_ROOT / '_mcs_mea_outputs_local')\n",
    "        return output_root / 'exports' / 'spikes_waveforms'\n",
    "    except Exception:\n",
    "        return Path('/Volumes/Manny2TB/mcs_mea_outputs/exports/spikes_waveforms')\n",
    "\n",
    "def _parse_bounds_attr(attr_val) -> Tuple[float, float]:\n",
    "    try:\n",
    "        if isinstance(attr_val, (bytes, bytearray)):\n",
    "            attr_val = attr_val.decode()\n",
    "        d = json.loads(attr_val) if isinstance(attr_val, str) else attr_val\n",
    "        return float(d.get('t0', 0.0)), float(d.get('t1', 0.0))\n",
    "    except Exception:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "def _noise_level(y: np.ndarray, method: str, pctl: float) -> float:\n",
    "    if y.size == 0:\n",
    "        return np.nan\n",
    "    if method == 'mad':\n",
    "        med = np.median(y)\n",
    "        return 1.4826 * np.median(np.abs(y - med))\n",
    "    if method == 'rms':\n",
    "        return float(np.sqrt(np.mean(np.square(y))))\n",
    "    if method == 'pctl':\n",
    "        med = np.median(y)\n",
    "        return float(np.percentile(np.abs(y - med), pctl))\n",
    "    return np.nan\n",
    "\n",
    "def _detect_prepost(t: np.ndarray, y: np.ndarray, sr_hz: float,\n",
    "                    t0b: float, t1b: float, t0a: float, t1a: float, dcfg: dict):\n",
    "    # masks\n",
    "    mb = (t >= t0b) & (t <= t1b)\n",
    "    ma = (t >= t0a) & (t <= t1a)\n",
    "    yb = y[mb]\n",
    "    noise = _noise_level(yb, str(dcfg.get('noise','mad')), float(dcfg.get('noise_percentile',68.0)))\n",
    "    if not np.isfinite(noise) or noise <= 0:\n",
    "        return np.empty(0), np.empty(0), np.empty(0), np.empty(0)\n",
    "    thr = float(dcfg.get('K', 5.0)) * noise\n",
    "    dist = max(1, int(round(float(dcfg.get('refractory_ms',1.0)) * 1e-3 * sr_hz)))\n",
    "    minw = max(1, int(round(float(dcfg.get('min_width_ms',0.3)) * 1e-3 * sr_hz)))\n",
    "    pol = str(dcfg.get('polarity','neg'))\n",
    "\n",
    "    def _detect(mask):\n",
    "        ta = t[mask]; ya = y[mask]\n",
    "        if ta.size == 0:\n",
    "            return np.empty(0), np.empty(0)\n",
    "        arr = -ya if pol in ('neg','both') else ya\n",
    "        peaks, _ = signal.find_peaks(arr, height=thr, distance=dist, width=minw)\n",
    "        widths, _, _, _ = signal.peak_widths(arr, peaks, rel_height=0.5) if peaks.size else (np.empty(0),)*4\n",
    "        st = ta[peaks] if peaks.size else np.empty(0)\n",
    "        w_ms = (widths / float(sr_hz)) * 1000.0 if widths.size else np.empty(0)\n",
    "        return st, w_ms\n",
    "\n",
    "    st_pre, _ = _detect(mb)\n",
    "    st_post, _ = _detect(ma)\n",
    "    return st_pre, st_post\n",
    "\n",
    "@dataclass\n",
    "class PairExportsAnalyzer:\n",
    "    exports_dir: Path = _resolve_exports_dir()\n",
    "\n",
    "    def discover_pairs(self) -> pd.DataFrame:\n",
    "        pairs = []\n",
    "        for h5 in sorted(self.exports_dir.rglob('*.h5')):\n",
    "            if h5.name.endswith('_summary.h5'):\n",
    "                continue\n",
    "            try:\n",
    "                round_name = h5.parents[1].name if len(h5.parents) > 1 else None\n",
    "                plate = None\n",
    "                try:\n",
    "                    ps = h5.parent.name\n",
    "                    plate = int(ps.replace('plate_', '')) if ps.startswith('plate_') else None\n",
    "                except Exception:\n",
    "                    pass\n",
    "                pairs.append({'pair_id': h5.stem, 'h5_path': str(h5), 'round': round_name, 'plate': plate})\n",
    "            except Exception:\n",
    "                continue\n",
    "        return pd.DataFrame(pairs).sort_values(['plate','round','pair_id']).reset_index(drop=True)\n",
    "\n",
    "    def fr_prepost_for_pair(self, h5_path: Path) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        with h5py.File(h5_path.as_posix(),'r') as f:\n",
    "            dcfg = {}\n",
    "            if 'detect_config_json' in f:\n",
    "                try:\n",
    "                    dcfg = json.loads(f['detect_config_json'][()].decode())\n",
    "                except Exception:\n",
    "                    dcfg = {}\n",
    "            for side in ('CTZ','VEH'):\n",
    "                if side not in f: \n",
    "                    continue\n",
    "                g = f[side]\n",
    "                sr = float(g.attrs.get('sr_hz', 0.0)) or 10000.0\n",
    "                t0b, t1b = _parse_bounds_attr(g.attrs.get('baseline_bounds', '{\"t0\":0,\"t1\":0}'))\n",
    "                t0a, t1a = _parse_bounds_attr(g.attrs.get('analysis_bounds', '{\"t0\":0,\"t1\":0}'))\n",
    "                chs = sorted(int(k[2:4]) for k in g.keys() if k.startswith('ch') and k.endswith('_time'))\n",
    "                for ch in chs:\n",
    "                    t = g.get(f'ch{ch:02d}_time', None)\n",
    "                    y = g.get(f'ch{ch:02d}_filtered', None)\n",
    "                    if t is None or y is None:\n",
    "                        continue\n",
    "                    t = t[:]; y = y[:]\n",
    "                    if t.size == 0 or y.size == 0:\n",
    "                        continue\n",
    "                    st_pre, st_post = _detect_prepost(t, y, sr, t0b, t1b, t0a, t1a, dcfg)\n",
    "                    dur_pre = max(1e-9, (t1b - t0b))\n",
    "                    dur_post = max(1e-9, (t1a - t0a))\n",
    "                    fr_pre = (st_pre.size / dur_pre) if dur_pre > 0 else np.nan\n",
    "                    fr_post = (st_post.size / dur_post) if dur_post > 0 else np.nan\n",
    "                    rows.append({'side': side, 'channel': ch, 'period': 'pre', 'fr_hz': fr_pre})\n",
    "                    rows.append({'side': side, 'channel': ch, 'period': 'post', 'fr_hz': fr_post})\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def compute_all(self, pairs_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        frames = []\n",
    "        for _, r in pairs_df.iterrows():\n",
    "            h5p = Path(r['h5_path'])\n",
    "            d = self.fr_prepost_for_pair(h5p)\n",
    "            if not d.empty:\n",
    "                d['pair_id'] = r['pair_id']; d['plate'] = r['plate']; d['round'] = r['round']\n",
    "                frames.append(d)\n",
    "        cols = ['pair_id','plate','round','side','channel','period','fr_hz']\n",
    "        return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame(columns=cols)\n",
    "\n",
    "    def plot_baseline_pair(self, df: pd.DataFrame, pair_id: str) -> None:\n",
    "        sub = df[(df['pair_id']==pair_id) & (df['period']=='pre')].copy()\n",
    "        if sub.empty:\n",
    "            print('No baseline data for', pair_id); return\n",
    "        plt.figure(figsize=(6,4))\n",
    "        if sns is not None:\n",
    "            sns.boxplot(data=sub, x='side', y='fr_hz')\n",
    "            sns.stripplot(data=sub, x='side', y='fr_hz', color='k', size=2, alpha=0.3)\n",
    "        else:\n",
    "            groups = [sub[sub['side']=='CTZ']['fr_hz'].dropna(), sub[sub['side']=='VEH']['fr_hz'].dropna()]\n",
    "            plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "        plt.title(f'Baseline FR (Hz) — {pair_id}')\n",
    "        plt.ylabel('FR (Hz)'); plt.xlabel('')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_baseline_all(self, df: pd.DataFrame) -> None:\n",
    "        sub = df[df['period']=='pre'].copy()\n",
    "        if sub.empty:\n",
    "            print('No baseline data.'); return\n",
    "        plt.figure(figsize=(6,4))\n",
    "        if sns is not None:\n",
    "            sns.boxplot(data=sub, x='side', y='fr_hz')\n",
    "            sns.stripplot(data=sub, x='side', y='fr_hz', color='k', size=2, alpha=0.3)\n",
    "        else:\n",
    "            groups = [sub[sub['side']=='CTZ']['fr_hz'].dropna(), sub[sub['side']=='VEH']['fr_hz'].dropna()]\n",
    "            plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "        plt.title('Baseline FR (Hz) — Combined Across Pairs')\n",
    "        plt.ylabel('FR (Hz)'); plt.xlabel('')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_baseline_pair_means(self, df: pd.DataFrame) -> None:\n",
    "        sub = df[df['period']=='pre'].copy()\n",
    "        if sub.empty:\n",
    "            print('No baseline data.'); return\n",
    "        means = (sub.groupby(['pair_id','side'], as_index=False)['fr_hz']\n",
    "                   .mean().rename(columns={'fr_hz':'mean_fr_hz'}))\n",
    "        plt.figure(figsize=(6,4))\n",
    "        if sns is not None:\n",
    "            sns.boxplot(data=means, x='side', y='mean_fr_hz')\n",
    "            sns.stripplot(data=means, x='side', y='mean_fr_hz', color='k', size=3, alpha=0.5)\n",
    "        else:\n",
    "            groups = [means[means['side']=='CTZ']['mean_fr_hz'].dropna(),\n",
    "                      means[means['side']=='VEH']['mean_fr_hz'].dropna()]\n",
    "            plt.boxplot(groups, labels=['CTZ','VEH'])\n",
    "        plt.title('Baseline FR (Hz) — Per-Pair Means')\n",
    "        plt.ylabel('Mean FR (Hz)'); plt.xlabel('')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the analyzer — baseline-only plots, by pair and combined\n",
    "an = PairExportsAnalyzer()\n",
    "pairs_df = an.discover_pairs()\n",
    "print('Discovered pairs:', len(pairs_df))\n",
    "display(pairs_df)\n",
    "\n",
    "# Limit to first 3 if you want; or use all by setting sel = pairs_df\n",
    "sel = pairs_df.iloc[:3] if len(pairs_df) > 3 else pairs_df\n",
    "\n",
    "fr_df = an.compute_all(sel)\n",
    "print('Computed rows:', len(fr_df))\n",
    "\n",
    "# Combined baseline CTZ vs VEH across selected pairs\n",
    "an.plot_baseline_all(fr_df)\n",
    "\n",
    "# Baseline per pair (CTZ vs VEH), one figure per pair\n",
    "for pid in sel['pair_id']:\n",
    "    an.plot_baseline_pair(fr_df, pid)\n",
    "\n",
    "# Baseline per-pair means (one mean per side per pair)\n",
    "an.plot_baseline_pair_means(fr_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
