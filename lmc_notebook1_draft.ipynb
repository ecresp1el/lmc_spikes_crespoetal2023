{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import pickle\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pickle file to access the dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_file(file_name):\n",
    "    # ask the user to select the directory path to the pickle file\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    file_path = filedialog.askdirectory()\n",
    "\n",
    "    # load the selected pickle file from the user provided file path\n",
    "    if file_path:\n",
    "        try:\n",
    "            with open(file_path + '/' + file_name, 'rb') as f:\n",
    "                output_dict_forprocessing = pickle.load(f)\n",
    "                print(\"Pickle file loaded successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No pickle file found in the selected directory.\")\n",
    "            \n",
    "    return output_dict_forprocessing\n",
    "\n",
    "#load the pickle file\n",
    "output_dict_forprocessing = load_pickle_file('SpikeTrains_for_PSTHs.p')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand the input dictionary to account for stimulus trials (zero, low, mid, high) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_inputdict_2_trialdict(my_dict):\n",
    "    \n",
    "    #initialize an empty dictionary\n",
    "    trial_dict = {}\n",
    "    \n",
    "    #iterate over the keys in the dictionary to access the matrix values\n",
    "    for key in my_dict.keys():\n",
    "        \n",
    "        #store matrix per key in the input dictionary in a new dictionary, but first change the key name by adding '_zero' to the end of the key name to label the stimulus intensity\n",
    "        trial_dict[str(key) + '_zero'] = my_dict[key][0,0] #store the 2D matrix, assumes that index 0 is the zero intensity stimulus\n",
    "        trial_dict[str(key) + '_low'] = my_dict[key][0,1] #store the 2D matrix, assumes that index 1 is the low intensity stimulus\n",
    "        trial_dict[str(key) + '_mid'] = my_dict[key][0,2] #store the 2D matrix, assumes that index 2 is the mid intensity stimulus\n",
    "        trial_dict[str(key) + '_high'] = my_dict[key][0,3] #store the 2D matrix, assumes that index 3 is the high intensity stimulus\n",
    "        \n",
    "        #print the key name and the shape of the matrix to make sure it is correct\n",
    "        print(\"The key name is: \" + str(key) + \"_zero\" + \" and the shape of the matrix is: \" + str(my_dict[key][0,0].shape))\n",
    "        print(\"The key name is: \" + str(key) + \"_low\" + \" and the shape of the matrix is: \" + str(my_dict[key][0,1].shape))\n",
    "        print(\"The key name is: \" + str(key) + \"_mid\" + \" and the shape of the matrix is: \" + str(my_dict[key][0,2].shape))\n",
    "        print(\"The key name is: \" + str(key) + \"_high\" + \" and the shape of the matrix is: \" + str(my_dict[key][0,3].shape))    \n",
    "        \n",
    "    #the new dictionary should have the four times the number of keys as the input dictionary\n",
    "    #if not, then return an error message\n",
    "    assert len(trial_dict) == 4*len(my_dict), \"The new dictionary does not have four times the number of keys as the input dictionary.\"\n",
    "\n",
    "    #if it is, then return the new dictionary\n",
    "    return trial_dict      \n",
    "\n",
    "#call the convert_inputdict_2_trialdict function  \n",
    "trial_dict_forprocessing = convert_inputdict_2_trialdict(output_dict_forprocessing) #this is the dictionary that will be used for further processing and will have the 2D matrices as values for each key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the incomplate dataframe from the dictionary for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that will loop through thr dictionary keys and create a dataframe per key\n",
    "def create_dataframe_from_dict(my_dict):\n",
    "    \n",
    "    #initialize an empty dictionary\n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    #iterate over the keys and store the key name as the column name in the dataframe under 'trial_name' column\n",
    "    #and store the values of the key under 'spikes'ArithmeticError\n",
    "    \n",
    "    for key in my_dict.keys():\n",
    "        temp_df = pd.DataFrame()\n",
    "        temp_df['trial_name'] = [str(key)]\n",
    "        \n",
    "        temp_df['spikes'] = [my_dict[key]]\n",
    "        \n",
    "        #print the shape of the values to make sure it is correct\n",
    "        print(\"The key name is: \" + str(key) + \" and the shape of the matrix is: \" + str(my_dict[key].shape))\n",
    "        \n",
    "        #use concat to append the temporary dataframe to the main dataframe\n",
    "        main_df = pd.concat([main_df, temp_df], ignore_index=True)\n",
    "        \n",
    "    return main_df\n",
    "\n",
    "#call the function to create the dataframe\n",
    "main_df_forprocessing = create_dataframe_from_dict(trial_dict_forprocessing) \n",
    "\n",
    "#check the dataframe to access the first entry in spikes column\n",
    "first_entry_df = main_df_forprocessing['spikes'][0]\n",
    "\n",
    "#what is the key name for the first entry?\n",
    "first_entry_key = main_df_forprocessing['trial_name'][0]      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the complete dataframe for processing as this will add columns where stimulus condition, group name, cell id, mouse id, and is post epoch is a boolean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that will now add columnns based on the trial name columns \n",
    "def add_columns_from_trial_name(my_df):\n",
    "    \n",
    "    #create a new column called is_post, if the the trial_name contains_post then the value is True, if not then the value is False\n",
    "        my_df['is_post'] = my_df['trial_name'].str.contains('post')\n",
    "    \n",
    "    #create four columns called zero, low, mid, high and store as True if the trial_name contains zero, low, mid, high respectively and False if not\n",
    "        my_df['zero'] = my_df['trial_name'].str.contains('zero')\n",
    "        my_df['low'] = my_df['trial_name'].str.contains('low')\n",
    "        my_df['mid'] = my_df['trial_name'].str.contains('mid')\n",
    "        my_df['high'] = my_df['trial_name'].str.contains('high')\n",
    "    \n",
    "    #create a column called 'group_name' and store the group name based on the trial_name, if 'Lmc_opsin' is in the trial_name then store 'Lmc_opsin' in the group_name column, if 'Lmc_noopsin' is in the trial_name then store 'Lmc_noopsin' in the group_name column\n",
    "        my_df['group_name'] = np.where(my_df['trial_name'].str.contains('Lmc_opsin'), 'Lmc_opsin', 'Lmc_noopsin')\n",
    "    \n",
    "    #create a column that has the cell_id based on the trial_name, first by spliting the trial_name between the 7th and 8th '_' and then extracting the characters after the 7th but before the 8th '_' and storing in a new column called cell_id\n",
    "        my_df['cell_id'] = my_df['trial_name'].str.split('_', expand = True)[7] \n",
    "    \n",
    "    #create a column that has the mouse id based on the trial_name by finding four consecutive numbers in the trial_name and storing them in a new column called mouse_id\n",
    "        my_df['mouse_id'] = my_df['trial_name'].str.extract('(\\d{4})', expand = True)\n",
    "    \n",
    "    #save the dataframe as a pickle file in the same directory as the script \n",
    "    \n",
    "    #return the dataframe\n",
    "        return my_df\n",
    "\n",
    "#call the function to add columns to the dataframe  \n",
    "main_df_forprocessing_addedcol = add_columns_from_trial_name(main_df_forprocessing)\n",
    "\n",
    "#access the first entry in the dataframe to make sure the columns were added correctly\n",
    "first_entry_df_addedcol = main_df_forprocessing_addedcol['spikes'][0] #should be a 2D matrix \n",
    "\n",
    "#confirm that this is the case\n",
    "print(\"The shape of the first entry in the dataframe is: \" + str(first_entry_df_addedcol.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function that prompts the user with a window to select the directory path where the csv file will be saved \n",
    "def save_dataframe_as_csv(my_df):\n",
    "    # ask the user to select the directory path to the pickle file\n",
    "    root = tk.Tk()\n",
    "    \n",
    "    #hide the root window\n",
    "    root.withdraw()\n",
    "    \n",
    "    #ask the user to select the directory path to save the csv file\n",
    "    file_path = filedialog.askdirectory()\n",
    "    \n",
    "    #save the dataframe as a csv file in the user provided directory path\n",
    "    if file_path:\n",
    "        try:\n",
    "            my_df.to_csv(file_path + '/' + 'spikes_dataframe.csv')\n",
    "            print(\"Dataframe saved successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No directory path selected.\")\n",
    "            \n",
    "#call the function to save the dataframe as a csv file\n",
    "save_dataframe_as_csv(main_df_forprocessing_addedcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function that prompts the user with a window to select the directory where the pickle file will be saved\n",
    "def save_dataframe_as_pickle(my_df):\n",
    "        \n",
    "        #prompt the user with a window to select the directory where the pickle file will be saved\n",
    "        pickle_file = filedialog.asksaveasfilename(initialdir = \"/Users/cresp1el/Documents/lmc_project_analysis_dir/analysis_directory\", title = \"Select directory to save pickle file\", filetypes = ((\"pickle files\",\"*.pickle\"),(\"all files\",\"*.*\")))\n",
    "        \n",
    "        #save the dataframe as a pickle file \n",
    "        my_df.to_pickle(pickle_file)\n",
    "        \n",
    "        #check if the file has been saved as a pickle file in the directory\n",
    "        assert os.path.exists(pickle_file), \"The dataframe has not been saved as a pickle file in the directory.\" \n",
    "        \n",
    "        #return the dataframe\n",
    "        return my_df\n",
    "    \n",
    "#call the function to save the dataframe as a pickle file\n",
    "main_df_forprocessing_addedcol_pickle = save_dataframe_as_pickle(main_df_forprocessing_addedcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas version 1.3.3, save the dataframe as a pickle file \n",
    "main_df_forprocessing_addedcol_pickle.to_pickle('spikes_dataframe.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pickle file as a dataframe, for further proressing\n",
    "spikes_df = pd.read_pickle('/Users/cresp1el/Documents/lmc_project_analysis_dir/analysis_directory/test5.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#check the dataframe --not needed for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the first entry in the dataframe\n",
    "first_entry_spikes_df = spikes_df['spikes'][0]\n",
    "\n",
    "#how many cells are there in the dataframe per group?\n",
    "spikes_df.groupby('group_name')['cell_id'].nunique()\n",
    "\n",
    "#print the unique cell ids per group\n",
    "print('The unique cell ids per group are: ', spikes_df.groupby('group_name')['cell_id'].unique())\n",
    "\n",
    "#print the unique mice \n",
    "print('The unique mice per group are: ', spikes_df.groupby('group_name')['mouse_id'].unique())\n",
    "\n",
    "#how many mice are there in the dataframe per group?\n",
    "spikes_df.groupby('group_name')['mouse_id'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that will take in a user group name, a cell id, mouse id, and pre or post and return four numpy matrices\n",
    "def create_matrices_from_user_input(group_name, cell_id, mouse_id, pre_or_post):\n",
    "\n",
    "    #create a dataframe that has the user input group name, cell id, mouse id, and pre or post\n",
    "    user_input_df = spikes_df[(spikes_df['group_name'] == group_name) & (spikes_df['cell_id'] == cell_id) & (spikes_df['mouse_id'] == mouse_id) & (spikes_df['is_post'] == pre_or_post)]\n",
    "    \n",
    "    #check if the dataframe is empty\n",
    "    if user_input_df.empty:\n",
    "        print('No data found for the given input.')\n",
    "        return None\n",
    "    \n",
    "    #now create four numpy matrices from the dataframe based on the true values in the zero, low, mid, high columns\n",
    "    zero_matrix = user_input_df[user_input_df['zero'] == True]['spikes'].iloc[0]\n",
    "    low_matrix = user_input_df[user_input_df['low'] == True]['spikes'].iloc[0]\n",
    "    mid_matrix = user_input_df[user_input_df['mid'] == True]['spikes'].iloc[0]\n",
    "    high_matrix = user_input_df[user_input_df['high'] == True]['spikes'].iloc[0]\n",
    "    \n",
    "    #print the shape of each matrix\n",
    "    print('The shape of the zero matrix is: ', zero_matrix.shape)\n",
    "    print('The shape of the low matrix is: ', low_matrix.shape)\n",
    "    print('The shape of the mid matrix is: ', mid_matrix.shape)\n",
    "    print('The shape of the high matrix is: ', high_matrix.shape)\n",
    "    \n",
    "    #return the four matrices in a list\n",
    "    return [zero_matrix, low_matrix, mid_matrix, high_matrix] #this is a list of numpy matrices \n",
    "\n",
    "#call the function to create the matrices   \n",
    "user_input_matrices = create_matrices_from_user_input('Lmc_opsin', 'cid93', '3093', False)\n",
    "\n",
    "#now plot the raster plots for each matrix in a subplot \n",
    "def plot_raster_plots_from_matrices(matrices_list):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    for i in range(len(matrices_list)):\n",
    "        for ii in range(matrices_list[i].shape[0]):\n",
    "            spike_times = np.where(matrices_list[i][ii] == 1)[0]\n",
    "            axs[i].vlines(spike_times, ii, ii+1, color='black')\n",
    "            axs[i].set_ylabel('Trials')\n",
    "            axs[i].set_xlabel('Time (ms)')\n",
    "            #make each matrix tittle the stimulus intensity \n",
    "            if i == 0:\n",
    "                axs[i].set_title('Zero')\n",
    "            elif i == 1:\n",
    "                axs[i].set_title('Low')\n",
    "            elif i == 2:\n",
    "                axs[i].set_title('Mid')\n",
    "            elif i == 3:\n",
    "                axs[i].set_title('High')\n",
    "                \n",
    "                \n",
    "    plt.show()\n",
    "    return fig, axs\n",
    "    \n",
    "#call the function to plot the raster plots for each matrix\n",
    "raster_plots = plot_raster_plots_from_matrices(user_input_matrices)    \n",
    "                \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create a function that is similar to the one above but it will loop through the unique cell ids instead for plotting the raster plots\n",
    "def plot_raster_plots_from_unique_cell_ids(group_name, mouse_id, pre_or_post):\n",
    "    #create a dataframe that has the user input group name, mouse id, and pre or post \n",
    "    user_input_df = spikes_df[(spikes_df['group_name'] == group_name) & (spikes_df['mouse_id'] == mouse_id) & (spikes_df['is_post'] == pre_or_post)]\n",
    "    \n",
    "    #check if the dataframe is empty\n",
    "    if user_input_df.empty:\n",
    "        print('No data found for the given input.')\n",
    "        return None\n",
    "    \n",
    "    #Loop through the unique cell ids and plot the raster plots for each cell id as before \n",
    "    for cell_id in user_input_df['cell_id'].unique():\n",
    "        #now create four numpy matrices from the dataframe based on the true values in the zero, low, mid, high columns\n",
    "        zero_matrix = user_input_df[(user_input_df['zero'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "        low_matrix = user_input_df[(user_input_df['low'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "        mid_matrix = user_input_df[(user_input_df['mid'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "        high_matrix = user_input_df[(user_input_df['high'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "        \n",
    "        #create a list of the four matrices\n",
    "        matrices_list = [zero_matrix, low_matrix, mid_matrix, high_matrix]\n",
    "        \n",
    "        #now plot the raster plots for each matrix in a subplot \n",
    "        fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "        for i in range(len(matrices_list)):\n",
    "            #loop through the rows in the matrix\n",
    "            for ii in range(matrices_list[i].shape[0]):\n",
    "                spike_times = np.where(matrices_list[i][ii] == 1)[0]\n",
    "                axs[i].vlines(spike_times, ii, ii+1, color='black')\n",
    "                axs[i].set_ylabel('Trials')\n",
    "                axs[i].set_xlabel('Time (ms)')\n",
    "                #make each matrix tittle the stimulus intensity \n",
    "                if i == 0:\n",
    "                    axs[i].set_title('Zero')\n",
    "                elif i == 1:\n",
    "                    axs[i].set_title('Low')\n",
    "                elif i == 2:\n",
    "                    axs[i].set_title('Mid')\n",
    "                elif i == 3:\n",
    "                    axs[i].set_title('High')\n",
    "                    \n",
    "        #make the title of each of the figures list the cell id, mouse id, and pre or post somewhere on the figure\n",
    "        fig.suptitle('Cell ID: ' + str(cell_id) + ' Mouse: ' + str(mouse_id) + 'Group ID: ' + str(group_name) + 'is Post: ' + str(pre_or_post))\n",
    "                    \n",
    "        #make sure the text of set_title is not overlapping with the subplots\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        \n",
    "        #now append the figure to a list of figures for the next cell id\n",
    "        #fig_list.append(fig)\n",
    "        \n",
    "        #show the figure\n",
    "        plt.show()\n",
    "        \n",
    "#call the function to plot the raster plots for each unique cell id \n",
    "\n",
    "#plot_raster_plots_from_unique_cell_ids('Lmc_opsin', '3093', True) #this will plot the raster plots for each unique cell id in the dataframe for the given group name, mouse id, and pre or post\n",
    "plot_raster_plots_from_unique_cell_ids('Lmc_noopsin', '3096', False)     \n",
    "plot_raster_plots_from_unique_cell_ids('Lmc_noopsin', '3096', True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sum_of_spikes(group_name, mouse_id, pre_or_post):\n",
    "    #create a dataframe that has the user input group name, mouse id, and pre or post\n",
    "    user_input_df = spikes_df[(spikes_df['group_name'] == group_name) & (spikes_df['mouse_id'] == mouse_id) & (spikes_df['is_post'] == pre_or_post)]\n",
    "    \n",
    "    #check if the dataframe is empty\n",
    "    if user_input_df.empty:\n",
    "        print('No data found for the given input.')\n",
    "        return None\n",
    "    \n",
    "    #create an empty dataframe that will store the sum of the spikes in each matrix\n",
    "    sum_of_spikes_df = pd.DataFrame()\n",
    "    \n",
    "    #Loop through the unique cell ids and calculate the sum of the spikes in each matrix for each cell id\n",
    "    for cell_id in user_input_df['cell_id'].unique():\n",
    "        #now create four numpy matrices from the dataframe based on the true values in the zero, low, mid, high columns\n",
    "        zero_matrix = user_input_df[(user_input_df['zero'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "        low_matrix = user_input_df[(user_input_df['low'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "        mid_matrix = user_input_df[(user_input_df['mid'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "        high_matrix = user_input_df[(user_input_df['high'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "\n",
    "        #calculate the sum of the spikes in each matrix by summing down the columns\n",
    "        zero_matrix_sum = np.sum(zero_matrix, axis = 0)\n",
    "        low_matrix_sum = np.sum(low_matrix, axis = 0)\n",
    "        mid_matrix_sum = np.sum(mid_matrix, axis = 0)\n",
    "        high_matrix_sum = np.sum(high_matrix, axis = 0)\n",
    "        \n",
    "        #print the shape of each matrix \n",
    "        print('The shape of the zero matrix is: ', zero_matrix_sum.shape)\n",
    "        print('The shape of the low matrix is: ', low_matrix_sum.shape)\n",
    "        print('The shape of the mid matrix is: ', mid_matrix_sum.shape)\n",
    "        print('The shape of the high matrix is: ', high_matrix_sum.shape)\n",
    "        \n",
    "        #insert the entire array into a list and then insert the list into the dataframe that has four columns called zero_sum_array, low_sum_array, mid_sum_array, high_sum_array and matches the cell id, mouse id, group name, and pre or post of this cell id\n",
    "        sum_of_spikes_dict = {'zero_sum_array': [zero_matrix_sum], 'low_sum_array': [low_matrix_sum], 'mid_sum_array': [mid_matrix_sum], 'high_sum_array': [high_matrix_sum]}\n",
    "\n",
    "        #store the dictionary in a dataframe where the 1500 array is in a separate column\n",
    "        sum_of_spikes_df_temp = pd.DataFrame(sum_of_spikes_dict)\n",
    "        \n",
    "        #now add the cell id, mouse id, group name, and pre or post to the dataframe of the corresponding cell id \n",
    "        sum_of_spikes_df_temp['cell_id'] = cell_id\n",
    "        sum_of_spikes_df_temp['mouse_id'] = mouse_id\n",
    "        sum_of_spikes_df_temp['group_name'] = group_name\n",
    "        sum_of_spikes_df_temp['is_post'] = pre_or_post\n",
    "        \n",
    "        #append the dataframe to the empty dataframe \n",
    "        sum_of_spikes_df = pd.concat([sum_of_spikes_df, sum_of_spikes_df_temp], ignore_index=True)\n",
    "    #return the dataframe\n",
    "    return sum_of_spikes_df\n",
    "\n",
    "#call the function to calculate the sum of the spikes in each matrix for each cell id   \n",
    "sum_of_spikes_df = calculate_sum_of_spikes('Lmc_opsin', '3093', False) #this will calculate the sum of the spikes in each matrix for each cell id in the dataframe for the given group name, mouse id, and pre or post\n",
    "\n",
    "\n",
    "#create a function that will do the same as above but will automatically loop through each group name, then mouse id, then pre or post for each cell id to create one dataframe that has the sum of the spikes in each matrix for each cell id\n",
    "def calculate_sum_of_spikes_for_all_cell_ids():\n",
    "    \n",
    "    #check if the dataframe is empty\n",
    "    if spikes_df.empty:\n",
    "        print('No data found for the given input.')\n",
    "        return None\n",
    "\n",
    "    #create an empty dataframe that will store the sum of the spikes in each matrix\n",
    "    sum_of_spikes_df = pd.DataFrame()\n",
    "    \n",
    "    #loop through the unique group names\n",
    "    for group_name in spikes_df['group_name'].unique():\n",
    "        #loop through the unique mouse ids\n",
    "        for mouse_id in spikes_df['mouse_id'].unique():\n",
    "            #loop through the unique pre or post\n",
    "            for pre_or_post in spikes_df['is_post'].unique():\n",
    "                #create a dataframe that has the user input group name, mouse id, and pre or post\n",
    "                user_input_df = spikes_df[(spikes_df['group_name'] == group_name) & (spikes_df['mouse_id'] == mouse_id) & (spikes_df['is_post'] == pre_or_post)]\n",
    "\n",
    "                #Loop through the unique cell ids and calculate the sum of the spikes in each matrix for each cell id\n",
    "                for cell_id in user_input_df['cell_id'].unique():\n",
    "                    #now create four numpy matrices from the dataframe based on the true values in the zero, low, mid, high columns\n",
    "                    zero_matrix = user_input_df[(user_input_df['zero'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "                    low_matrix = user_input_df[(user_input_df['low'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "                    mid_matrix = user_input_df[(user_input_df['mid'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "                    high_matrix = user_input_df[(user_input_df['high'] == True) & (user_input_df['cell_id'] == cell_id)]['spikes'].iloc[0]\n",
    "                    \n",
    "                    #calculate the sum of the spikes in each matrix by summing down the columns\n",
    "                    zero_matrix_sum = np.sum(zero_matrix, axis = 0)\n",
    "                    low_matrix_sum = np.sum(low_matrix, axis = 0)\n",
    "                    mid_matrix_sum = np.sum(mid_matrix, axis = 0)\n",
    "                    high_matrix_sum = np.sum(high_matrix, axis = 0)\n",
    "                    \n",
    "                    #print the shape of each matrix for the user to check\n",
    "                    print('The shape of the zero matrix is: ', zero_matrix_sum.shape)\n",
    "                    print('The shape of the low matrix is: ', low_matrix_sum.shape)\n",
    "                    print('The shape of the mid matrix is: ', mid_matrix_sum.shape)\n",
    "                    print('The shape of the high matrix is: ', high_matrix_sum.shape)\n",
    "                    \n",
    "                    #insert the entire array into a list and then insert the list into the dataframe that has four columns called zero_sum_array, low_sum_array, mid_sum_array, high_sum_array and matches the cell id, mouse id, group name, and pre or post of this cell id\n",
    "                    sum_of_spikes_dict = {'zero_sum_array': [zero_matrix_sum], 'low_sum_array': [low_matrix_sum], 'mid_sum_array': [mid_matrix_sum], 'high_sum_array': [high_matrix_sum]}\n",
    "                    \n",
    "                    #store the dictionary in a dataframe where the 1500 array is in a separate column\n",
    "                    sum_of_spikes_df_temp = pd.DataFrame(sum_of_spikes_dict)\n",
    "                    \n",
    "                    #now add the cell id, mouse id, group name, and pre or post to the dataframe of the corresponding cell id\n",
    "                    sum_of_spikes_df_temp['cell_id'] = cell_id\n",
    "                    sum_of_spikes_df_temp['mouse_id'] = mouse_id\n",
    "                    sum_of_spikes_df_temp['group_name'] = group_name\n",
    "                    sum_of_spikes_df_temp['is_post'] = pre_or_post\n",
    "\n",
    "                    #append the dataframe to the empty dataframe\n",
    "                    sum_of_spikes_df = pd.concat([sum_of_spikes_df, sum_of_spikes_df_temp], ignore_index=True)\n",
    "\n",
    "    #return the dataframe\n",
    "    return sum_of_spikes_df\n",
    "\n",
    "#call the function to calculate the sum of the spikes in each matrix for each cell id for all group names, mouse ids, and pre or post   \n",
    "sum_of_all_cellids_spikes_df = calculate_sum_of_spikes_for_all_cell_ids() #this will calculate the sum of the spikes in each matrix for each cell id in the dataframe for all group names, mouse ids, and pre or post\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which pandas version are you using?\n",
    "pd.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that will loop through thr dictionary keys and create a dataframe per key and append it the to the dataframe \n",
    "\n",
    "def spiketrains_df(spiketrains_dict):\n",
    "    #first loop through the the keys in the dictionary and create a dataframe for each key at the end of the loop append the dataframe to the main dataframe\n",
    "\n",
    "    #create an empty dataframe called main_df\n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    #create a list of column names that will be used for the main dataframe column names\n",
    "    column_names = ['trial_name','trial_id','spikes', 'zero','low','mid','high']\n",
    "    \n",
    "    \n",
    "    #loop through the keys in the dictionary\n",
    "    #for each key determine the numbner of trials which is the number of rows of the matrix\n",
    "    #then loop through the number of rows, create the trial_id which is the row number, add the row number to the trial_number column\n",
    "    #then pull out the row slice of the matrix and add it to the corresponding spikes column\n",
    "    #then add the trial name to the trial_name column\n",
    "    \n",
    "    for key in spiketrains_dict:\n",
    "        \n",
    "        #determine the number of trials which is the number of rows of the matrix\n",
    "        num_trials = spiketrains_dict[key].shape[0]\n",
    "        \n",
    "        #iterate through the number of trials of the matrix and pull out the row slice of the matrix, store the row number as the trial_id in the main_df\n",
    "        for trial in range(num_trials):\n",
    "                \n",
    "                #create a dataframe for each trial\n",
    "                trial_df = pd.DataFrame()\n",
    "                \n",
    "                #add the trial_id to the trial_id column\n",
    "                trial_df['trial_id'] = [trial]\n",
    "                \n",
    "                #add the spikes to the spikes column, pull out the row slice of the matrix\n",
    "                trial_df['spikes'] = [spiketrains_dict[key][trial,:]]\n",
    "                \n",
    "                #add the trial name to the trial_name column\n",
    "                trial_df['trial_name'] = [key]\n",
    "                \n",
    "                #check if the trial name is pre or post and TRUE in the column 'is_post'\n",
    "                if 'post' in key:\n",
    "                    trial_df['is_post'] = True\n",
    "                else:\n",
    "                    trial_df['is_post'] = False\n",
    "                    \n",
    "                #check if the trial name is zero, low, mid, or high and TRUE in the corresponding columnm if not FALSE\n",
    "                if 'zero' in key:\n",
    "                    trial_df['zero'] = True\n",
    "                    trial_df['low'] = False\n",
    "                    trial_df['mid'] = False\n",
    "                    trial_df['high'] = False\n",
    "                elif 'low' in key:\n",
    "                    trial_df['zero'] = False\n",
    "                    trial_df['low'] = True\n",
    "                    trial_df['mid'] = False\n",
    "                    trial_df['high'] = False\n",
    "                elif 'mid' in key:\n",
    "                    trial_df['zero'] = False\n",
    "                    trial_df['low'] = False\n",
    "                    trial_df['mid'] = True\n",
    "                    trial_df['high'] = False\n",
    "                elif 'high' in key:\n",
    "                    trial_df['zero'] = False\n",
    "                    trial_df['low'] = False\n",
    "                    trial_df['mid'] = False\n",
    "                    trial_df['high'] = True\n",
    "                    \n",
    "                #check if there are at least 2 spikes in the trial, if there are more than 2 spike then TRUE in the column 'more_than_2' or FALSE if there are less than 2 spikes\n",
    "                if np.sum(spiketrains_dict[key][trial,:]) > 2:\n",
    "                    trial_df['more_than_2'] = True\n",
    "                else:\n",
    "                    trial_df['more_than_2'] = False        \n",
    "                    \n",
    "                    \n",
    "                #check if there are more than 50 spikes in the trial, if there are more than 50 spikes then TRUE in the column 'more_than_50' or FALSE if there are less than 50 spikes\n",
    "                if np.sum(spiketrains_dict[key][trial,:]) > 50:\n",
    "                    trial_df['more_than_50'] = True\n",
    "                else:\n",
    "                    trial_df['more_than_50'] = False\n",
    "                \n",
    "                #append the trial_df to the main_df\n",
    "                main_df = main_df.append(trial_df)\n",
    "                \n",
    "    #reset the index of the main_df\n",
    "    main_df = main_df.reset_index(drop=True)\n",
    "    \n",
    "        \n",
    "    return main_df\n",
    "\n",
    "#call the function to create the dataframe\n",
    "main_df = spiketrains_df(spiketrains_dict)\n",
    "    \n",
    "#now         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function to calculate the mean firing rate for each stimulus frequency from dict of spike matrices and return a dict of mean firing rates where the keys are the stimulus frequencies\n",
    "def mean_firing_rate_dict(spiketrains_dict):\n",
    "    mean_firing_rate_dict = {}\n",
    "    for key in spiketrains_dict:\n",
    "        mean_firing_rate_dict[key] = np.mean(spiketrains_dict[key], axis=0)*1000 #multiply by 1000 to convert to Hz\n",
    "    return mean_firing_rate_dict\n",
    "\n",
    "#call the function to create the dictionary of mean firing rates\n",
    "mean_firing_rate_dict = mean_firing_rate_dict(spiketrains_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian filter the mean firing rates with user defined sigma and return a dict of gaussian filtered mean firing rates where the keys are the stimulus frequencies\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "#create a function to gaussian filter the mean firing rates with user defined sigma and return a dict of gaussian filtered mean firing rates where the keys are the stimulus frequencies\n",
    "def gaussian_filter_dict(mean_firing_rate_dict, sigma):\n",
    "    gaussian_filter_dict = {}\n",
    "    for key in mean_firing_rate_dict:\n",
    "        gaussian_filter_dict[key] = gaussian_filter(mean_firing_rate_dict[key], sigma=sigma)\n",
    "    return gaussian_filter_dict\n",
    "\n",
    "#call the function to create the dictionary of gaussian filtered mean firing rates\n",
    "gaussian_filter_dict = gaussian_filter_dict(mean_firing_rate_dict, sigma=5)\n",
    "\n",
    "\n",
    "#plot the gaussian filtered mean firing rates for the pre and post stimulus conditions on the same plot\n",
    "def plot_gaussian_filter_dict(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['pre_high'], label='pre_high')\n",
    "    ax.plot(gaussian_filter_dict['post_high'], label='post_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Pre and Post Stimulus Conditions')\n",
    "    \n",
    "    #add vertical lines to indicate the stimulus onset and offset times \n",
    "    ax.axvline(x=500, color='black', linestyle='--')\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for the pre and post stimulus conditions on the same plot\n",
    "plot_gaussian_filter_dict(gaussian_filter_dict)\n",
    "\n",
    "#plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "# keep the color the same for all prestimulus conditions and change the opacity for each stimulus condition\n",
    "def plot_gaussian_filter_dict_all(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['pre_zero'], color='grey', alpha=0.25, label='pre_zero')\n",
    "    ax.plot(gaussian_filter_dict['pre_low'], color='grey', alpha=0.5, label='pre_low')\n",
    "    ax.plot(gaussian_filter_dict['pre_mid'], color='grey', alpha=0.75, label='pre_mid')\n",
    "    ax.plot(gaussian_filter_dict['pre_high'], color='grey', alpha=1, label='pre_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Pre Stimulus Conditions')\n",
    "    \n",
    "    #add vertical lines to indicate the stimulus onset and offset times \n",
    "    ax.axvline(x=500, color='black', linestyle='--')\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all(gaussian_filter_dict)\n",
    "\n",
    "\n",
    "#now repeat the above for the post stimulus conditions\n",
    "#plot the gaussian filtered mean firing rates for all poststimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "# keep the color the same for all poststimulus conditions and change the opacity for each stimulus condition\n",
    "def plot_gaussian_filter_dict_all_post(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['post_zero'], color='blue', alpha=0.25, label='post_zero')\n",
    "    ax.plot(gaussian_filter_dict['post_low'], color='blue', alpha=0.5, label='post_low')\n",
    "    ax.plot(gaussian_filter_dict['post_mid'], color='blue', alpha=0.75, label='post_mid')\n",
    "    ax.plot(gaussian_filter_dict['post_high'], color='blue', alpha=1, label='post_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Post Stimulus Conditions')\n",
    "    \n",
    "    #add vertical lines to indicate the stimulus onset and offset times \n",
    "    ax.axvline(x=500, color='black', linestyle='--')\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all poststimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all_post(gaussian_filter_dict)\n",
    "\n",
    "#now the same but zoom in from 459 to 550 ms\n",
    "#plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "# keep the color the same for all prestimulus conditions and change the opacity for each stimulus condition\n",
    "def plot_gaussian_filter_dict_all_zoom(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['pre_zero'][459:550], color='grey', alpha=0.25, label='pre_zero')\n",
    "    ax.plot(gaussian_filter_dict['pre_low'][459:550], color='grey', alpha=0.5, label='pre_low')\n",
    "    ax.plot(gaussian_filter_dict['pre_mid'][459:550], color='grey', alpha=0.75, label='pre_mid')\n",
    "    ax.plot(gaussian_filter_dict['pre_high'][459:550], color='grey', alpha=1, label='pre_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Pre Stimulus Conditions')\n",
    "        #add vertical lines to indicate the stimulus onset and offset times \n",
    "    ax.axvline(x=50, color='black', linestyle='--')\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all_zoom(gaussian_filter_dict)\n",
    "\n",
    "#now repeat this plot for the post stimulus conditions\n",
    "#plot the gaussian filtered mean firing rates for all poststimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "# keep the color the same for all poststimulus conditions and change the opacity for each stimulus condition\n",
    "def plot_gaussian_filter_dict_all_post_zoom(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['post_zero'][459:550], color='blue', alpha=0.25, label='post_zero')\n",
    "    ax.plot(gaussian_filter_dict['post_low'][459:550], color='blue', alpha=0.5, label='post_low')\n",
    "    ax.plot(gaussian_filter_dict['post_mid'][459:550], color='blue', alpha=0.75, label='post_mid')\n",
    "    ax.plot(gaussian_filter_dict['post_high'][459:550], color='blue', alpha=1, label='post_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Post Stimulus Conditions')\n",
    "    ax.axvline(x=50, color='black', linestyle='--') \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all poststimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all_post_zoom(gaussian_filter_dict)\n",
    "\n",
    "\n",
    "#now over lay the zoomed in pre and post stimulus conditions on the same plot\n",
    "\n",
    "def plot_gaussian_filter_dict_all_zoom_overlay(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['pre_zero'][459:550], color='grey', alpha=0.25, label='pre_zero')\n",
    "    ax.plot(gaussian_filter_dict['pre_low'][459:550], color='grey', alpha=0.5, label='pre_low')\n",
    "    ax.plot(gaussian_filter_dict['pre_mid'][459:550], color='grey', alpha=0.75, label='pre_mid')\n",
    "    ax.plot(gaussian_filter_dict['pre_high'][459:550], color='grey', alpha=1, label='pre_high')\n",
    "    ax.plot(gaussian_filter_dict['post_zero'][459:550], color='blue', alpha=0.25, label='post_zero')\n",
    "    ax.plot(gaussian_filter_dict['post_low'][459:550], color='blue', alpha=0.5, label='post_low')\n",
    "    ax.plot(gaussian_filter_dict['post_mid'][459:550], color='blue', alpha=0.75, label='post_mid')\n",
    "    ax.plot(gaussian_filter_dict['post_high'][459:550], color='blue', alpha=1, label='post_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Pre and Post Stimulus Conditions')\n",
    "    \n",
    "    #make the high stimulus conditions more thick to make it easier to see\n",
    "    ax.plot(gaussian_filter_dict['pre_high'][459:550], color='grey', alpha=1, linewidth=3)\n",
    "    ax.plot(gaussian_filter_dict['post_high'][459:550], color='blue', alpha=1, linewidth=3)\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all_zoom_overlay(gaussian_filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now loop through the keys in the spiketrains_dict and plot a new raster plot for each key\n",
    "for key in spiketrains_dict:\n",
    "    spikes = spiketrains_dict[key]\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i in range(spikes.shape[0]):\n",
    "        spike_times = np.where(spikes[i] == 1)[0]\n",
    "        ax.vlines(spike_times, i, i+1, color='black')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Trial Number')\n",
    "    ax.set_title('Raster Plot for ' + key)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot the same way but using the main_df dataframe as a function\n",
    "#take user input for 'is_post' being True or False\n",
    "#for each stimulus type, create a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe \n",
    "#plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "\n",
    "def plot_raster_main_df(main_df, is_post):\n",
    "    #is_post is a boolean value of 1 or 0\n",
    "    #if is_post is 1, then plot the post stimulus conditions\n",
    "    #if is_post is 0, then plot the pre stimulus conditions\n",
    "    \n",
    "    #filter the dataframe based on the is_post value\n",
    "    if is_post:\n",
    "        main_df = main_df[main_df['is_post'] == 1]\n",
    "        #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns\n",
    "        main_df_zero = main_df[main_df['zero'] == 1] \n",
    "        main_df_low = main_df[main_df['low'] == 1]\n",
    "        main_df_mid = main_df[main_df['mid'] == 1]\n",
    "        main_df_high = main_df[main_df['high'] == 1]\n",
    "        \n",
    "        #now plot the raster plot for each stimulus type by creating a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe\n",
    "        #plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "        #plot each raster on a new figure\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_zero.shape[0]):  \n",
    "            spike_times = np.where(main_df_zero['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Post Zero')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_low.shape[0]):\n",
    "            spike_times = np.where(main_df_low['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Post Low')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)    \n",
    "        for i in range(main_df_mid.shape[0]):\n",
    "            spike_times = np.where(main_df_mid['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Post Mid')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_high.shape[0]):\n",
    "            spike_times = np.where(main_df_high['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Post High')\n",
    "    #if is_post is 0, then plot the pre stimulus conditions\n",
    "    else:\n",
    "        main_df = main_df[main_df['is_post'] == 0]\n",
    "        \n",
    "        #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns\n",
    "        main_df_zero = main_df[main_df['zero'] == 1]\n",
    "        main_df_low = main_df[main_df['low'] == 1]\n",
    "        main_df_mid = main_df[main_df['mid'] == 1]\n",
    "        main_df_high = main_df[main_df['high'] == 1]\n",
    "    \n",
    "        #now plot the raster plot for each stimulus type by creating a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe\n",
    "        #plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "        #plot each raster on a new figure\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_zero.shape[0]):\n",
    "            spike_times = np.where(main_df_zero['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Pre Zero')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_low.shape[0]):\n",
    "            spike_times = np.where(main_df_low['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Pre Low')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_mid.shape[0]):\n",
    "            spike_times = np.where(main_df_mid['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Pre Mid')\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_high.shape[0]):\n",
    "            spike_times = np.where(main_df_high['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)') \n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Pre High')\n",
    "        \n",
    "    #now display all the figure\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "#call the nunction to plot the raster plot for the pre stimulus conditions\n",
    "plot_raster_main_df(main_df, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that will filter the main_df datarame\n",
    "#take user input for input for true or false for is_post \n",
    "#then in a iterative manner, 1) filter the dataframe by zero, low, mid, high 2) filter the dataframe by no_spike being FALSE and more_than_50 being TRUE 3) plot the raster plot for each stimulus as a new plot \n",
    "def plot_raster_main_df_no_spike(main_df, is_post):\n",
    "   #is_post is a boolean value of 1 or 0\n",
    "   #if is_post is 1, then plot the post stimulus conditions\n",
    "   #if is_post is 0, then plot the pre stimulus conditions\n",
    "   #filter the dataframe by is_post being TRUE or FALSE\n",
    "   if is_post == 1:\n",
    "      #filter the dataframe by is_post being TRUE\n",
    "      main_df = main_df[main_df['is_post'] == 1]\n",
    "      #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns AND filter the dataframe by no_spike being FALSE and more_than_50 being FALSE conditions\n",
    "      main_df_zero = main_df[(main_df['zero'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_low = main_df[(main_df['low'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_mid = main_df[(main_df['mid'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_high = main_df[(main_df['high'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "\n",
    "      #now plot the raster plot for each stimulus type by creating a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe\n",
    "      #plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "      #plot each raster on a new figure   \n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_zero.shape[0]):\n",
    "         spike_times = np.where(main_df_zero['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number') \n",
    "      ax.set_title('Raster Plot for Post Zero')\n",
    "\n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_low.shape[0]):\n",
    "         spike_times = np.where(main_df_low['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Post Low ')\n",
    "\n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_mid.shape[0]):\n",
    "         spike_times = np.where(main_df_mid['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Post Mid')\n",
    "\n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_high.shape[0]):\n",
    "         spike_times = np.where(main_df_high['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Post High')   \n",
    "\n",
    "   else: \n",
    "      #filter the dataframe by is_post being FALSE\n",
    "      main_df = main_df[main_df['is_post'] == 0]\n",
    "      #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns AND filter the dataframe by no_spike being FALSE and more_than_50 being FALSE conditions\n",
    "      main_df_zero = main_df[(main_df['zero'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_low = main_df[(main_df['low'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_mid = main_df[(main_df['mid'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_high = main_df[(main_df['high'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "\n",
    "      #now plot the raster plot for each stimulus type by creating a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe\n",
    "      #plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "      #plot each raster on a new figure\n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_zero.shape[0]):\n",
    "         spike_times = np.where(main_df_zero['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Pre Zero')\n",
    "      \n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_low.shape[0]):\n",
    "         spike_times = np.where(main_df_low['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Pre Low')\n",
    "      \n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_mid.shape[0]):\n",
    "         spike_times = np.where(main_df_mid['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)') \n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Pre Mid')\n",
    "      \n",
    "      \n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_high.shape[0]):\n",
    "         spike_times = np.where(main_df_high['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Pre High')\n",
    "\n",
    "\n",
    "      \n",
    "   plt.show()\n",
    "   \n",
    "   return \n",
    "\n",
    "#call the function to plot the raster plot for the pre and post stimulus types for filtered dataframes\n",
    "plot_raster_main_df_no_spike(main_df, 1) \n",
    "plot_raster_main_df_no_spike(main_df, 0) \n",
    "         \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculateISIsfromfiltereddata(main_df, is_post):\n",
    "    #is_post is a boolean value of 1 or 0\n",
    "    #if is_post is 1, then plot the post stimulus conditions\n",
    "    #if is_post is 0, then plot the pre stimulus conditions\n",
    "    #filter the dataframe by is_post being TRUE or FALSE\n",
    "\n",
    "    \n",
    "    if is_post == 1:\n",
    "        #filter the dataframe by is_post being TRUE\n",
    "        main_df = main_df[main_df['is_post'] == 1]\n",
    "        #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns AND filter the dataframe by no_spike being FALSE and more_than_50 being FALSE conditions\n",
    "        main_df_zero = main_df[(main_df['zero'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_low = main_df[(main_df['low'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_mid = main_df[(main_df['mid'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_high = main_df[(main_df['high'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        \n",
    "        #store the dataframes into a list to iterate through\n",
    "        main_df_list = [main_df_zero, main_df_low, main_df_mid, main_df_high]\n",
    "        \n",
    "        #for each dataframe in the list, add a columns for the ISIs to be stored in\n",
    "        for df in main_df_list:\n",
    "            df['ISIs'] = pd.Series(dtype=object)\n",
    "            \n",
    "        #iterate through the list of dataframes to do the following:\n",
    "        # 1) create an array for the calculated  ISIs to be stored in for each trial which correspond to the row of the partiuclar dataframe\n",
    "        # 2) iterate through the spikes column for the length of rows of the particualr  dataframe to calculate the ISIs for each trial\n",
    "        \n",
    "        for df in main_df_list:\n",
    "            for i in range(df.shape[0]):\n",
    "                ISIs = []\n",
    "                spike_times = np.where(df['spikes'].iloc[i] == 1)[0]\n",
    "                for j in range(len(spike_times)-1):\n",
    "                    ISI = spike_times[j+1] - spike_times[j]\n",
    "                    ISIs.append(ISI)\n",
    "                df['ISIs'].iloc[i] = ISIs\n",
    "                \n",
    "    #else if is_post is 0, repeate the same process as above but for the pre stimulus conditions\n",
    "    elif is_post == 0:\n",
    "        main_df = main_df[main_df['is_post'] == 0]\n",
    "        main_df_zero = main_df[(main_df['zero'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_low = main_df[(main_df['low'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_mid = main_df[(main_df['mid'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_high = main_df[(main_df['high'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        \n",
    "        main_df_list = [main_df_zero, main_df_low, main_df_mid, main_df_high]\n",
    "        \n",
    "        #for each dataframe in the list, add a columns for the ISIs to be stored in\n",
    "        for df in main_df_list:\n",
    "            df['ISIs'] = pd.Series(dtype=object)\n",
    "            \n",
    "        #iterate through the list of dataframes to do the following:\n",
    "        # 1) create an array for the calculated  ISIs to be stored in for each trial which correspond to the row of the partiuclar dataframe\n",
    "        # 2) iterate through the spikes column for the length of rows of the particualr  dataframe to calculate the ISIs for each trial\n",
    "        \n",
    "        for df in main_df_list:\n",
    "            for i in range(df.shape[0]):\n",
    "                ISIs = []\n",
    "                spike_times = np.where(df['spikes'].iloc[i] == 1)[0]\n",
    "                for j in range(len(spike_times)-1):\n",
    "                    ISI = spike_times[j+1] - spike_times[j]\n",
    "                    ISIs.append(ISI)\n",
    "                df['ISIs'].iloc[i] = ISIs\n",
    "                \n",
    "                    \n",
    "    #retunn the updated list of dataframes once processed\n",
    "    return main_df_list\n",
    "\n",
    "#call the function to calculate the ISIs for the post stimulus conditions\n",
    "main_df_list_post = calculateISIsfromfiltereddata(main_df, 1)\n",
    "\n",
    "#call the function to calculate the ISIs for the pre stimulus conditions\n",
    "main_df_list_pre = calculateISIsfromfiltereddata(main_df, 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "#create a funnction to plot the histogram of the ISIs using the list of dataframes given to the function as an input \n",
    "def plotISIhistogram(main_df_list):\n",
    "    #iterate through the list of dataframes to plot the histogram of the ISIs for each stimulus type on a separate plot\n",
    "    for df in main_df_list:\n",
    "        #store all ISIs into a list for plotting and peform a log transformation on the ISIs\n",
    "        all_ISIs = []       \n",
    "        \n",
    "        #iniatilize the bin_size=25 for the histogram, ##CHANGE HERE FOR BIN SIZE was 25\n",
    "        bin_size = 1\n",
    "        \n",
    "        for i in range(df.shape[0]):\n",
    "            for j in range(len(df['ISIs'].iloc[i])):\n",
    "                all_ISIs.append(df['ISIs'].iloc[i][j])\n",
    "                \n",
    "                #of the \n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "        #plot the histogram of the ISIs overlaid with the gaussian kernel density estimate\n",
    "        plt.hist(all_ISIs, bins=np.arange(0, max(all_ISIs) + bin_size, bin_size), density=True)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        #log scale the y axis\n",
    "        plt.yscale('log')\n",
    "        #set the the upper limit of the y axis to be 1\n",
    "        \n",
    "        #set the x axis to be 1500ms ###CHANGE HERE TO ZOOM\n",
    "        plt.xlim(0, 1000)\n",
    "        \n",
    "        plt.ylim(0.0001, 1)    \n",
    "\n",
    "        #set the x axis label\n",
    "        plt.xlabel('ISI (ms)')\n",
    "        \n",
    "        #set the title to be the column called 'trial_name' in the dataframe\n",
    "        plt.title(df['trial_name'].iloc[0])\n",
    "\n",
    "        #show the plot\n",
    "        plt.show()\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "#call the function to plot the histogram of the ISIs for the pre stimulus conditions\n",
    "plotISIhistogram(main_df_list_pre)\n",
    "\n",
    "#call the function to plot the histogram of the ISIs for the post stimulus conditions   \n",
    "plotISIhistogram(main_df_list_post)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repeat the same process as above but zoom in on the ISIs between 0 and 100ms  \n",
    "def plotISIhistogramzoomed(main_df_list):\n",
    "    #iterate through the list of dataframes to plot the histogram of the ISIs for each stimulus type on a separate plot\n",
    "    for df in main_df_list:\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now calculate the ISI for each spike train and plot the histogram of the ISI for each spike train\n",
    "for key in spiketrains_dict:\n",
    "    spikes = spiketrains_dict[key]\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i in range(spikes.shape[0]):\n",
    "        spike_times = np.where(spikes[i] == 1)[0]\n",
    "        ISI = np.diff(spike_times)\n",
    "        ax.hist(ISI, bins=20)\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Trial Number')\n",
    "    ax.set_title('Histogram of ISI for ' + key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create a list of matrices for the pre and post stimulus conditions in two different lists and each matrix is a list of the spike times for each stimulus condition zero, low, mid, high\n",
    "pre_stimulus_list = []\n",
    "post_stimulus_list = []\n",
    "for key in spiketrains_dict:\n",
    "    if key.startswith('pre'):\n",
    "        pre_stimulus_list.append(spiketrains_dict[key])\n",
    "    else:\n",
    "        post_stimulus_list.append(spiketrains_dict[key])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now combine the pre matrices into one matrix and the post matrices into one matrix based on the keys names in the spiketrains_dict\n",
    "#rename the keys in the spiketrains_dict to be pre and post\n",
    "spiketrains_dict['pre'] = spiketrains_dict.pop('pre_zero')\n",
    "spiketrains_dict['pre'] = np.vstack((spiketrains_dict['pre'], spiketrains_dict.pop('pre_low')))\n",
    "spiketrains_dict['pre'] = np.vstack((spiketrains_dict['pre'], spiketrains_dict.pop('pre_mid')))\n",
    "spiketrains_dict['pre'] = np.vstack((spiketrains_dict['pre'], spiketrains_dict.pop('pre_high')))\n",
    "spiketrains_dict['post'] = spiketrains_dict.pop('post_zero')\n",
    "spiketrains_dict['post'] = np.vstack((spiketrains_dict['post'], spiketrains_dict.pop('post_low')))\n",
    "spiketrains_dict['post'] = np.vstack((spiketrains_dict['post'], spiketrains_dict.pop('post_mid')))\n",
    "spiketrains_dict['post'] = np.vstack((spiketrains_dict['post'], spiketrains_dict.pop('post_high')))\n",
    "\n",
    "\n",
    "#now plot the raster plot for the pre and post stimulus conditions\n",
    "for key in spiketrains_dict:\n",
    "    spikes = spiketrains_dict[key]\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i in range(spikes.shape[0]):\n",
    "        spike_times = np.where(spikes[i] == 1)[0]\n",
    "        ax.vlines(spike_times, i, i+1, color='black')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Trial Number')\n",
    "    ax.set_title('Raster Plot for ' + key)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a matrix called pre_matrix annd post_matrix from the spiketrains_dict\n",
    "pre_matrix = spiketrains_dict['pre']\n",
    "post_matrix = spiketrains_dict['post']\n",
    "\n",
    "#now create a subplot with 2 rows and 1 column\n",
    "#using the pre_matrix and post_matrix, plot the raster plots for the pre and post stimulus conditions\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ax[0].vlines(spike_times, i, i+1, color='black')\n",
    "ax[0].set_xlabel('Time (ms)')\n",
    "ax[0].set_ylabel('Trial Number')\n",
    "ax[0].set_title('Raster Plot for Pre Stimulus Condition')\n",
    "\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ax[1].vlines(spike_times, i, i+1, color='black')\n",
    "ax[1].set_xlabel('Time (ms)')\n",
    "ax[1].set_ylabel('Trial Number')\n",
    "ax[1].set_title('Raster Plot for Post Stimulus Condition')\n",
    "\n",
    "#create more spave between the two plots and keep both y axes the same which ever is larger\n",
    "\n",
    "#find the max y value for the pre and post stimulus conditions\n",
    "pre_max_y = pre_matrix.shape[0]\n",
    "post_max_y = post_matrix.shape[0]\n",
    "\n",
    "#set the y limits for both plots to be the max y value\n",
    "ax[0].set_ylim(0, max(pre_max_y, post_max_y))\n",
    "ax[1].set_ylim(0, max(pre_max_y, post_max_y))\n",
    "\n",
    "#set the space between the two plots to be 0.5\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "#now plot the ISI for the pre and post stimulus conditions \n",
    "#pre stimulus condition is in blue and post stimulus condition is in red\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    ax.hist(ISI, bins=50, color='grey', alpha=0.5)\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    ax.hist(ISI, bins=50, color='blue', alpha=0.5)\n",
    "    \n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Trial Number')\n",
    "ax.set_title('Histogram of ISI for Pre and Post Stimulus Conditions')\n",
    "\n",
    "#now create a smpoothed histogram of the ISI for the pre and post stimulus conditions\n",
    "#pre stimulus condition is in blue and post stimulus condition is in red\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.distplot(ISI, hist=False, color='grey')\n",
    "    #zoom in on the y axis to see the distribution better\n",
    "    ax.set_ylim(0, 0.01)\n",
    "    ax.set_xlim(-500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create a smpoothed histogram of the ISI for the post stimulus conditions\n",
    "#post stimulus condition is in blue\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.distplot(ISI, hist=False, color='blue')\n",
    "    #zoom in on the y axis to see the distribution better\n",
    "    ax.set_ylim(0, 0.01)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian kernel density estimation\n",
    "#now create a smpoothed histogram of the ISI for the pre and post stimulus conditions\n",
    "#pre stimulus condition is in grey and post stimulus condition is in blue\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.kdeplot(ISI, color='grey')\n",
    "    #zoom in on the y axis to see the distribution better\n",
    "    ax.set_ylim(0, 0.01)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "    \n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.kdeplot(ISI, color='blue')\n",
    "    #zoom in on the y axis to see the distribution better\n",
    "    ax.set_ylim(0, 0.01)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian kernel density estimation\n",
    "#now create a smpoothed histogram of the ISI for the pre and post stimulus conditions\n",
    "#pre stimulus condition is in grey and post stimulus condition is in blue\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.kdeplot(ISI, color='grey')\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.kdeplot(ISI, color='blue')\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the probability distribution of the ISIs for the pre and post stimulus conditions\n",
    "#pre stimulus condition is in grey and post stimulus condition is in blue\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    ax.hist(ISI, bins=50, density=True, color='grey', alpha=0.5)\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    ax.hist(ISI, bins=50, density=True, color='blue', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Probability Distribution of ISI for Pre and Post Stimulus Conditions')\n",
    "\n",
    "#zoom in on the y axis to see the distribution better\n",
    "ax.set_ylim(0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmc_ephys_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
