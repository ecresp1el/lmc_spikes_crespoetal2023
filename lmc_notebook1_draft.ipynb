{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def load_pickle_file(file_name):\n",
    "    # ask the user to select the directory path to the pickle file\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    file_path = filedialog.askdirectory()\n",
    "\n",
    "    # load the selected pickle file from the user provided file path\n",
    "    if file_path:\n",
    "        try:\n",
    "            with open(file_path + '/' + file_name, 'rb') as f:\n",
    "                output_dict_forprocessing = pickle.load(f)\n",
    "                print(\"Pickle file loaded successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No pickle file found in the selected directory.\")\n",
    "            \n",
    "    return output_dict_forprocessing\n",
    "\n",
    "#load the pickle file\n",
    "output_dict_forprocessing = load_pickle_file('SpikeTrains_for_PSTHs.p')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeTrainsDict:\n",
    "    def __init__(self, my_dict):\n",
    "        self.my_dict = my_dict\n",
    "    def filter_by_pre_or_post(self, pre_or_post):\n",
    "        #initialize an empty dictionary\n",
    "        filtered_dict = {}\n",
    "        #iterate over the keys in the dictionary\n",
    "        for key in self.my_dict.keys():\n",
    "            #if the user input argument is 'pre' then filter the dictionary by the keys that contain 'pre'\n",
    "            if pre_or_post == 'pre':\n",
    "                if 'pre' in key:\n",
    "                    filtered_dict[key] = self.my_dict[key]\n",
    "            #if the user input argument is 'post' then filter the dictionary by the keys that contain 'post'\n",
    "            elif pre_or_post == 'post':\n",
    "                if 'post' in key:\n",
    "                    filtered_dict[key] = self.my_dict[key]\n",
    "            #if the user input argument is neither 'pre' nor 'post' then return an error message\n",
    "            else:\n",
    "                print(\"Please enter either 'pre' or 'post' as the argument.\")\n",
    "        return filtered_dict\n",
    "    def filter_by_group(self, group):\n",
    "        #initialize an empty dictionary\n",
    "        filtered_dict = {}\n",
    "        #iterate over the keys in the dictionary\n",
    "        for key in self.my_dict.keys():\n",
    "            #if the user input argument is 'Lmc_opsin' then filter the dictionary by the keys that contain 'Lmc_opsin'\n",
    "            if group == 'Lmc_opsin':\n",
    "                if 'Lmc_opsin' in key:\n",
    "                    filtered_dict[key] = self.my_dict[key]\n",
    "            #if the user input argument is 'Lmc_noopsin' then filter the dictionary by the keys that contain 'Lmc_noopsin'\n",
    "            elif group == 'Lmc_noopsin':\n",
    "                if 'Lmc_noopsin' in key:\n",
    "                    filtered_dict[key] = self.my_dict[key]\n",
    "            #if the user input argument is neither 'Lmc_opsin' nor 'Lmc_noopsin' then return an error message\n",
    "            else:\n",
    "                print(\"Please enter either 'Lmc_opsin' or 'Lmc_noopsin' as the argument.\")\n",
    "        return filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_inputdict_2_trialdict(my_dict):\n",
    "    \n",
    "    #initialize an empty dictionary\n",
    "    trial_dict = {}\n",
    "    \n",
    "    #iterate over the keys in the dictionary to access the matrix values\n",
    "    for key in my_dict.keys():\n",
    "        \n",
    "        #store matrix per key in the input dictionary in a new dictionary, but first change the key name by adding '_zero' to the end of the key name to label the stimulus intensity\n",
    "        trial_dict[str(key) + '_zero'] = my_dict[key][0,0] #store the 2D matrix, assumes that index 0 is the zero intensity stimulus\n",
    "        trial_dict[str(key) + '_low'] = my_dict[key][0,1] #store the 2D matrix, assumes that index 1 is the low intensity stimulus\n",
    "        trial_dict[str(key) + '_mid'] = my_dict[key][0,2] #store the 2D matrix, assumes that index 2 is the mid intensity stimulus\n",
    "        trial_dict[str(key) + '_high'] = my_dict[key][0,3] #store the 2D matrix, assumes that index 3 is the high intensity stimulus\n",
    "        \n",
    "        \n",
    "    #the new dictionary should have the four times the number of keys as the input dictionary\n",
    "    #if not, then return an error message\n",
    "    assert len(trial_dict) == 4*len(my_dict), \"The new dictionary does not have four times the number of keys as the input dictionary.\"\n",
    "\n",
    "    #if it is, then return the new dictionary\n",
    "    return trial_dict      \n",
    "\n",
    "#call the convert_inputdict_2_trialdict function  \n",
    "trial_dict_forprocessing = convert_inputdict_2_trialdict(output_dict_forprocessing) #this is the dictionary that will be used for further processing and will have the 2D matrices as values for each key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n",
      "/var/folders/ws/rz9dhstn6hbcglgm5d7dxjdw0000gq/T/ipykernel_71120/4194666064.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_df = main_df.append(trialdf)\n"
     ]
    }
   ],
   "source": [
    "##make a function that will loop through thr dictionary keys and create a dataframe per key and append it the to the dataframe \n",
    "def create_dataframe_from_dict(my_dict):\n",
    "\n",
    "    #first loop through the the keys in the dictionary and create a dataframe for each key at the end of the loop append the dataframe to the main dataframe\n",
    "\n",
    "    #create an empty dataframe called main_df, this will be the dataframe that will be appended to at the end of each loop\n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    #loop through the keys in the dictionary\n",
    "    for key in my_dict.keys():\n",
    "        #determine the number of trials which is the number of rows of the matrix\n",
    "        num_trials = my_dict[key].shape[0]\n",
    "        \n",
    "        ##iterate through the number of trials of the matrix and pull out the row slice of the matrix, store the row number as the trial_id in the main_df\n",
    "        for trial in range(num_trials):\n",
    "            \n",
    "            #create a dataframe to store the matrix\n",
    "            trialdf = pd.DataFrame()\n",
    "            \n",
    "            #add the trial name to the trial_name column\n",
    "            trialdf['trial_name'] = [key]\n",
    "            \n",
    "            #add the spikes to the spikes column, pull out the entire matrix and store it in the spikes column\n",
    "            trialdf['spikes'] = [my_dict[key][trial,:]]\n",
    "            \n",
    "        \n",
    "        #append the trialdf dataframe to the main_df dataframe\n",
    "        main_df = main_df.append(trialdf)\n",
    "        \n",
    "        #return the main_df dataframe\n",
    "    return main_df\n",
    "\n",
    "#call the function to create the dataframe\n",
    "main_df_forprocessing = create_dataframe_from_dict(trial_dict_forprocessing)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cid93' 'cid134' 'cid113' 'cid52' 'cid238' 'cid148' 'cid21' 'cid145'\n",
      " 'cid79' 'cid24' 'cid219' 'cid82' 'cid211' 'cid39' 'cid159' 'cid22'\n",
      " 'cid81' 'cid91' 'cid156' 'cid169' 'cid244' 'cid251' 'cid102']\n",
      "['Lmc_opsin_lmc_ch_2_3093_rec1_cid93_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid93_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid93_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid93_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid134_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid134_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid134_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid134_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid113_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid113_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid113_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid113_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid52_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid52_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid52_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid52_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid238_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid238_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid238_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid238_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid148_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid148_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid148_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid148_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid21_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid21_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid21_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid21_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid113_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid113_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid113_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid113_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid145_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid145_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid145_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid145_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid79_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid79_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid79_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid79_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid24_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid24_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid24_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid24_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid52_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid52_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid52_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid52_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid219_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid219_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid219_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid219_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid82_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid82_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid82_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid82_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid211_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid211_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid211_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid211_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid39_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid39_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid39_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid39_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid238_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid238_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid238_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid238_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid159_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid159_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid159_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid159_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid22_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid22_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid22_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid22_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid81_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid81_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid81_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid81_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid91_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid91_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid91_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid91_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid156_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid156_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid156_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid156_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid22_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid22_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid22_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid22_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid79_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid79_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid79_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid79_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid219_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid219_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid219_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid219_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid82_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid82_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid82_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec2_cid82_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid169_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid169_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid169_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid169_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid134_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid134_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid134_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid134_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid148_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid148_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid148_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid148_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid211_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid211_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid211_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid211_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid39_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid39_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid39_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid39_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid93_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid93_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid93_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid93_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid81_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid81_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid81_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid81_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid244_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid244_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid244_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid244_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid251_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid251_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid251_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid251_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid102_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid102_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid102_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid102_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid156_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid156_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid156_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid156_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid91_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid91_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid91_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid91_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid102_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid102_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid102_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_2_3093_rec1_cid102_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid159_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid159_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid159_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid159_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid24_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid24_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid24_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid24_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid169_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid169_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid169_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid169_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid145_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid145_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid145_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_opsin_lmc_ch_1_3094_rec1_cid145_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid21_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid21_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid21_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec2_cid21_pre_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid251_post_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid251_post_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid251_post_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid251_post_SpikeTrains_for_PSTHs_high'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid244_pre_SpikeTrains_for_PSTHs_zero'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid244_pre_SpikeTrains_for_PSTHs_low'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid244_pre_SpikeTrains_for_PSTHs_mid'\n",
      " 'Lmc_noopsin_lmc_noch_1_3096_rec1_cid244_pre_SpikeTrains_for_PSTHs_high']\n"
     ]
    }
   ],
   "source": [
    "#in trial_dict_forprocessing, extract the 2D matrix for the trial name that has Lmc_opsin_lmc_ch_1_3094_rec1_cid134_post_SpikeTrains_for_PSTHs_zero in trial_name\n",
    "#store the 2D matrix in a variable called trial_matrix\n",
    "trial_matrix = trial_dict_forprocessing['Lmc_opsin_lmc_ch_1_3094_rec1_cid134_post_SpikeTrains_for_PSTHs_zero']\n",
    "\n",
    "#make a function that will now add columnns based on the trial name columns \n",
    "def add_columns_from_trial_name(my_df):\n",
    "    \n",
    "    #create a new column called is_post, if the the trial_name contains_post then the value is True, if not then the value is False\n",
    "    my_df['is_post'] = my_df['trial_name'].str.contains('post')\n",
    "    \n",
    "    #create four columns called zero, low, mid, high and store as True if the trial_name contains zero, low, mid, high respectively and False if not\n",
    "    my_df['zero'] = my_df['trial_name'].str.contains('zero')\n",
    "    my_df['low'] = my_df['trial_name'].str.contains('low')\n",
    "    my_df['mid'] = my_df['trial_name'].str.contains('mid')\n",
    "    my_df['high'] = my_df['trial_name'].str.contains('high')\n",
    "    \n",
    "    #create a column called 'group_name' and store the group name based on the trial_name, if 'Lmc_opsin' is in the trial_name then store 'Lmc_opsin' in the group_name column, if 'Lmc_noopsin' is in the trial_name then store 'Lmc_noopsin' in the group_name column\n",
    "    my_df['group_name'] = np.where(my_df['trial_name'].str.contains('Lmc_opsin'), 'Lmc_opsin', 'Lmc_noopsin')\n",
    "    \n",
    "    #create a column that has the cell_id based on the trial_name, first by spliting the trial_name between the 7th and 8th '_' and then extracting the characters after the 7th but before the 8th '_' and storing in a new column called cell_id\n",
    "    my_df['cell_id'] = my_df['trial_name'].str.split('_', expand = True)[7] \n",
    "    \n",
    "    #create a column that has the mouse id based on the trial_name by finding four consecutive numbers in the trial_name and storing them in a new column called mouse_id\n",
    "    my_df['mouse_id'] = my_df['trial_name'].str.extract('(\\d{4})', expand = True)\n",
    "\n",
    "    \n",
    "    #return the dataframe\n",
    "    return my_df\n",
    "\n",
    "#call the function to add columns to the dataframe  \n",
    "main_df_forprocessing_addedcol = add_columns_from_trial_name(main_df_forprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory of mat file\n",
    "mat_dir_post = '/Users/cresp1el/Documents/lmc_project_analysis_dir/cell93_post_spiketrains.mat'\n",
    "mat_dir_pre = '/Users/cresp1el/Documents/lmc_project_analysis_dir/cell93_pre_spiketrains.mat'\n",
    "\n",
    "#create a dictionary to store the data\n",
    "mat_post = scipy.io.loadmat(mat_dir_post)\n",
    "mat_pre = scipy.io.loadmat(mat_dir_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the data in a 'spiketrains_pre and spiketrains_post' variable\n",
    "spiketrains_pre = mat_pre['cell93_pre_spiketrains']\n",
    "spiketrains_post = mat_post['cell93_post_spiketrains']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function to store the pre and post spike matrices into a dict where the keys are the stimulus frequencies\n",
    "def spiketrains_dict(spiketrains_pre, spiketrains_post):\n",
    "    spiketrains_dict = {}\n",
    "    spiketrains_dict['pre_zero'] = spiketrains_pre[0,0]\n",
    "    spiketrains_dict['pre_low'] = spiketrains_pre[0,1]\n",
    "    spiketrains_dict['pre_mid'] = spiketrains_pre[0,2]\n",
    "    spiketrains_dict['pre_high'] = spiketrains_pre[0,3]\n",
    "    spiketrains_dict['post_zero'] = spiketrains_post[0,0]\n",
    "    spiketrains_dict['post_low'] = spiketrains_post[0,1]\n",
    "    spiketrains_dict['post_mid'] = spiketrains_post[0,2]\n",
    "    spiketrains_dict['post_high'] = spiketrains_post[0,3]\n",
    "    return spiketrains_dict\n",
    "\n",
    "#call the function to create the dictionarys\n",
    "spiketrains_dict = spiketrains_dict(spiketrains_pre, spiketrains_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that will loop through thr dictionary keys and create a dataframe per key and append it the to the dataframe \n",
    "\n",
    "def spiketrains_df(spiketrains_dict):\n",
    "    #first loop through the the keys in the dictionary and create a dataframe for each key at the end of the loop append the dataframe to the main dataframe\n",
    "\n",
    "    #create an empty dataframe called main_df\n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    #create a list of column names that will be used for the main dataframe column names\n",
    "    column_names = ['trial_name','trial_id','spikes', 'zero','low','mid','high']\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #loop through the keys in the dictionary\n",
    "    #for each key determine the numbner of trials which is the number of rows of the matrix\n",
    "    #then loop through the number of rows, create the trial_id which is the row number, add the row number to the trial_number column\n",
    "    #then pull out the row slice of the matrix and add it to the corresponding spikes column\n",
    "    #then add the trial name to the trial_name column\n",
    "    \n",
    "    for key in spiketrains_dict:\n",
    "        \n",
    "        #determine the number of trials which is the number of rows of the matrix\n",
    "        num_trials = spiketrains_dict[key].shape[0]\n",
    "        \n",
    "        #iterate through the number of trials of the matrix and pull out the row slice of the matrix, store the row number as the trial_id in the main_df\n",
    "        for trial in range(num_trials):\n",
    "                \n",
    "                #create a dataframe for each trial\n",
    "                trial_df = pd.DataFrame()\n",
    "                \n",
    "                #add the trial_id to the trial_id column\n",
    "                trial_df['trial_id'] = [trial]\n",
    "                \n",
    "                #add the spikes to the spikes column, pull out the row slice of the matrix\n",
    "                trial_df['spikes'] = [spiketrains_dict[key][trial,:]]\n",
    "                \n",
    "                #add the trial name to the trial_name column\n",
    "                trial_df['trial_name'] = [key]\n",
    "                \n",
    "                #check if the trial name is pre or post and TRUE in the column 'is_post'\n",
    "                if 'post' in key:\n",
    "                    trial_df['is_post'] = True\n",
    "                else:\n",
    "                    trial_df['is_post'] = False\n",
    "                    \n",
    "                #check if the trial name is zero, low, mid, or high and TRUE in the corresponding columnm if not FALSE\n",
    "                if 'zero' in key:\n",
    "                    trial_df['zero'] = True\n",
    "                    trial_df['low'] = False\n",
    "                    trial_df['mid'] = False\n",
    "                    trial_df['high'] = False\n",
    "                elif 'low' in key:\n",
    "                    trial_df['zero'] = False\n",
    "                    trial_df['low'] = True\n",
    "                    trial_df['mid'] = False\n",
    "                    trial_df['high'] = False\n",
    "                elif 'mid' in key:\n",
    "                    trial_df['zero'] = False\n",
    "                    trial_df['low'] = False\n",
    "                    trial_df['mid'] = True\n",
    "                    trial_df['high'] = False\n",
    "                elif 'high' in key:\n",
    "                    trial_df['zero'] = False\n",
    "                    trial_df['low'] = False\n",
    "                    trial_df['mid'] = False\n",
    "                    trial_df['high'] = True\n",
    "                    \n",
    "                #check if there are at least 2 spikes in the trial, if there are more than 2 spike then TRUE in the column 'more_than_2' or FALSE if there are less than 2 spikes\n",
    "                if np.sum(spiketrains_dict[key][trial,:]) > 2:\n",
    "                    trial_df['more_than_2'] = True\n",
    "                else:\n",
    "                    trial_df['more_than_2'] = False        \n",
    "                    \n",
    "                    \n",
    "                #check if there are more than 50 spikes in the trial, if there are more than 50 spikes then TRUE in the column 'more_than_50' or FALSE if there are less than 50 spikes\n",
    "                if np.sum(spiketrains_dict[key][trial,:]) > 50:\n",
    "                    trial_df['more_than_50'] = True\n",
    "                else:\n",
    "                    trial_df['more_than_50'] = False\n",
    "                \n",
    "                #append the trial_df to the main_df\n",
    "                main_df = main_df.append(trial_df)\n",
    "                \n",
    "    #reset the index of the main_df\n",
    "    main_df = main_df.reset_index(drop=True)\n",
    "    \n",
    "        \n",
    "    return main_df\n",
    "\n",
    "#call the function to create the dataframe\n",
    "main_df = spiketrains_df(spiketrains_dict)\n",
    "    \n",
    "#now         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function to calculate the mean firing rate for each stimulus frequency from dict of spike matrices and return a dict of mean firing rates where the keys are the stimulus frequencies\n",
    "def mean_firing_rate_dict(spiketrains_dict):\n",
    "    mean_firing_rate_dict = {}\n",
    "    for key in spiketrains_dict:\n",
    "        mean_firing_rate_dict[key] = np.mean(spiketrains_dict[key], axis=0)*1000 #multiply by 1000 to convert to Hz\n",
    "    return mean_firing_rate_dict\n",
    "\n",
    "#call the function to create the dictionary of mean firing rates\n",
    "mean_firing_rate_dict = mean_firing_rate_dict(spiketrains_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian filter the mean firing rates with user defined sigma and return a dict of gaussian filtered mean firing rates where the keys are the stimulus frequencies\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "#create a function to gaussian filter the mean firing rates with user defined sigma and return a dict of gaussian filtered mean firing rates where the keys are the stimulus frequencies\n",
    "def gaussian_filter_dict(mean_firing_rate_dict, sigma):\n",
    "    gaussian_filter_dict = {}\n",
    "    for key in mean_firing_rate_dict:\n",
    "        gaussian_filter_dict[key] = gaussian_filter(mean_firing_rate_dict[key], sigma=sigma)\n",
    "    return gaussian_filter_dict\n",
    "\n",
    "#call the function to create the dictionary of gaussian filtered mean firing rates\n",
    "gaussian_filter_dict = gaussian_filter_dict(mean_firing_rate_dict, sigma=5)\n",
    "\n",
    "\n",
    "#plot the gaussian filtered mean firing rates for the pre and post stimulus conditions on the same plot\n",
    "def plot_gaussian_filter_dict(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['pre_high'], label='pre_high')\n",
    "    ax.plot(gaussian_filter_dict['post_high'], label='post_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Pre and Post Stimulus Conditions')\n",
    "    \n",
    "    #add vertical lines to indicate the stimulus onset and offset times \n",
    "    ax.axvline(x=500, color='black', linestyle='--')\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for the pre and post stimulus conditions on the same plot\n",
    "plot_gaussian_filter_dict(gaussian_filter_dict)\n",
    "\n",
    "#plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "# keep the color the same for all prestimulus conditions and change the opacity for each stimulus condition\n",
    "def plot_gaussian_filter_dict_all(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['pre_zero'], color='grey', alpha=0.25, label='pre_zero')\n",
    "    ax.plot(gaussian_filter_dict['pre_low'], color='grey', alpha=0.5, label='pre_low')\n",
    "    ax.plot(gaussian_filter_dict['pre_mid'], color='grey', alpha=0.75, label='pre_mid')\n",
    "    ax.plot(gaussian_filter_dict['pre_high'], color='grey', alpha=1, label='pre_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Pre Stimulus Conditions')\n",
    "    \n",
    "    #add vertical lines to indicate the stimulus onset and offset times \n",
    "    ax.axvline(x=500, color='black', linestyle='--')\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all(gaussian_filter_dict)\n",
    "\n",
    "\n",
    "#now repeat the above for the post stimulus conditions\n",
    "#plot the gaussian filtered mean firing rates for all poststimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "# keep the color the same for all poststimulus conditions and change the opacity for each stimulus condition\n",
    "def plot_gaussian_filter_dict_all_post(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['post_zero'], color='blue', alpha=0.25, label='post_zero')\n",
    "    ax.plot(gaussian_filter_dict['post_low'], color='blue', alpha=0.5, label='post_low')\n",
    "    ax.plot(gaussian_filter_dict['post_mid'], color='blue', alpha=0.75, label='post_mid')\n",
    "    ax.plot(gaussian_filter_dict['post_high'], color='blue', alpha=1, label='post_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Post Stimulus Conditions')\n",
    "    \n",
    "    #add vertical lines to indicate the stimulus onset and offset times \n",
    "    ax.axvline(x=500, color='black', linestyle='--')\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all poststimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all_post(gaussian_filter_dict)\n",
    "\n",
    "#now the same but zoom in from 459 to 550 ms\n",
    "#plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "# keep the color the same for all prestimulus conditions and change the opacity for each stimulus condition\n",
    "def plot_gaussian_filter_dict_all_zoom(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['pre_zero'][459:550], color='grey', alpha=0.25, label='pre_zero')\n",
    "    ax.plot(gaussian_filter_dict['pre_low'][459:550], color='grey', alpha=0.5, label='pre_low')\n",
    "    ax.plot(gaussian_filter_dict['pre_mid'][459:550], color='grey', alpha=0.75, label='pre_mid')\n",
    "    ax.plot(gaussian_filter_dict['pre_high'][459:550], color='grey', alpha=1, label='pre_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Pre Stimulus Conditions')\n",
    "        #add vertical lines to indicate the stimulus onset and offset times \n",
    "    ax.axvline(x=50, color='black', linestyle='--')\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all_zoom(gaussian_filter_dict)\n",
    "\n",
    "#now repeat this plot for the post stimulus conditions\n",
    "#plot the gaussian filtered mean firing rates for all poststimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "# keep the color the same for all poststimulus conditions and change the opacity for each stimulus condition\n",
    "def plot_gaussian_filter_dict_all_post_zoom(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['post_zero'][459:550], color='blue', alpha=0.25, label='post_zero')\n",
    "    ax.plot(gaussian_filter_dict['post_low'][459:550], color='blue', alpha=0.5, label='post_low')\n",
    "    ax.plot(gaussian_filter_dict['post_mid'][459:550], color='blue', alpha=0.75, label='post_mid')\n",
    "    ax.plot(gaussian_filter_dict['post_high'][459:550], color='blue', alpha=1, label='post_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Post Stimulus Conditions')\n",
    "    ax.axvline(x=50, color='black', linestyle='--') \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all poststimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all_post_zoom(gaussian_filter_dict)\n",
    "\n",
    "\n",
    "#now over lay the zoomed in pre and post stimulus conditions on the same plot\n",
    "\n",
    "def plot_gaussian_filter_dict_all_zoom_overlay(gaussian_filter_dict):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(gaussian_filter_dict['pre_zero'][459:550], color='grey', alpha=0.25, label='pre_zero')\n",
    "    ax.plot(gaussian_filter_dict['pre_low'][459:550], color='grey', alpha=0.5, label='pre_low')\n",
    "    ax.plot(gaussian_filter_dict['pre_mid'][459:550], color='grey', alpha=0.75, label='pre_mid')\n",
    "    ax.plot(gaussian_filter_dict['pre_high'][459:550], color='grey', alpha=1, label='pre_high')\n",
    "    ax.plot(gaussian_filter_dict['post_zero'][459:550], color='blue', alpha=0.25, label='post_zero')\n",
    "    ax.plot(gaussian_filter_dict['post_low'][459:550], color='blue', alpha=0.5, label='post_low')\n",
    "    ax.plot(gaussian_filter_dict['post_mid'][459:550], color='blue', alpha=0.75, label='post_mid')\n",
    "    ax.plot(gaussian_filter_dict['post_high'][459:550], color='blue', alpha=1, label='post_high')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Firing Rate (Hz)')\n",
    "    ax.set_title('Gaussian Filtered Mean Firing Rates for Pre and Post Stimulus Conditions')\n",
    "    \n",
    "    #make the high stimulus conditions more thick to make it easier to see\n",
    "    ax.plot(gaussian_filter_dict['pre_high'][459:550], color='grey', alpha=1, linewidth=3)\n",
    "    ax.plot(gaussian_filter_dict['post_high'][459:550], color='blue', alpha=1, linewidth=3)\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "#call the function to plot the gaussian filtered mean firing rates for all prestimulus conditions on the same plot with increasing opacity for increasing stimuli\n",
    "plot_gaussian_filter_dict_all_zoom_overlay(gaussian_filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now loop through the keys in the spiketrains_dict and plot a new raster plot for each key\n",
    "for key in spiketrains_dict:\n",
    "    spikes = spiketrains_dict[key]\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i in range(spikes.shape[0]):\n",
    "        spike_times = np.where(spikes[i] == 1)[0]\n",
    "        ax.vlines(spike_times, i, i+1, color='black')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Trial Number')\n",
    "    ax.set_title('Raster Plot for ' + key)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot the same way but using the main_df dataframe as a function\n",
    "#take user input for 'is_post' being True or False\n",
    "#for each stimulus type, create a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe \n",
    "#plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "\n",
    "def plot_raster_main_df(main_df, is_post):\n",
    "    #is_post is a boolean value of 1 or 0\n",
    "    #if is_post is 1, then plot the post stimulus conditions\n",
    "    #if is_post is 0, then plot the pre stimulus conditions\n",
    "    \n",
    "    #filter the dataframe based on the is_post value\n",
    "    if is_post:\n",
    "        main_df = main_df[main_df['is_post'] == 1]\n",
    "        #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns\n",
    "        main_df_zero = main_df[main_df['zero'] == 1] \n",
    "        main_df_low = main_df[main_df['low'] == 1]\n",
    "        main_df_mid = main_df[main_df['mid'] == 1]\n",
    "        main_df_high = main_df[main_df['high'] == 1]\n",
    "        \n",
    "        #now plot the raster plot for each stimulus type by creating a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe\n",
    "        #plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "        #plot each raster on a new figure\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_zero.shape[0]):  \n",
    "            spike_times = np.where(main_df_zero['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Post Zero')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_low.shape[0]):\n",
    "            spike_times = np.where(main_df_low['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Post Low')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)    \n",
    "        for i in range(main_df_mid.shape[0]):\n",
    "            spike_times = np.where(main_df_mid['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Post Mid')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_high.shape[0]):\n",
    "            spike_times = np.where(main_df_high['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Post High')\n",
    "    #if is_post is 0, then plot the pre stimulus conditions\n",
    "    else:\n",
    "        main_df = main_df[main_df['is_post'] == 0]\n",
    "        \n",
    "        #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns\n",
    "        main_df_zero = main_df[main_df['zero'] == 1]\n",
    "        main_df_low = main_df[main_df['low'] == 1]\n",
    "        main_df_mid = main_df[main_df['mid'] == 1]\n",
    "        main_df_high = main_df[main_df['high'] == 1]\n",
    "    \n",
    "        #now plot the raster plot for each stimulus type by creating a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe\n",
    "        #plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "        #plot each raster on a new figure\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_zero.shape[0]):\n",
    "            spike_times = np.where(main_df_zero['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Pre Zero')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_low.shape[0]):\n",
    "            spike_times = np.where(main_df_low['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Pre Low')\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_mid.shape[0]):\n",
    "            spike_times = np.where(main_df_mid['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Pre Mid')\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        for i in range(main_df_high.shape[0]):\n",
    "            spike_times = np.where(main_df_high['spikes'].iloc[i] == 1)[0]\n",
    "            ax.vlines(spike_times, i, i+1, color='black')\n",
    "        ax.set_xlabel('Time (ms)') \n",
    "        ax.set_ylabel('Trial Number')\n",
    "        ax.set_title('Raster Plot for Pre High')\n",
    "        \n",
    "    #now display all the figure\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "#call the nunction to plot the raster plot for the pre stimulus conditions\n",
    "plot_raster_main_df(main_df, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that will filter the main_df datarame\n",
    "#take user input for input for true or false for is_post \n",
    "#then in a iterative manner, 1) filter the dataframe by zero, low, mid, high 2) filter the dataframe by no_spike being FALSE and more_than_50 being TRUE 3) plot the raster plot for each stimulus as a new plot \n",
    "def plot_raster_main_df_no_spike(main_df, is_post):\n",
    "   #is_post is a boolean value of 1 or 0\n",
    "   #if is_post is 1, then plot the post stimulus conditions\n",
    "   #if is_post is 0, then plot the pre stimulus conditions\n",
    "   #filter the dataframe by is_post being TRUE or FALSE\n",
    "   if is_post == 1:\n",
    "      #filter the dataframe by is_post being TRUE\n",
    "      main_df = main_df[main_df['is_post'] == 1]\n",
    "      #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns AND filter the dataframe by no_spike being FALSE and more_than_50 being FALSE conditions\n",
    "      main_df_zero = main_df[(main_df['zero'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_low = main_df[(main_df['low'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_mid = main_df[(main_df['mid'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_high = main_df[(main_df['high'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "\n",
    "      #now plot the raster plot for each stimulus type by creating a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe\n",
    "      #plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "      #plot each raster on a new figure   \n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_zero.shape[0]):\n",
    "         spike_times = np.where(main_df_zero['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number') \n",
    "      ax.set_title('Raster Plot for Post Zero')\n",
    "\n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_low.shape[0]):\n",
    "         spike_times = np.where(main_df_low['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Post Low ')\n",
    "\n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_mid.shape[0]):\n",
    "         spike_times = np.where(main_df_mid['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Post Mid')\n",
    "\n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_high.shape[0]):\n",
    "         spike_times = np.where(main_df_high['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Post High')   \n",
    "\n",
    "   else: \n",
    "      #filter the dataframe by is_post being FALSE\n",
    "      main_df = main_df[main_df['is_post'] == 0]\n",
    "      #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns AND filter the dataframe by no_spike being FALSE and more_than_50 being FALSE conditions\n",
    "      main_df_zero = main_df[(main_df['zero'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_low = main_df[(main_df['low'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_mid = main_df[(main_df['mid'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "      main_df_high = main_df[(main_df['high'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "\n",
    "      #now plot the raster plot for each stimulus type by creating a matrix of the spikes where the rows are the trials and the data is the correspding 'spikes' column of the dataframe\n",
    "      #plot the raster plot for each stimulus type being zero, low, mid, high based on the TRUE or FALSE for zero, low, mid, high columns of the dataframe\n",
    "      #plot each raster on a new figure\n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_zero.shape[0]):\n",
    "         spike_times = np.where(main_df_zero['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Pre Zero')\n",
    "      \n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_low.shape[0]):\n",
    "         spike_times = np.where(main_df_low['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Pre Low')\n",
    "      \n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_mid.shape[0]):\n",
    "         spike_times = np.where(main_df_mid['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)') \n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Pre Mid')\n",
    "      \n",
    "      \n",
    "      fig, ax = plt.subplots(1, 1)\n",
    "      for i in range(main_df_high.shape[0]):\n",
    "         spike_times = np.where(main_df_high['spikes'].iloc[i] == 1)[0]\n",
    "         ax.vlines(spike_times, i, i+1, color='black')\n",
    "      ax.set_xlabel('Time (ms)')\n",
    "      ax.set_ylabel('Trial Number')\n",
    "      ax.set_title('Raster Plot for Pre High')\n",
    "\n",
    "\n",
    "      \n",
    "   plt.show()\n",
    "   \n",
    "   return \n",
    "\n",
    "#call the function to plot the raster plot for the pre and post stimulus types for filtered dataframes\n",
    "plot_raster_main_df_no_spike(main_df, 1) \n",
    "plot_raster_main_df_no_spike(main_df, 0) \n",
    "         \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculateISIsfromfiltereddata(main_df, is_post):\n",
    "    #is_post is a boolean value of 1 or 0\n",
    "    #if is_post is 1, then plot the post stimulus conditions\n",
    "    #if is_post is 0, then plot the pre stimulus conditions\n",
    "    #filter the dataframe by is_post being TRUE or FALSE\n",
    "\n",
    "    \n",
    "    if is_post == 1:\n",
    "        #filter the dataframe by is_post being TRUE\n",
    "        main_df = main_df[main_df['is_post'] == 1]\n",
    "        #filter the dataframe per stimulus type which is the TRUE or FALSE value for the zero, low, mid, high columns AND filter the dataframe by no_spike being FALSE and more_than_50 being FALSE conditions\n",
    "        main_df_zero = main_df[(main_df['zero'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_low = main_df[(main_df['low'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_mid = main_df[(main_df['mid'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_high = main_df[(main_df['high'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        \n",
    "        #store the dataframes into a list to iterate through\n",
    "        main_df_list = [main_df_zero, main_df_low, main_df_mid, main_df_high]\n",
    "        \n",
    "        #for each dataframe in the list, add a columns for the ISIs to be stored in\n",
    "        for df in main_df_list:\n",
    "            df['ISIs'] = pd.Series(dtype=object)\n",
    "            \n",
    "        #iterate through the list of dataframes to do the following:\n",
    "        # 1) create an array for the calculated  ISIs to be stored in for each trial which correspond to the row of the partiuclar dataframe\n",
    "        # 2) iterate through the spikes column for the length of rows of the particualr  dataframe to calculate the ISIs for each trial\n",
    "        \n",
    "        for df in main_df_list:\n",
    "            for i in range(df.shape[0]):\n",
    "                ISIs = []\n",
    "                spike_times = np.where(df['spikes'].iloc[i] == 1)[0]\n",
    "                for j in range(len(spike_times)-1):\n",
    "                    ISI = spike_times[j+1] - spike_times[j]\n",
    "                    ISIs.append(ISI)\n",
    "                df['ISIs'].iloc[i] = ISIs\n",
    "                \n",
    "    #else if is_post is 0, repeate the same process as above but for the pre stimulus conditions\n",
    "    elif is_post == 0:\n",
    "        main_df = main_df[main_df['is_post'] == 0]\n",
    "        main_df_zero = main_df[(main_df['zero'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_low = main_df[(main_df['low'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_mid = main_df[(main_df['mid'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        main_df_high = main_df[(main_df['high'] == 1) & (main_df['more_than_2'] == 1) & (main_df['more_than_50'] == 0)]\n",
    "        \n",
    "        main_df_list = [main_df_zero, main_df_low, main_df_mid, main_df_high]\n",
    "        \n",
    "        #for each dataframe in the list, add a columns for the ISIs to be stored in\n",
    "        for df in main_df_list:\n",
    "            df['ISIs'] = pd.Series(dtype=object)\n",
    "            \n",
    "        #iterate through the list of dataframes to do the following:\n",
    "        # 1) create an array for the calculated  ISIs to be stored in for each trial which correspond to the row of the partiuclar dataframe\n",
    "        # 2) iterate through the spikes column for the length of rows of the particualr  dataframe to calculate the ISIs for each trial\n",
    "        \n",
    "        for df in main_df_list:\n",
    "            for i in range(df.shape[0]):\n",
    "                ISIs = []\n",
    "                spike_times = np.where(df['spikes'].iloc[i] == 1)[0]\n",
    "                for j in range(len(spike_times)-1):\n",
    "                    ISI = spike_times[j+1] - spike_times[j]\n",
    "                    ISIs.append(ISI)\n",
    "                df['ISIs'].iloc[i] = ISIs\n",
    "                \n",
    "                    \n",
    "    #retunn the updated list of dataframes once processed\n",
    "    return main_df_list\n",
    "\n",
    "#call the function to calculate the ISIs for the post stimulus conditions\n",
    "main_df_list_post = calculateISIsfromfiltereddata(main_df, 1)\n",
    "\n",
    "#call the function to calculate the ISIs for the pre stimulus conditions\n",
    "main_df_list_pre = calculateISIsfromfiltereddata(main_df, 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "#create a funnction to plot the histogram of the ISIs using the list of dataframes given to the function as an input \n",
    "def plotISIhistogram(main_df_list):\n",
    "    #iterate through the list of dataframes to plot the histogram of the ISIs for each stimulus type on a separate plot\n",
    "    for df in main_df_list:\n",
    "        #store all ISIs into a list for plotting and peform a log transformation on the ISIs\n",
    "        all_ISIs = []       \n",
    "        \n",
    "        #iniatilize the bin_size=25 for the histogram, ##CHANGE HERE FOR BIN SIZE was 25\n",
    "        bin_size = 1\n",
    "        \n",
    "        for i in range(df.shape[0]):\n",
    "            for j in range(len(df['ISIs'].iloc[i])):\n",
    "                all_ISIs.append(df['ISIs'].iloc[i][j])\n",
    "                \n",
    "                #of the \n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "        #plot the histogram of the ISIs overlaid with the gaussian kernel density estimate\n",
    "        plt.hist(all_ISIs, bins=np.arange(0, max(all_ISIs) + bin_size, bin_size), density=True)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        #log scale the y axis\n",
    "        plt.yscale('log')\n",
    "        #set the the upper limit of the y axis to be 1\n",
    "        \n",
    "        #set the x axis to be 1500ms ###CHANGE HERE TO ZOOM\n",
    "        plt.xlim(0, 1000)\n",
    "        \n",
    "        plt.ylim(0.0001, 1)    \n",
    "\n",
    "        #set the x axis label\n",
    "        plt.xlabel('ISI (ms)')\n",
    "        \n",
    "        #set the title to be the column called 'trial_name' in the dataframe\n",
    "        plt.title(df['trial_name'].iloc[0])\n",
    "\n",
    "        #show the plot\n",
    "        plt.show()\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "#call the function to plot the histogram of the ISIs for the pre stimulus conditions\n",
    "plotISIhistogram(main_df_list_pre)\n",
    "\n",
    "#call the function to plot the histogram of the ISIs for the post stimulus conditions   \n",
    "plotISIhistogram(main_df_list_post)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repeat the same process as above but zoom in on the ISIs between 0 and 100ms  \n",
    "def plotISIhistogramzoomed(main_df_list):\n",
    "    #iterate through the list of dataframes to plot the histogram of the ISIs for each stimulus type on a separate plot\n",
    "    for df in main_df_list:\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now calculate the ISI for each spike train and plot the histogram of the ISI for each spike train\n",
    "for key in spiketrains_dict:\n",
    "    spikes = spiketrains_dict[key]\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i in range(spikes.shape[0]):\n",
    "        spike_times = np.where(spikes[i] == 1)[0]\n",
    "        ISI = np.diff(spike_times)\n",
    "        ax.hist(ISI, bins=20)\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Trial Number')\n",
    "    ax.set_title('Histogram of ISI for ' + key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create a list of matrices for the pre and post stimulus conditions in two different lists and each matrix is a list of the spike times for each stimulus condition zero, low, mid, high\n",
    "pre_stimulus_list = []\n",
    "post_stimulus_list = []\n",
    "for key in spiketrains_dict:\n",
    "    if key.startswith('pre'):\n",
    "        pre_stimulus_list.append(spiketrains_dict[key])\n",
    "    else:\n",
    "        post_stimulus_list.append(spiketrains_dict[key])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now combine the pre matrices into one matrix and the post matrices into one matrix based on the keys names in the spiketrains_dict\n",
    "#rename the keys in the spiketrains_dict to be pre and post\n",
    "spiketrains_dict['pre'] = spiketrains_dict.pop('pre_zero')\n",
    "spiketrains_dict['pre'] = np.vstack((spiketrains_dict['pre'], spiketrains_dict.pop('pre_low')))\n",
    "spiketrains_dict['pre'] = np.vstack((spiketrains_dict['pre'], spiketrains_dict.pop('pre_mid')))\n",
    "spiketrains_dict['pre'] = np.vstack((spiketrains_dict['pre'], spiketrains_dict.pop('pre_high')))\n",
    "spiketrains_dict['post'] = spiketrains_dict.pop('post_zero')\n",
    "spiketrains_dict['post'] = np.vstack((spiketrains_dict['post'], spiketrains_dict.pop('post_low')))\n",
    "spiketrains_dict['post'] = np.vstack((spiketrains_dict['post'], spiketrains_dict.pop('post_mid')))\n",
    "spiketrains_dict['post'] = np.vstack((spiketrains_dict['post'], spiketrains_dict.pop('post_high')))\n",
    "\n",
    "\n",
    "#now plot the raster plot for the pre and post stimulus conditions\n",
    "for key in spiketrains_dict:\n",
    "    spikes = spiketrains_dict[key]\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i in range(spikes.shape[0]):\n",
    "        spike_times = np.where(spikes[i] == 1)[0]\n",
    "        ax.vlines(spike_times, i, i+1, color='black')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Trial Number')\n",
    "    ax.set_title('Raster Plot for ' + key)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a matrix called pre_matrix annd post_matrix from the spiketrains_dict\n",
    "pre_matrix = spiketrains_dict['pre']\n",
    "post_matrix = spiketrains_dict['post']\n",
    "\n",
    "#now create a subplot with 2 rows and 1 column\n",
    "#using the pre_matrix and post_matrix, plot the raster plots for the pre and post stimulus conditions\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ax[0].vlines(spike_times, i, i+1, color='black')\n",
    "ax[0].set_xlabel('Time (ms)')\n",
    "ax[0].set_ylabel('Trial Number')\n",
    "ax[0].set_title('Raster Plot for Pre Stimulus Condition')\n",
    "\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ax[1].vlines(spike_times, i, i+1, color='black')\n",
    "ax[1].set_xlabel('Time (ms)')\n",
    "ax[1].set_ylabel('Trial Number')\n",
    "ax[1].set_title('Raster Plot for Post Stimulus Condition')\n",
    "\n",
    "#create more spave between the two plots and keep both y axes the same which ever is larger\n",
    "\n",
    "#find the max y value for the pre and post stimulus conditions\n",
    "pre_max_y = pre_matrix.shape[0]\n",
    "post_max_y = post_matrix.shape[0]\n",
    "\n",
    "#set the y limits for both plots to be the max y value\n",
    "ax[0].set_ylim(0, max(pre_max_y, post_max_y))\n",
    "ax[1].set_ylim(0, max(pre_max_y, post_max_y))\n",
    "\n",
    "#set the space between the two plots to be 0.5\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "#now plot the ISI for the pre and post stimulus conditions \n",
    "#pre stimulus condition is in blue and post stimulus condition is in red\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    ax.hist(ISI, bins=50, color='grey', alpha=0.5)\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    ax.hist(ISI, bins=50, color='blue', alpha=0.5)\n",
    "    \n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Trial Number')\n",
    "ax.set_title('Histogram of ISI for Pre and Post Stimulus Conditions')\n",
    "\n",
    "#now create a smpoothed histogram of the ISI for the pre and post stimulus conditions\n",
    "#pre stimulus condition is in blue and post stimulus condition is in red\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.distplot(ISI, hist=False, color='grey')\n",
    "    #zoom in on the y axis to see the distribution better\n",
    "    ax.set_ylim(0, 0.01)\n",
    "    ax.set_xlim(-500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create a smpoothed histogram of the ISI for the post stimulus conditions\n",
    "#post stimulus condition is in blue\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.distplot(ISI, hist=False, color='blue')\n",
    "    #zoom in on the y axis to see the distribution better\n",
    "    ax.set_ylim(0, 0.01)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian kernel density estimation\n",
    "#now create a smpoothed histogram of the ISI for the pre and post stimulus conditions\n",
    "#pre stimulus condition is in grey and post stimulus condition is in blue\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.kdeplot(ISI, color='grey')\n",
    "    #zoom in on the y axis to see the distribution better\n",
    "    ax.set_ylim(0, 0.01)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "    \n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.kdeplot(ISI, color='blue')\n",
    "    #zoom in on the y axis to see the distribution better\n",
    "    ax.set_ylim(0, 0.01)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian kernel density estimation\n",
    "#now create a smpoothed histogram of the ISI for the pre and post stimulus conditions\n",
    "#pre stimulus condition is in grey and post stimulus condition is in blue\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.kdeplot(ISI, color='grey')\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    sns.kdeplot(ISI, color='blue')\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    ax.set_xlim(-500, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the probability distribution of the ISIs for the pre and post stimulus conditions\n",
    "#pre stimulus condition is in grey and post stimulus condition is in blue\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(pre_matrix.shape[0]):\n",
    "    spike_times = np.where(pre_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    ax.hist(ISI, bins=50, density=True, color='grey', alpha=0.5)\n",
    "for i in range(post_matrix.shape[0]):\n",
    "    spike_times = np.where(post_matrix[i] == 1)[0]\n",
    "    ISI = np.diff(spike_times)\n",
    "    ax.hist(ISI, bins=50, density=True, color='blue', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Probability Distribution of ISI for Pre and Post Stimulus Conditions')\n",
    "\n",
    "#zoom in on the y axis to see the distribution better\n",
    "ax.set_ylim(0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmc_ephys_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
